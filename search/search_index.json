{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Atlas","text":"<p>Atlas was developed by Netflix to manage dimensional time series data for near real-time operational insight. Atlas features in-memory data storage, allowing it to gather and report very large numbers of metrics, very quickly.</p> <p>Atlas captures operational intelligence. Whereas business intelligence is data gathered for analyzing trends over time, operational intelligence provides a picture of what is currently happening within a system.</p> <p>Atlas was built because the existing systems Netflix was using for operational intelligence were not able to cope with the increase in metrics we were seeing as we expanded our operations in the cloud. In 2011, we were monitoring 2 million metrics related to our streaming systems. By 2014, we were at 1.2 billion metrics and the numbers continue to rise. Atlas is designed to handle this large quantity of data and can scale with the hardware we use to analyze and store it.</p> <p>For details and background on the project please read through the overview page.</p> <p>Check out the getting started page for an introduction to using Atlas in the cloud environment. Once you've explored the example, check out the stack language references to see the various types of information you can access.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>The instructions on this page are for quickly getting a sample backend server running on a local machine. For other common tasks see:</p> <ul> <li>Querying Data:<ul> <li>Examples</li> <li>Tutorial</li> </ul> </li> <li>Instrumenting Code</li> </ul>"},{"location":"getting-started/#run-a-demo-instance","title":"Run a Demo Instance","text":"<p>Prerequisites</p> <ul> <li>These instructions assume a unix based machine with curl. Other systems   may work, but have not been tried.</li> <li>Java 8 or higher is required.</li> </ul> <p>To quickly run a version with some synthetic sample data:</p> <pre><code>$ curl -LO https://github.com/Netflix/atlas/releases/download/v1.7.8/atlas-standalone-1.7.8.jar\n$ java -jar atlas-standalone-1.7.8.jar\n</code></pre>"},{"location":"getting-started/#explore-available-tags","title":"Explore Available Tags","text":"<p>The tags API is used to explore available tags and the relationships between them.</p> <pre><code># show all tags\n$ curl -s 'http://localhost:7101/api/v1/tags'\n\n# show all values of the name, nf.app and type tags\n$ curl -s 'http://localhost:7101/api/v1/tags/name'\n$ curl -s 'http://localhost:7101/api/v1/tags/nf.app'\n$ curl -s 'http://localhost:7101/api/v1/tags/type'\n\n# show all name tags that also have the type tag\n$ curl -s 'http://localhost:7101/api/v1/tags/name?q=type,:has'\n\n# show all name tags that have an nf.app tag with a value of nccp\n$ curl -s 'http://localhost:7101/api/v1/tags/name?q=nf.app,nccp,:eq'\n</code></pre>"},{"location":"getting-started/#generate-graphs","title":"Generate Graphs","text":"<p>These graph API URLs show off a couple of the capabilities of the Atlas backend.  See the Examples page for more detailed use cases.</p> <pre><code># graph all metrics with a name tag value of ssCpuUser, using an :avg aggregation\n$ curl -Lo graph.png 'http://localhost:7101/api/v1/graph?q=name,ssCpuUser,:eq,:avg'\n\n# duplicate the ssCpuUser signal, check if it is greater than 22.8 and display the result as a vertical span with 30% alpha\n$ curl -Lo graph.png 'http://localhost:7101/api/v1/graph?q=name,ssCpuUser,:eq,:avg,:dup,22.8,:gt,:vspan,30,:alpha'\n</code></pre>"},{"location":"getting-started/#running-demo-with-memory-storage","title":"Running Demo with Memory Storage","text":"<p>Run an instance with a configuration to use the memory storage:</p> <pre><code>$ curl -Lo memory.conf https://raw.githubusercontent.com/Netflix/atlas/v1.7.x/conf/memory.conf\n$ java -jar atlas-standalone-1.7.8.jar memory.conf\n</code></pre> <p>Now we can send some data to it. To quickly get started there is a sample script to send in some data:</p> <pre><code>$ curl -Lo publish-test.sh https://raw.githubusercontent.com/Netflix/atlas/v1.7.x/scripts/publish-test.sh\n$ chmod 755 publish-test.sh\n$ ./publish-test.sh\n</code></pre> <p>Then view the data in a web browser:</p> <pre><code>$ open 'http://localhost:7101/api/v1/graph?q=name,randomValue,:eq,:sum,(,name,),:by'\n</code></pre>"},{"location":"overview/","title":"Overview","text":"<p>Atlas is the system Netflix uses to manage dimensional time-series data for near real-time operational insight. It was primarily created to address issues with scale and query capability in the previous system.</p>"},{"location":"overview/#history","title":"History","text":"<p>In May of 2011, Netflix was using a home-grown solution called Epic to manage time-series data. Epic was a combination of perl CGI scripts, RRDTool logging, and MySQL. We were tracking around 2M distinct time series and the monitoring system was regularly failing to keep up with the volume of data. In addition there were a number of trends in the company which presaged a drastic increase in metric volume:</p> <ul> <li>Rolling pushes to Red/Black deployments.</li> <li>Leveraging auto-scaling for large clusters.   Netflix has always used auto-scaling groups in AWS, but initially most were configured with fixed   size and just used as a group and to replace instances.</li> <li>Expansion internationally into Latin America   and Europe. This led to an increase   in the number of countries being tracked for key metrics and for Europe it was the first move   into additional AWS regions. With additional regions we also wanted to have better isolation so   a problem with monitoring in one region would not impact another, but at the same time have   a mechanism to provide a global view if needed.</li> </ul> <p>Since that time the metric volume has continued to grow quickly. The graph below shows the increase in metrics measured over last few years:</p> <p></p> <p>The growth in raw volume required increased query capability to actually use the data.</p>"},{"location":"overview/#goals","title":"Goals","text":"<p>The main goals for Atlas were to build a system that provided:</p> <ul> <li>A Common API</li> <li>Scale</li> <li>Dimensionality</li> </ul>"},{"location":"overview/#common-api","title":"Common API","text":"<p>Epic did a number of things really well that we didn't want to lose when transitioning. In particular:</p> <ul> <li>Normalization and consolidation</li> <li>Flexible legends that scale independently of the chart</li> <li>Math, especially handling of NaN values representing no data</li> <li>Holt-Winters used for alerting</li> <li>Visualization options</li> <li>Deep linking</li> </ul> <p>Many of these are capabilities that are provided by the RRDTool library Epic was using, but most alternatives we looked at fell short in these categories. In addition, we have uses for other 3rd party services like CloudWatch and it is desirable to have common query capability for that data.</p>"},{"location":"overview/#scale","title":"Scale","text":"<p>As indicated in the history section, metrics volume was growing and we needed a system that could keep up. For a long time our biggest concern was write volume, however, we also wanted to scale in terms of the amount of data we could read or aggregate as part of a graph request.</p>"},{"location":"overview/#dimensionality","title":"Dimensionality","text":"<p>This is a decision that was made because users were already doing it in ways that were hard to support. Epic only support a simple name with some special case system dimensions of cluster and node. Many users were creating names like:</p> <pre><code>com.netflix.eds.nccp.successful.requests.uiversion.nccprt-authorization.devtypid-101.clver-PHL_0AB.uiver-UI_169_mid.geo-US\n</code></pre> <p>That breaks down to:</p> Key Value name com.netflix.eds.nccp.successful.requests.uiversion nccprt authorization devtypid 101 clver PHL_0AB uiver UI_169_mid geo US <p>Since it was all mangled into a name with different conventions by team, users would have to resort to complex regular expressions to slice and dice the data based on the dimensions.</p>"},{"location":"overview/#query-layer","title":"Query Layer","text":"<p>In order to get a common API, have flexibility for backend implementations, and provide merged views across backends we built a query layer that can be hierarchically composed. The diagram below shows the main Netflix setup:</p> <p></p> <p>We have isolated regional deployments in each region we operate in as well as a global deployment that can combine the results from multiple regions. The query and aggregation operations can be performed on the fan out so most of the big summarization operations will distribute the computation across the tree and typically to an optimized storage layer at some point.</p> <p>Allowing the query and rendering layer to work on multiple backends also makes it easier for us to consider transitioning to other backends in the future such as OpenTSDB or InfluxDB. Switching to Atlas one of the biggest hurdles was compatibility and transitioning to the new system.</p>"},{"location":"overview/#stack-language","title":"Stack Language","text":"<p>One of our key requirements was to be able to have deep links into a particular chart and to be able to reliably pass around or embed these images via email, wikis, html pages, etc. In addition, the user who receives the link should be able to tweak the result. Atlas uses a simple stack language that has a minimal punctuation and allows arbitrarily complex graph expressions to be encoded in a URL friendly way. This means that all images can be accessed using a GET request. The stack language is also simple to parse and interpret, allowing it to be easily consumed from a variety of tools. The core features include:</p> <ul> <li>Embedding and linking using a GET request</li> <li>URL friendly stack language<ul> <li>Few special symbols (comma, colon, parenthesis)</li> <li>Easy to extend</li> </ul> </li> <li>Basic operations<ul> <li>Query: and, or, equal, regex, has key, not</li> <li>Aggregation: sum, count, min, max, group by</li> <li>Consolidation: aggregate across time</li> <li>Math: add, subtract, multiply, etc</li> <li>Boolean: and, or, lt, gt, etc</li> <li>Graph settings: legends, area, transparency</li> </ul> </li> </ul>"},{"location":"overview/#graph-example","title":"Graph Example","text":"<p>To illustrate, this is a sample graph image:</p> <p></p> <p>This graph shows the number of requests per second and compares that with a prediction line generated using double exponential smoothing. If the number of requests per second falls below the prediction, it indicates an alert would trigger using the vertical spans. The url to generate this image follows (newlines added for readability):</p> <pre><code>http://atlas/api/v1/graph\n  ?tz=UTC\n  &amp;e=2012-01-01T08:00\n  &amp;s=e-8h\n  &amp;w=500\n  &amp;h=150\n  &amp;l=0\n  &amp;q=nf.cluster,alerttest,:eq,\n     name,requestsPerSecond,:eq,:and,\n     :sum,\n     :dup,10,0.1,0.02,:des,\n     0.85,:mul,\n     :2over,:lt,\n     :rot,$name,:legend,\n     :rot,prediction,:legend,\n     :rot,:vspan,60,:alpha,alert+triggered,:legend\n</code></pre> <p>Adding some comments to the stack expression to explain a bit what is going on:</p> <pre><code># Query to generate the input line\nnf.cluster,alerttest,:eq,\nname,requestsPerSecond,:eq,:and,\n:sum,\n\n# Create a copy on the stack\n:dup,\n\n# Apply a DES function to generate a prediction\n# using the copy on the top of the stack. For\n# a description of the parameters see the DES\n# reference page.\n10,0.1,0.02,:des,\n\n# Used to set a threshold. The prediction should\n# be roughly equal to the line, in this case the\n# threshold would be 85% of the prediction.\n0.85,:mul,\n\n# Before              After\n# 4.                  4. actual\n# 3.                  3. prediction\n# 2. actual           2. actual\n# 1. prediction       1. prediction\n:2over,\n\n# Create a boolean signal line that is 1\n# for datapoints where the actual value is\n# less than the prediction and 0 where it\n# is greater than or equal the prediction.\n# The 1 values are where the alert should\n# trigger.\n:lt,\n\n# Apply presentation details.\n:rot,$name,:legend,\n:rot,prediction,:legend,\n:rot,:vspan,60,:alpha,alert+triggered,:legend\n</code></pre> <p>See the stack language page for more information.</p>"},{"location":"overview/#memory-storage","title":"Memory Storage","text":"<p>Storage for Atlas has been a bit of a sore point. We have tried many backends and ended up moving more and more to a model where pretty much all data is stored in memory either in or off the java heap.</p>"},{"location":"overview/#speed","title":"Speed","text":"<p>The primary goal for Atlas is to support queries over dimensional time series data so we can slice and dice to drill down into problems. This means we frequently have a need to perform a large aggregations that involve many data points even though the final result set might be small.</p> <p>As an example consider a simple graph showing the number of requests per second hitting a service for the last 3 hours. Assuming minute resolution that is 180 datapoints for the final output. On a typical service we would get one time series per node showing the number of requests so if we have 100 nodes the intermediate result set is around 18k datapoints. For one service users went hog wild with dimensions breaking down requests by device (~1000s) and country (~50) leading to about 50k time series per node. If we still assume 100 nodes that is about 900M datapoints for the same 3h line.</p> <p>Though obviously we have to be mindful about the explosion of dimensions, we also want that where possible to be a decision based on cost and business value rather than a technical limitation.</p>"},{"location":"overview/#resilience","title":"Resilience","text":"<p>What all has to be working in order for the monitoring system to work? If it falls over what is involved in getting it back up? Our focus is primarily operational insight so the top priority is to be able to determine what is going on right now. This leads to the following rules of thumb:</p> <ul> <li>Data becomes exponentially less important as it gets older</li> <li>Restoring service is more important than preventing data loss</li> <li>Try to degrade gracefully</li> </ul> <p>As a result the internal Atlas deployment breaks up the data into multiple windows based on the window of data they contain.</p> <p></p> <p>With this setup we can show the last 6h of data as long as clients can successfully publish. The data is all in memory sharded across machines in the 6h clusters. Because the data and index are all in memory on the local node each instance is self-contained and doesn't need any external service to function. We typically run multiple mirrors of the 6h cluster so data is replicated and we can handle loss of an instance. In AWS we run each mirror in a different zone so that a zone failure will only impact a single mirror.</p> <p>The publish cluster needs to know all the instance in the mirror cluster and takes care of splitting the traffic up, so it goes to the correct shard. The set of mirror instances and shards are assigned based on slots from the Edda autoScalingGroups API. Since the set of instances for the mirrors change rarely, the publish instances can cache the Edda response and still retain successfully publish most data if Edda fails. If an instance is replaced and we can't update data we would have partial loss for a single shard if the same shard was missing in another mirror.</p> <p>Historical data can also fail in which case graphs would not be able to show data for some older windows. This doesn't have to be fully continuous, for example a common use case for us is to look at week-over-week (WoW) charts even though the span of the chart might only be a few hours. If the <code>&lt; 4d</code> cluster fails but the <code>&lt; 16d</code> cluster is functioning we could still serve that graph even though we couldn't show a continuous graph for the full week. A graph would still be shown but would be missing data in the middle.</p> <p>After data is written to the mirrors, they will flush to a persistence layer that is responsible for writing the data to the long term storage in S3. The data at full resolution is kept in S3 and we use hadoop (Elastic MapReduce) for processing the data to perform corrective merging of data from the mirrors, generate reports, and perform rollups into a form that can be loaded into the historical clusters.</p>"},{"location":"overview/#cost","title":"Cost","text":"<p>Keeping all data in memory is expensive in-particular with the large growth rate of data. The combination of dimensionality and time based partitioning used for resilience also give us a way to help manage costs.</p> <p>The first way is in controlling the number of replicas. In most cases we are using replicas for redundancy not to provide additional query capacity. For historical data that can be reloaded from stable storage we typically run only one replica as the duration of partial downtime was not deemed to be worth the cost for an additional replica.</p> <p>The second way is as part of the hadoop processing we can compute rollups so that we have a much smaller data volume to load in historical clusters. At Netflix the typical policy is roughly:</p> Cluster Policy &lt; 6h Keeps all data received &lt; 4d ago Keeps most data, we do early rollup by dropping the node dimension on some business metrics &lt; 16d ago Rollup by dropping the node dimension on all metrics older Explicit whitelist, typically recommend BI systems for these use-cases <p>Using these policies we get greatly reduced index sizes for the number of distinct time series despite a significant amount of churn. With auto-scaling and red/black deployment models the set of instances change frequently so typically the intersection of distinct time series from one day to the next is less than 50%. Rollups target the dimensions which lead to that churn giving us much smaller index sizes. Also, in many cases dimensions like node that lead to this increase become less relevant after the node goes away. Deep-dive or investigative use-cases can still access the data using hadoop if needed.</p> <p>Snapshot of index sizes for one region in our environment:</p> &lt; 6h &lt; 4d &lt; 16d"},{"location":"overview/#ecosystem","title":"Ecosystem","text":"<p>Internally there is a lot of tooling and infrastructure built up around Atlas. We are planning to open source many of these tools as time permits. This project is the first step for that with the query layer and some of the in-heap memory storage. Some additional parts that should come in the future:</p> <ul> <li>User interfaces<ul> <li>Main UI for browsing data and constructing queries.</li> <li>Dashboards</li> <li>Alerts</li> </ul> </li> <li>Platform<ul> <li>Inline aggregation of reported data before storage layer</li> <li>Storage options using off-heap memory and lucene</li> <li>Percentile backend</li> <li>Publish and persistence applications</li> <li>EMR processing for computing rollups and analysis</li> <li>Poller for SNMP, healthchecks, etc</li> </ul> </li> <li>Client<ul> <li>Supports integrating servo with Atlas</li> <li>Local rollups and alerting</li> </ul> </li> <li>Analytics<ul> <li>Metrics volume report</li> <li>Canary analysis</li> <li>Outlier and anomaly detection</li> </ul> </li> </ul> <p>These projects were originally developed and run internally and thus only needed to be setup by our team and assume many internal infrastructure pieces to run. There is a goal to try and make this easier, but it will take some time.</p>"},{"location":"api/tags/","title":"Tags","text":"<p>This page is a reference for the tags API provided by Atlas.</p>"},{"location":"api/tags/#uri","title":"URI","text":"<p><code>/api/v1/tags?q=&lt;expr&gt;&amp;[OPTIONS]</code></p>"},{"location":"api/tags/#query-parameters","title":"Query Parameters","text":""},{"location":"api/tags/#callback-callback","title":"Callback (callback)","text":"<p>If the format is <code>json</code>, the callback is used for providing JSONP output. This parameter is ignored for all other formats.</p>"},{"location":"api/tags/#format-format","title":"Format (format)","text":"<p>Specifies the output format to use. The default is <code>json</code>.</p> Value Description json Outputs the graph data as a JSON object. txt Uses mime-type <code>text/plain</code> so it will render in the browser."},{"location":"api/tags/#limit-limit","title":"Limit (limit)","text":"<p>Maximum number of results to return before paging the response. If the response is paged  a <code>x-nflx-atlas-next-offset</code> will be set to indicate the next offset. Pass the value with an  offset param to get the next part of the list. If the header is not present  there is no more data.</p>"},{"location":"api/tags/#offset-offset","title":"Offset (offset)","text":"<p>If the response is paged this param is used to indicate where the next request should pick up from.</p>"},{"location":"api/tags/#query-q","title":"Query (q)","text":"<p>Query expression used to select a set of metrics and manipulate them for presentation in a graph. The query expression can use query and std commands described in the reference. </p>"},{"location":"api/time-parameters/","title":"Time Parameters","text":"<p>APIs that accept time ranges support three parameters:</p> <ol> <li>Start time (<code>s</code>)</li> <li>End time (<code>e</code>)</li> <li>Time zone (<code>tz</code>)</li> </ol>"},{"location":"api/time-parameters/#time-zone","title":"Time Zone","text":"<p>Time zone can be any valid time zone id string.</p>"},{"location":"api/time-parameters/#time","title":"Time","text":""},{"location":"api/time-parameters/#absolute-times","title":"Absolute Times","text":"<p>Absolute times can be specified by name or as a timestamp.</p>"},{"location":"api/time-parameters/#named-times","title":"Named Times","text":"<p>Named times are references that will get resolved to a timestamp when a query is executed. For example, with graphs it is common to set the end time to <code>now</code>.</p> Name Description <code>s</code> User specified start time. Can only be used as part of the end parameter. <code>e</code> User specified end time. Can only be used as part of the start parameter. <code>now</code> Current time. <code>epoch</code> January 1, 1970 UTC."},{"location":"api/time-parameters/#timestamps","title":"Timestamps","text":"<p>Explicit timestamps can use the following formats:</p> Format Description %Y-%m-%d Date using the timezone for the query. The time will be 00:00. %Y-%m-%dT%H:%M Date time using the timezone for the query. The seconds will be 00. %Y-%m-%dT%H:%M:%S Date time using the timezone for the query. %s Seconds since January 1, 1970 UTC. %s (ms) Milliseconds since January 1, 1970 UTC. <p>For times since the epoch both seconds and milliseconds are supported because both are in common use and it helps to avoid confusion when copy and pasting from another source. Values less than or equal 2,147,483,648 (2<sup>31</sup>) will be treated as a timestamp in seconds. Values above that will be treated as a timestamp in milliseconds. So times from the epoch to 1970-01-25T20:31:23 cannot be represented in the millisecond form. In practice, this limitation has not been a problem.</p> <p>The first three formats above can also be used with an explicit time zone.</p>"},{"location":"api/time-parameters/#zone-offsets","title":"Zone Offsets","text":"<p>An explicit time zone can be specified as <code>Z</code> to indicate UTC or by using an offset in hours and minutes. For example:</p> <pre><code>2012-01-12T01:37Z\n2012-01-12T01:37-00:00\n2012-01-12T01:37-07:00\n2012-01-12T01:37-07:42\n</code></pre> <p>A common format recommended for logs at Netflix is an ISO timestamp in UTC:</p> <pre><code>2012-01-12T01:37:27Z\n</code></pre> <p>These can be copy and pasted to quickly check a graph for a timestamp from a log file. For practical purposes in Atlas a <code>-00:00</code> offset timezone can be thought of as UTC, but depending on the source may have some additional meaning.</p>"},{"location":"api/time-parameters/#relative-times","title":"Relative Times","text":"<p>Relative times consist of a named time used for an anchor and an offset duration.</p> <pre><code>&lt;named=time&gt; '-' &lt;duration&gt;\n&lt;named-time&gt; '+' &lt;duration&gt;\n</code></pre> <p>For example:</p> Pattern Description now-1w One week ago. e-1w One week before the end time. s+6h Six hours after the start time. s+P2DT6H5M Two days, 6 hours, and 5 minutes after the start time."},{"location":"api/time-parameters/#durations","title":"Durations","text":""},{"location":"api/time-parameters/#duration-vs-period","title":"Duration vs Period","text":"<p>This section is using the definition of duration and period from the java time libraries. In short:</p> <ul> <li>Durations are a fixed number of seconds.</li> <li>Periods represent a length of time in a given calendar. For example, the length of   a day will vary if there is a daylight savings transition.</li> </ul> <p>The offset used for relative times in Atlas are durations because:</p> <ul> <li>It is    primarily focused on shorter time spans (~ 2 weeks) where drift is less of    an issue. In this range the variation is most commonly seen for the daylight    savings time transitions.</li> <li>For time shifts day over day and week over week are the most common for   operational purposes. During daylight savings time transitions a fixed duration   seems to cause the least confusion, especially when the transition time is within   the window being displayed. The primary use-case where periods were found to be   more beneficial and less confusing is for week over week when looking at a   small window that does not include the transition. In those cases if the signal   reflects human behavior, such as playing movies, then the week over week pattern   will typically line up better if using a period.</li> </ul>"},{"location":"api/time-parameters/#simple-duration","title":"Simple Duration","text":"<p>A simple offset uses a positive integer followed by one of these units:</p> <ul> <li><code>s</code>, <code>second</code>, or <code>seconds</code></li> <li><code>m</code>, <code>min</code>, <code>minute</code>, or <code>minutes</code></li> <li><code>h</code>, <code>hour</code>, or <code>hours</code></li> <li><code>d</code>, <code>day</code>, or <code>days</code></li> <li><code>w</code>, <code>week</code>, or <code>weeks</code></li> <li><code>month</code> or <code>months</code></li> <li><code>y</code>, <code>year</code>, or <code>years</code></li> </ul> <p>All durations are a fixed number of seconds. A day is 24 hours, week is 7 days, month is 30 days, and a year is 365 days.</p>"},{"location":"api/time-parameters/#iso-duration","title":"ISO Duration","text":"<p>The duration can also be specified as an ISO duration string, but day (<code>D</code>) is the largest part that can be used within the duration. Others such as week (<code>W</code>), month (<code>M</code>), and year (<code>Y</code>) are not supported. Examples:</p> Pattern Description P1D One day of exactly 24 hours. P1DT37M One day and 37 minutes. PT5H6M Five hours and six minutes. <p>For more details see docs on parsing durations.</p>"},{"location":"api/graph/anonymization/","title":"Anonymization","text":"<p>Occasionally it is useful to show a graph, but the exact values need to be suppressed. This can be useful for communicating with external support or including in a presentation. To avoid showing the actual values disable tick labels using <code>tick_labels=off</code> and either disable the legend or disable the legend stats.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend_stats=1\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by\n  &amp;s=e-1w\n  &amp;tick_labels=off\n</pre> <p></p> <p>If you also want to suppress the time axis, then use the <code>only_graph</code> option:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;only_graph=1\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by\n  &amp;s=e-1w\n</pre> <p></p>"},{"location":"api/graph/axis-bounds/","title":"Axis Bounds","text":"<p>The upper and lower bounds for an axis can be set to an explicit floating point value or:</p> <ul> <li><code>auto-style</code>: automatically determine the bounds based on the data and the style settings for   that data. In particular, if the line style is area or stack, then   the bounds will be adjusted to show the filled area. This is the default behavior.</li> <li><code>auto-data</code>: automatically determine the bounds based on the data. This will only take into   account the values of the lines. In the case of stack it will account for the   position of the stacked lines, but not the filled area.</li> </ul> <p>When selecting bounds it is important to think about how it can impact the perception of what is shown. Automatic bounds can be useful for zooming in on the data, but can also lead to mis-perceptions for someone quickly scanning a dashboard. Consider these two graphs showing percent CPU usage on an instance:</p> Automatic Bounds Explicit Bounds <p>The automatic bounds allows us to see much more detail, but could lead a casual observer to think there were frequent large spikes in CPU usage rather than just noise on a machine with very little load.</p> <p>See Tick Labels for information on Y axis label formatting and suffix information.</p>"},{"location":"api/graph/axis-bounds/#default-lower","title":"Default Lower","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;s=e-1d\n  &amp;tz=UTC\n  &amp;q=\n    name,sps,:eq,\n    nf.cluster,(,nccp-xbox,nccp-silverlight,),:in,\n    :and,\n    :sum,\n    (,nf.cluster,),:by\n</pre>"},{"location":"api/graph/axis-bounds/#default-lower-stack","title":"Default Lower Stack","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;s=e-1d\n  &amp;tz=UTC\n  &amp;q=\n    name,sps,:eq,\n    nf.cluster,(,nccp-xbox,nccp-silverlight,),:in,\n    :and,\n    :sum,\n    (,nf.cluster,),:by,\n    :stack\n</pre>"},{"location":"api/graph/axis-bounds/#default-upper","title":"Default Upper","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;s=e-1d\n  &amp;tz=UTC\n  &amp;q=\n    name,sps,:eq,\n    nf.cluster,(,nccp-xbox,nccp-silverlight,),:in,\n    :and,\n    :sum,\n    (,nf.cluster,),:by,\n    :neg\n</pre>"},{"location":"api/graph/axis-bounds/#default-upper-stack","title":"Default Upper Stack","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;s=e-1d\n  &amp;tz=UTC\n  &amp;q=\n    name,sps,:eq,\n    nf.cluster,(,nccp-xbox,nccp-silverlight,),:in,\n    :and,\n    :sum,\n    (,nf.cluster,),:by,\n    :neg,\n    :stack\n</pre>"},{"location":"api/graph/axis-bounds/#explicit-bounds","title":"Explicit Bounds","text":"<p>Note the <code>&amp;l=0</code> and <code>&amp;u=60e3</code> parameters.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;s=e-1d\n  &amp;tz=UTC\n  &amp;l=0\n  &amp;u=60e3\n  &amp;q=\n    name,sps,:eq,\n    nf.cluster,(,nccp-xbox,nccp-silverlight,),:in,\n    :and,\n    :sum,\n    (,nf.cluster,),:by\n</pre> <p></p> <p>Note</p> <p>It is possible to define the boundaries beyond the range of the data source so that a graph appears empty.</p>"},{"location":"api/graph/axis-bounds/#auto-lower","title":"Auto Lower","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;s=e-1d\n  &amp;tz=UTC\n  &amp;l=auto-data\n  &amp;\n  &amp;q=\n    name,sps,:eq,\n    nf.cluster,(,nccp-xbox,nccp-silverlight,),:in,\n    :and,\n    :sum,\n    (,nf.cluster,),:by,\n    :stack\n</pre>"},{"location":"api/graph/axis-bounds/#auto-upper","title":"Auto Upper","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;s=e-1d\n  &amp;tz=UTC\n  &amp;u=auto-data\n  &amp;\n  &amp;q=\n    name,sps,:eq,\n    nf.cluster,(,nccp-xbox,nccp-silverlight,),:in,\n    :and,\n    :sum,\n    (,nf.cluster,),:by,\n    :stack\n</pre>"},{"location":"api/graph/axis-scale/","title":"Axis Scale","text":"<p>Scales determine how the data value for a line will get mapped to the Y-Axis. There are currently five scales that can be used for an axis:</p> <ul> <li>Linear</li> <li>Logarithmic</li> <li>Log Linear</li> <li>Power of 2</li> <li>Square Root</li> </ul> <p>See Tick Labels for information on Y axis label formatting and suffix information.</p>"},{"location":"api/graph/axis-scale/#linear","title":"Linear","text":"<p>A linear scale uniformly maps the input values (domain) to the Y-axis location (range). If v is datapoint in a time series, then y=m*v+b where m and b are automatically chosen based on the domain and range.</p> <p>This is the default scale for an axis and will get used if no explicit scale is set. Since 1.6, it can also be used explicitly:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    minuteOfHour,:time,\n    1e3,:add,\n    minuteOfHour,:time\n  &amp;scale=linear\n</pre> <p></p>"},{"location":"api/graph/axis-scale/#logarithmic","title":"Logarithmic","text":"<p>A logarithmic scale emphasizes smaller values when mapping the input values (domain) to the Y-axis location (range). This is often used if two lines with significantly different magnitudes are on the same axis. If v is datapoint in a time series, then y=m*log(v)+b where m and b are automatically chosen based on the domain and range. In many cases, using a separate Y-axis can be a better option that doesn't distort the line as much.</p> <p>To use this mode, add <code>scale=log</code> (prior to 1.6 use <code>o=1</code>).</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    minuteOfHour,:time,\n    1e3,:add,\n    minuteOfHour,:time\n  &amp;scale=log\n</pre> <p></p>"},{"location":"api/graph/axis-scale/#log-linear","title":"Log Linear","text":"<p>Since 1.8.</p> <p>A logarithmic scale for powers of 10 with linear behavior between ticks. This is useful for heatmap views of percentile distributions. Note that unit suffixes change with this scale.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    minuteOfHour,:time,\n    1e3,:add,\n    minuteOfHour,:time\n  &amp;scale=log-linear\n</pre> <p></p>"},{"location":"api/graph/axis-scale/#power-of-2","title":"Power of 2","text":"<p>Since 1.6.</p> <p>A power scale that emphasizes larger values when mapping the input values (domain) to the Y-axis location (range). If v is datapoint in a time series, then y=m*v<sup>2</sup>+b where m and b are automatically chosen based on the domain and range. To emphasize smaller values see the square root scale.</p> <p>To use this mode, add <code>scale=pow2</code>.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    minuteOfHour,:time,\n    1e3,:add,\n    minuteOfHour,:time\n  &amp;scale=pow2\n</pre> <p></p>"},{"location":"api/graph/axis-scale/#square-root","title":"Square Root","text":"<p>Since 1.6.</p> <p>A power scale that emphasizes smaller values when mapping the input values (domain) to the Y-axis location (range). If v is datapoint in a time series, then y=m*v<sup>0.5</sup>+b where m and b are automatically chosen based on the domain and range. To emphasize larger values see the power of 2 scale.</p> <p>To use this mode, add <code>scale=sqrt</code>.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    minuteOfHour,:time,\n    1e3,:add,\n    minuteOfHour,:time\n  &amp;scale=sqrt\n</pre> <p></p>"},{"location":"api/graph/basics/","title":"Basics","text":"<p>This section gives some examples to get started quickly creating simple graphs.</p> <ul> <li>Single Line</li> <li>Adding a Title</li> <li>Multiple Lines</li> <li>Group By</li> <li>Simple Math</li> <li>Binary Operations</li> </ul>"},{"location":"api/graph/basics/#single-line","title":"Single Line","text":"<p>The only required parameter is <code>q</code> which specifies the query expression for a line. The other two common parameters are for setting the start time, <code>s</code>, and the end time, <code>e</code>, for the data being shown. Usually the start time will be set relative to the end time, such as <code>e-3h</code>, which indicates 3 hours before the end time. See time parameters for more details on time ranges.</p> <p>Putting it all together:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq\n  &amp;s=e-2d\n</pre> <p></p> <p>The resulting PNG plot displays time along the X axis, automatically scaled to the proper time range. The Y axis labels are scaled using metric prefixes to show the measured value. A legend is displayed under the plot with the name(s) of the expression results and a set of statistics computed on the plotted data for the time window. The small text at the very  bottom reflect query parameters and step size along with some processing statistics.</p>"},{"location":"api/graph/basics/#adding-a-title","title":"Adding a Title","text":"<p>The graph title can be set using the <code>title</code> parameter. Similarly, a Y-axis label can be set using the <code>ylabel</code> parameter.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq\n  &amp;s=e-2d\n  &amp;title=Starts+Per+Second\n  &amp;ylabel=sps\n</pre> <p></p>"},{"location":"api/graph/basics/#multiple-lines","title":"Multiple Lines","text":"<p>Multiple expressions can be placed on a chart by concatenating the expressions, e.g., showing a query expression along with a constant value:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    500e3\n  &amp;s=e-2d\n</pre> <p></p>"},{"location":"api/graph/basics/#group-by","title":"Group By","text":"<p>Multiple lines can also be a result of a single expression via group by.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by\n  &amp;s=e-2d\n</pre> <p></p>"},{"location":"api/graph/basics/#simple-math","title":"Simple Math","text":"<p>A number of operators are provided to manipulate a line. See the math section of the stack language tutorial for a complete list. Example that negates the value of a line:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    :neg\n  &amp;s=e-2d\n</pre> <p></p> <p>Example that negates and then applies  absolute value to get the original value back (since all values were  positive in the input):</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    :neg,\n    :abs\n  &amp;s=e-2d\n</pre> <p></p>"},{"location":"api/graph/basics/#binary-operations","title":"Binary Operations","text":"<p>Lines can be combined using binary math operators such as add or  multiply. Example using divide:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    1000,:div\n  &amp;s=e-2d\n</pre> <p></p> <p>If used with a group by, then either:</p> <ul> <li>Both sides have the same group by clause. In this case an inner join will be preformed and the   binary operation will be applied to the corresponding entries from both sides.</li> <li>One side is not a grouped expression, and the binary operation will be applied for each instance   in the grouped result set.</li> </ul>"},{"location":"api/graph/basics/#both-sides-grouped","title":"Both Sides Grouped","text":"<p>Dividing by self with both sides grouped:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    :dup,\n    :div\n  &amp;s=e-2d\n</pre> <p></p>"},{"location":"api/graph/basics/#one-side-grouped","title":"One Side Grouped","text":"<p>Dividing a grouped expression by a constant:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    1000,:div\n  &amp;s=e-2d\n</pre> <p></p> <p>Equivalent to the previous expression, but the right-hand side is grouped and it uses multiply instead of divide:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    0.001,name,sps,:eq,\n    (,nf.cluster,),:by,\n    :mul\n  &amp;s=e-2d\n</pre> <p></p>"},{"location":"api/graph/color-palettes/","title":"Color Palettes","text":"<p>The following color palettes are supported:</p> <ul> <li>armytage</li> <li>epic</li> <li>blues</li> <li>greens</li> <li>oranges</li> <li>purples</li> <li>reds</li> <li>custom</li> </ul> <p>There is also a hashed selection mode that can be used so that a line with a given label will always get the same color.</p>"},{"location":"api/graph/color-palettes/#armytage","title":"Armytage","text":"<p>This is the default color palette, it comes from the paper A Colour Alphabet and the Limits of Colour Coding by Paul Green-Armytage. Two colors, Xanthin and Yellow, are excluded because users found them hard to distinguish from a white background when used for a single pixel line. So overall there are 24 distinct colors with this palette.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;palette=armytage\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;q=\n    1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n</pre> <p></p>"},{"location":"api/graph/color-palettes/#epic","title":"Epic","text":"<p>This is a legacy palette that alternates between shades of red, green, and blue. It is supported for backwards compatibility, but not recommended.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;palette=epic\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;q=\n    1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n</pre> <p></p>"},{"location":"api/graph/color-palettes/#blues","title":"Blues","text":"<p>Shades of blue.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;palette=blues\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;q=\n    1,1,1,1,1,1,1\n</pre> <p></p>"},{"location":"api/graph/color-palettes/#greens","title":"Greens","text":"<p>Shades of green.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;palette=greens\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;q=\n    1,1,1,1,1,1,1\n</pre> <p></p>"},{"location":"api/graph/color-palettes/#oranges","title":"Oranges","text":"<p>Shades of orange.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;palette=oranges\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;q=\n    1,1,1,1,1,1,1\n</pre> <p></p>"},{"location":"api/graph/color-palettes/#purples","title":"Purples","text":"<p>Shades of purple.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;palette=purples\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;q=\n    1,1,1,1,1,1,1\n</pre> <p></p>"},{"location":"api/graph/color-palettes/#reds","title":"Reds","text":"<p>Shades of red.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;palette=reds\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;q=\n    1,1,1,1,1,1,1\n</pre> <p></p>"},{"location":"api/graph/color-palettes/#custom","title":"Custom","text":"<p>A custom color palette can be provided for a graph by using a list of  comma separated  hex color values following the ASL list format <code>(,HEX,HEX,HEX,)</code>.  This is mainly used to customize the colors for the result of a group by where you  cannot set the color for each line using the list.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;palette=(,1a9850,91cf60,d9ef8b,fee08b,fc8d59,d73027,)\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;q=\n    1,1,1,1,1,1,1\n</pre> <p></p>"},{"location":"api/graph/color-palettes/#hashed-selection","title":"Hashed Selection","text":"<p>Any of the palettes above can be prefixed with <code>hash:</code> to select the color using a hashing function on the label rather than picking the next color from the list. The primary advantage is that the selected color will always be the same for a given label using a particular palette. However, some nice properties of the default mode are lost:</p> <ul> <li>Colors can be duplicated even with a small number of lines. Hash collisions will result   in the same color.</li> <li>The palettes are ordered to try and make the stacked appearance and legends easier to   read. For the armytage palette it is ordered so adjacent colors are easy   to distinguish. For the palettes that are shades of a color they are ordered from dark   to light shades to create a gradient effect. Hashing causes an arbitrary ordering of   the colors from the palette.</li> </ul> <p>The table below illustrates the difference by adding some additional lines to a chart for the second row:</p> armytage hash:armytage <p></p> <p></p> <p></p> <p></p> <p>Example:</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;palette=hash:armytage\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    :stack\n  &amp;tz=UTC\n</pre> <p></p>"},{"location":"api/graph/examples/","title":"Examples","text":"<p>Browse the sidebar to get a good overview of graph options. It is recommended to at least go through the basics section. There is also a quick visual index below:</p> Line Area Stack Stacked Percent <p></p> <p></p> <p></p> <p></p> VSpan Transparency Line Width Palettes <p></p> <p></p> <p></p> <p></p> Bounds Scales Multi Y Time Zones <p></p> <p></p> <p></p> <p></p>"},{"location":"api/graph/graph/","title":"Introduction","text":"<p>The Graph API is the primary means to retrieve data from an Atlas store.</p> <p>The default response is a PNG image plotting data matching the  Atlas Stack Language expression along with optional parameters  to control time ranges, size, style, labels, etc. For a quick overview by example see  the examples page.</p> <p>If graphs look familiar, that's because the design and language were inspired by  RRDtool. RRD style graphs offer concise and highly customizable views of time series data. While a number of observability tools offer dynamic charts, a major benefit of these PNG graphs is the ability to snapshot data in time, particularly when that data may expire from a high throughput data store;  PNGs are forever. Additionally, the majority of email and on-call systems support  images out of the box without having to worry about porting a dynamic graphing library to various browsers and clients.</p> <p>The API only supports HTTP query strings at this time. This makes it easy to construct queries with tooling and share the URIs with other users. No JSON request payloads needed.</p> <p>Additional Output formats, including JSON, can be found in Outputs.</p>"},{"location":"api/graph/graph/#uri","title":"URI","text":"<p><code>/api/v1/graph?q=&lt;expr&gt;[&amp;OPTIONS]</code></p>"},{"location":"api/graph/graph/#http-method","title":"HTTP Method","text":"<p><code>GET</code> - Only the GET method is allowed at this time.</p>"},{"location":"api/graph/graph/#query-parameters","title":"Query Parameters","text":""},{"location":"api/graph/graph/#data","title":"Data","text":"<p>The only required query param is <code>q</code> which is the query expression  used by the user to select and manipulate data. The simplest API query you can make is  <code>/api/v1/graph?q=42</code>. This will produce a graph from Atlas with a straight line having a value of <code>42</code> for 3 hours* with a legend including statistics for the query period. </p> <p>All query params related to fetching data:</p> Name Description Default Type <code>q</code> Query expression must be specified by user expr <code>step</code> Step size for data auto duration <p>Warning</p> <p>In most cases users should not set <code>step</code> directly. The <code>step</code> parameter is deprecated.</p>"},{"location":"api/graph/graph/#time","title":"Time","text":"<p>There are three parameters to control the time range used for a graph:</p> Name Description Default Type <code>s</code> Start time <code>e-3h</code>* Time <code>e</code> End time <code>now</code>* Time <code>tz</code> Time zone <code>US/Pacific</code>* Time zone ID <p>For more information on the behavior see the time parameters page.</p>"},{"location":"api/graph/graph/#image-flags","title":"Image Flags","text":"Name Description Default Type <code>title</code> Set the graph title no title String <code>no_legend</code> Suppresses the legend <code>0</code> boolean <code>no_legend_stats</code> Suppresses summary stats for the legend <code>0</code> boolean <code>axis_per_line</code> Put each line on a separate Y-axis <code>0</code> boolean <code>only_graph</code> Only show the graph canvas <code>0</code> boolean <code>vision</code> Simulate different vision types <code>normal</code> vision type"},{"location":"api/graph/graph/#image-size","title":"Image Size","text":"<p>There are four parameters to control the image size and layout used for a graph:</p> Name Description Default Type <code>layout</code> Mode for controlling exact or relative sizing <code>canvas</code> layout mode <code>w</code> Width of the canvas or image <code>700</code>* int <code>h</code> Height of the canvas or image <code>300</code>* int <code>zoom</code> Transform the size by a zoom factor <code>1.0</code> float <p>For more information on the behavior see the graph layout page.</p>"},{"location":"api/graph/graph/#y-axis","title":"Y-Axis","text":"Name Description Default Type <code>stack</code> Set the default line style to stack <code>0</code> boolean <code>l</code> Lower bound for the axis <code>auto-style</code> axis bound <code>u</code> Upper bound for the axis <code>auto-style</code> axis bound <code>ylabel</code> Label for the axis no label String <code>palette</code> Color palette to use <code>armytage</code> palette <code>o</code> Use a logarithmic scale (deprecated in 1.6) <code>0</code> boolean <code>scale</code> Set the axis scale to use (since 1.6) <code>linear</code> scale <code>tick_labels</code> Set the mode to use for tick labels <code>decimal</code> tick label mode <code>sort</code> Set the mode to use for sorting the legend expr order sort mode <code>order</code> Set the order ascending or descending for the sort <code>asc</code> order"},{"location":"api/graph/graph/#output-format","title":"Output Format","text":"Name Description Default Type <code>format</code> Output format to use <code>png</code> output format <code>callback</code> Method name to use for JSONP callback none String"},{"location":"api/graph/graph/#defaults","title":"Defaults","text":"<p>If marked with an <code>*</code> the default shown can be changed by the administrator for the Atlas server. As a result the default in the table may not match the default you see. The defaults listed do match those used for the primary Atlas backends in use at Netflix.</p> <p>For users running their own server, the config settings and corresponding query params are:</p> Key Query Param <code>atlas.webapi.graph.start-time</code> <code>s</code> <code>atlas.webapi.graph.end-time</code> <code>e</code> <code>atlas.webapi.graph.timezone</code> <code>tz</code> <code>atlas.webapi.graph.width</code> <code>w</code> <code>atlas.webapi.graph.height</code> <code>h</code> <code>atlas.webapi.graph.palette</code> <code>palette</code>"},{"location":"api/graph/graph/#boolean-flags","title":"Boolean Flags","text":"<p>Flags with a true or false value are specified using <code>1</code> for true and <code>0</code> for false.</p>"},{"location":"api/graph/heatmap/","title":"Heatmap","text":"<p>Atlas primarily supports visualizing data in line charts. As of 1.8, Atlas can also visualize via heatmaps using the <code>:heatmap</code> line style. The graph area is broken up into a series of cells and a count for each cell is incremented when  a measurement falls within the cells boundaries. Colors or shades of colors then fill in cells  based on the final count.</p>"},{"location":"api/graph/heatmap/#percentiles","title":"Percentiles","text":"<p>Heatmaps are particularly useful on top of percentile metrics to analyze the entire measurement range. </p> <p>Note Using the log linear scale will help to highlight clustered regions of measurements via <code>&amp;scale=log-linear</code>. The example also uses data not available in the demo Atlas instance.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,requestLatency,:eq,\n    :percentile-heatmap,\n    \n  &amp;scale=log-linear\n</pre> <p></p>"},{"location":"api/graph/heatmap/#bounds","title":"Bounds","text":"<p>The <code>&amp;heatmap_l=</code> and <code>&amp;heatmap_u</code> parameters can be used to narrow the range of cells  displayed in a heatmap. Heatmap bounds act on the count of measurements in a cell and the palette colors or shades chosen. Depending on the bound limits, some cells may appear empty.</p> No Heatmap BoundsWith Bounds (<code>&amp;heatmap_l=1.2&amp;heatmap_u=1.3</code>) <pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:heatmap\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:heatmap\n</pre>"},{"location":"api/graph/heatmap/#palette","title":"Palette","text":"<p>The palette used for filling heatmap cells can be changed via the <code>&amp;heatmap_palette=</code> parameter. By default, a color is chosen from the global palette (based on whether the heatmap is the  first or a later expression). A gradient is then applied to that color with a lighter gradient representing smaller cell counts and darker representing larger counts.</p> Default PaletteReds Palette (<code>&amp;heatmap_palette=reds</code>) <pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:heatmap\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:heatmap\n</pre>"},{"location":"api/graph/heatmap/#custom-palette","title":"Custom Palette","text":"<p>A custom palette may be provided by listing the hex colors to use in descending order, meaning the color to use for the highest cell counts must appear first.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    :heatmap\n  &amp;heatmap_palette=(,8cd1b9,46adbc,2a91b8,1978b3,335ca9,413e95,361566,)\n</pre> <p></p> <p>For further information, see Custom Color Palettes.</p>"},{"location":"api/graph/heatmap/#order-of-expressions","title":"Order of Expressions","text":"<p>When overlaying expressions with a heatmap and using the default palette, the order of  expressions determines the color gradient used for cells. For example, if the heatmap expression is second in the query, the second palette color will be used as the gradient:</p> Heatmap FirstHeatmap Second <pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:heatmap,\nname,sps,:eq,\n\n</pre><pre>name,sps,:eq,\nname,sps,:eq,\n(,nf.cluster,),:by,\n:heatmap\n</pre>"},{"location":"api/graph/heatmap/#label","title":"Label","text":"<p>The label for the heatmap can be changed via the <code>&amp;heatmap_label=</code> parameter. By default, the label is simply <code>heatmap</code>.</p> <p></p> <pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:heatmap\n</pre>"},{"location":"api/graph/heatmap/#scale","title":"Scale","text":"<p>Similar to axis scales, the scale of the heatmap cell colors (or gradients) can be adjusted using the <code>&amp;heatmap_scale=</code> parameter. By default, the scale is <code>linear</code> though any of the valid scales may be used.</p> LinearLog Linear <pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:heatmap\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:heatmap\n</pre>"},{"location":"api/graph/layout/","title":"Layout","text":"<p>The diagram below shows the parts of an Atlas graph and will be used when describing the behavior for various options.</p> <p></p> <p>The layout for graph images is trying to accomplish two main goals:</p>"},{"location":"api/graph/layout/#usable-canvas-size","title":"Usable Canvas Size","text":"<p>Keep the canvas usable regardless of the number of lines, axes, etc that are competing for space. For example, the canvas area should not become too small due to the number of lines on the chart.</p> Good Layout Poor Layout"},{"location":"api/graph/layout/#canvas-alignment","title":"Canvas Alignment","text":"<p>Make it easy to align the canvas portion of several graphs on an html page. This is important because it makes it easier to find visual correlations between multiple graphs on a dashboard.</p> <p>In particular if arranged in a grid with the image in the top left of each cell, then the canvas should line up vertically for columns:</p> <p></p> <p>And horizontally for rows:</p> <p></p> <p>In the graph layout diagram at the top, this is why variable components such as multi axes, legend entries, and warnings are positioned on either the right side or the bottom of the canvas.</p>"},{"location":"api/graph/layout/#modes","title":"Modes","text":"<p>There are four supported layout modes that can be used with the layout query parameter:</p> <ul> <li><code>canvas</code>: the width or height are for the canvas component within the chart. The actual image size will be calculated based on the number of entries in the legend, number of axes, etc. This is the default behavior.</li> <li><code>image</code>: the width or height are for the final image not including the zoom parameter. To try and adhere to layout goals when using this mode everything below the X-axes will automatically be suppressed. Vertical alignment will still hold as long as all graphs use the same number of Y-axes. Horizontal alignment will still hold as long as all graphs use the same number of X-axes.</li> <li><code>iw</code>: use exact image sizing for the width and canvas sizing for the height.</li> <li><code>ih</code>: use exact image sizing for the height and canvas sizing for the width.</li> </ul>"},{"location":"api/graph/layout/#examples","title":"Examples","text":""},{"location":"api/graph/layout/#canvas","title":"Canvas","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;h=175\n  &amp;layout=canvas\n  &amp;q=\n    name,sps,:eq,\n    :sum,\n    (,nf.cluster,),:by\n  &amp;s=e-1d\n  &amp;tz=UTC\n  &amp;w=400\n</pre>"},{"location":"api/graph/layout/#image","title":"Image","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;h=175\n  &amp;layout=image\n  &amp;q=\n    name,sps,:eq,\n    :sum,\n    (,nf.cluster,),:by\n  &amp;s=e-1d\n  &amp;tz=UTC\n  &amp;w=400\n</pre>"},{"location":"api/graph/layout/#image-width","title":"Image Width","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;h=175\n  &amp;layout=iw\n  &amp;q=\n    name,sps,:eq,\n    :sum,\n    (,nf.cluster,),:by\n  &amp;s=e-1d\n  &amp;tz=UTC\n  &amp;w=400\n</pre>"},{"location":"api/graph/layout/#image-height","title":"Image Height","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;h=175\n  &amp;layout=ih\n  &amp;q=\n    name,sps,:eq,\n    :sum,\n    (,nf.cluster,),:by\n  &amp;s=e-1d\n  &amp;tz=UTC\n  &amp;w=400\n</pre>"},{"location":"api/graph/legends/","title":"Legends","text":"<p>Options for adjusting legend:</p> <ul> <li>Automatic</li> <li>Explicit</li> <li>Variables</li> <li>Disable</li> <li>Disable Stats</li> <li>Sorting</li> </ul>"},{"location":"api/graph/legends/#automatic","title":"Automatic","text":"<p>If no explicit legend is specified, then the system will generate an automatic legend that summarizes the expression. There is no particular guarantee about what it will contain and in some cases it is difficult to generate a usable legend automatically. Example:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    hourOfDay,:time,\n    100,:mul,\n    minuteOfHour,:time,\n    :add\n  &amp;s=e-1w\n</pre> <p></p>"},{"location":"api/graph/legends/#explicit","title":"Explicit","text":"<p>The legend for a line can be explicitly set using the :legend operator.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    hourOfDay,:time,\n    100,:mul,\n    minuteOfHour,:time,\n    :add,\n    time+value,:legend\n  &amp;s=e-1w\n</pre> <p></p>"},{"location":"api/graph/legends/#variables","title":"Variables","text":"<p>Tag keys can be used as variables to plug values into the legend. This is useful when working with group by operations to customize the legend for each output. The variable can be expressed as a <code>$</code> followed by the tag key if it is the only part of the legend:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    $nf.cluster,:legend\n  &amp;s=e-1w\n</pre> <p></p> <p>Or as <code>$(</code> the tag key and a closing <code>)</code> if combined with other text:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    cluster+$(nf.cluster)+sps,:legend\n  &amp;s=e-1w\n</pre> <p></p>"},{"location":"api/graph/legends/#disable","title":"Disable","text":"<p>Legends can be disabled using the <code>no_legend</code> graph parameter.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by\n  &amp;s=e-1w\n</pre> <p></p>"},{"location":"api/graph/legends/#disable-stats","title":"Disable Stats","text":"<p>You can also save veritical space and keep the legend by disabling the summary stats shown in the legend using the <code>no_legend_stats</code> graph parameter.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend_stats=1\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by\n  &amp;s=e-1w\n</pre> <p></p>"},{"location":"api/graph/legends/#sorting","title":"Sorting","text":"<p>By default the legend for an axis will be ordered based on the order of the expressions on the stack. If an expression results in multple lines, i.e. a group by, then they will be sorted by the label.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    120e3,threshold,:legend,\n    name,sps,:eq,\n    (,nf.cluster,),:by\n  &amp;s=e-12h\n</pre> <p></p>"},{"location":"api/graph/legends/#overall","title":"Overall","text":"<p>To sort all lines on a given axis using a different mode use the <code>sort</code> URL parameter.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    120e3,threshold,:legend,\n    name,sps,:eq,\n    (,nf.cluster,),:by\n  &amp;s=e-12h\n  &amp;sort=max\n</pre> <p></p> <p>To change it to descending order use the <code>order</code> parameter, e.g.:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    120e3,threshold,:legend,\n    name,sps,:eq,\n    (,nf.cluster,),:by\n  &amp;s=e-12h\n  &amp;sort=max\n  &amp;order=desc\n</pre> <p></p>"},{"location":"api/graph/legends/#group-by-expression","title":"Group By Expression","text":"<p>If more control is needed, then sorting can be applied to a particular group by expression. This can be useful for things like alerting visualizations where some common lines like the threshold and trigger indicator should be pinned to the top, but it is desirable to sort other results based on a stat like <code>max</code>. For example:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    120e3,threshold,:legend,\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    :dup,\n    :max,\n    120e3,:gt,\n    30,:alpha,\n    :vspan,\n    trigger,:legend,\n    :swap,\n    max,:sort,\n    desc,:order,\n    $nf.cluster,:legend\n  &amp;s=e-12h\n</pre> <p></p>"},{"location":"api/graph/legends/#sorting-modes","title":"Sorting Modes","text":"<ul> <li><code>legend</code>: alphabetically based on the label used in the legend. This is the default.</li> <li><code>min</code>: using the minimum value shown the legend stats.</li> <li><code>max</code>: using the maximum value shown the legend stats.</li> <li><code>avg</code>: using the average value shown the legend stats.</li> <li><code>count</code>: using the count value shown the legend stats.</li> <li><code>total</code>: using the total value shown the legend stats.</li> <li><code>last</code>: using the last value shown the legend stats.</li> </ul>"},{"location":"api/graph/legends/#sorting-order","title":"Sorting Order","text":"<ul> <li><code>asc</code>: use ascending order. This is the default.</li> <li><code>desc</code>: used descending order.</li> </ul>"},{"location":"api/graph/line-attributes/","title":"Line Attributes","text":"<p>In addition to the line style and legend the following attributes can be adjusted:</p> <ul> <li>Color</li> <li>Transparency</li> <li>Line Width</li> </ul>"},{"location":"api/graph/line-attributes/#color","title":"Color","text":"<p>By default the color will come from the palette that is in use. However the color for a line can also be set explicitly using the :color operator:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,sps,:eq,\n    f00,:color\n  &amp;s=e-1w\n</pre> <p></p> <p>Note, that for a group by all results will get the same attributes, so in this case all would end up being the same color:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    f00,:color\n  &amp;s=e-1w\n</pre> <p></p>"},{"location":"api/graph/line-attributes/#transparency","title":"Transparency","text":"<p>The transparency of a line can be set using the :alpha operator or by explicitly setting the alpha channel as part of the color.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,sps,:eq,\n    :dup,\n    6h,:offset,\n    :area,\n    40,:alpha\n  &amp;s=e-2d\n</pre> <p></p> <p>Setting the alpha explicitly as part of the color:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,sps,:eq,\n    :dup,\n    6h,:offset,\n    :area,\n    40ff0000,:color\n  &amp;s=e-2d\n</pre> <p></p>"},{"location":"api/graph/line-attributes/#line-width","title":"Line Width","text":"<p>Adjust the stroke width used for a line:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,sps,:eq,\n    :dup,\n    6h,:offset,\n    3,:lw\n  &amp;s=e-1w\n</pre> <p></p>"},{"location":"api/graph/line-styles/","title":"Line Styles","text":"<p>There are four line styles available:</p> <ul> <li>Line</li> <li>Area</li> <li>Stack</li> <li>Vertical Span</li> <li>Heatmap</li> </ul> <p>Multiple styles can be used in the same chart or combined with other operations.</p> <ul> <li>Stacked Percentage</li> <li>Combinations</li> <li>Layering</li> </ul>"},{"location":"api/graph/line-styles/#line","title":"Line","text":"<p>The default style is line.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    :line\n  &amp;s=e-1w\n</pre> <p></p>"},{"location":"api/graph/line-styles/#area","title":"Area","text":"<p>Area will fill the space between the line and 0 on the Y-axis. The alpha setting is just used to help visualize the overlap.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    :area,\n    40,:alpha\n  &amp;s=e-1w\n</pre> <p></p> <p>Similarly for negative values:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    :neg,\n    :area,\n    40,:alpha\n  &amp;s=e-1w\n</pre> <p></p>"},{"location":"api/graph/line-styles/#stack","title":"Stack","text":"<p>Stack is similar to area, but will stack the filled areas on top of each other.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    :stack\n  &amp;s=e-1w\n</pre> <p></p> <p>Similarly for negative values:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    :neg,\n    :stack\n  &amp;s=e-1w\n</pre> <p></p>"},{"location":"api/graph/line-styles/#stacked-percentage","title":"Stacked Percentage","text":"<p>The stack style can be combined with the :pct operator to get a stacked percentage chart for a group by:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    :pct,\n    :stack\n  &amp;s=e-1w\n</pre> <p></p>"},{"location":"api/graph/line-styles/#heatmap","title":"Heatmap","text":"<p>Since 1.8.</p> <p>Plotting many time series with a heat map can be useful for identifying concentrations of measurements where individual lines may produce too much noise. </p> <p>See Heatmap for more details.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    :heatmap\n</pre> <p></p>"},{"location":"api/graph/line-styles/#vertical-span","title":"Vertical Span","text":"<p>The vertical span style converts non-zero to spans. This is often used to highlight some portion of another line.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,sps,:eq,\n    50e3,:gt,\n    :vspan\n  &amp;s=e-1w\n</pre> <p></p>"},{"location":"api/graph/line-styles/#combinations","title":"Combinations","text":"<p>Line styles can be combined, e.g., to highlight the portion of a line that is above a threshold:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;no_legend=1\n  &amp;q=\n    name,sps,:eq,\n    :dup,\n    5003,:gt,\n    :vspan,\n    40,:alpha,\n    50e3\n  &amp;s=e-1w\n</pre> <p></p>"},{"location":"api/graph/line-styles/#layering","title":"Layering","text":"<p>The z-order is based on the order of the expression on the stack.</p> <pre>/api/v1/graph?\n  e=2015-03-10T13:13\n  &amp;no_legend=1\n  &amp;q=\n    t,name,sps,:eq,\n    :sum,\n    :set,\n    t,:get,\n    :stack,\n    t,:get,\n    1.1,:mul,\n    6h,:offset,\n    t,:get,\n    4,:div,\n    :stack\n  &amp;s=e-2d\n</pre> <p></p>"},{"location":"api/graph/multi-y/","title":"Multi Y Axis","text":"<p>Examples for using multiple Y-axes:</p> <ul> <li>Explicit</li> <li>Explicit Bounds</li> <li>Axis Per Line</li> <li>Palettes</li> </ul>"},{"location":"api/graph/multi-y/#explicit","title":"Explicit","text":"<p>By default all lines will go on axis <code>0</code>, the one on the left side. A different axis can be specified using the :axis operation.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    42,1,:axis\n</pre> <p></p>"},{"location":"api/graph/multi-y/#explicit-bounds","title":"Explicit Bounds","text":"<p>By default all axes will pick up axis settings with no qualifier:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;l=0\n  &amp;q=\n    name,sps,:eq,\n    42,1,:axis\n</pre> <p></p> <p>Bounds and other axis settings can be set per axis, e.g., this graph moves the constant line for <code>42</code> to a separate axis and sets the lower bound to <code>0</code> via the <code>&amp;l.1=0</code> parameter. This would  work as well for <code>&amp;u.1=100e3</code>. Append the index after the <code>l.</code> or <code>u.</code> :</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;l.1=0\n  &amp;q=\n    name,sps,:eq,\n    42,1,:axis\n</pre> <p></p>"},{"location":"api/graph/multi-y/#axis-per-line","title":"Axis Per Line","text":"<p>There is a convenience operation to plot each line on a separate axis.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;axis_per_line=1\n  &amp;q=\n    name,sps,:eq,\n    nf.cluster,nccp-p,:re,\n    :and,\n    (,nf.cluster,),:by\n</pre> <p></p> <p>If there are too many lines and it would be over the max Y-axis limit, then a warning will be shown:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;axis_per_line=1\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by\n</pre> <p></p>"},{"location":"api/graph/multi-y/#palettes","title":"Palettes","text":"<p>The color of the first line on an axis will get used as the color of the axis. The intention is to make it easy to understand which axis a line is associated with and in an image dynamic clues like hover cannot be used. Generally it is recommended to only have one line per axis when using multi-Y. Example:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;l=01\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    minuteOfHour,:time,\n    1,:axis\n</pre> <p></p> <p>Though we recommend not using more than one line per axis with multi-Y, a color palette can be specified for a specific axis. This can be used to select shades of a color for an axis so it is still easy to visually associate which axis a line belongs to:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;l=01\n  &amp;palette.0=reds\n  &amp;palette.1=blues\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    :stack,\n    minuteOfHour,:time,\n    1,:axis\n</pre> <p></p>"},{"location":"api/graph/outputs/","title":"Output Formats","text":"<p>The following output formats are supported by default for graphing:</p> <ul> <li>png</li> <li>csv</li> <li>txt</li> <li>json</li> <li>std.json</li> <li>stats.json</li> </ul>"},{"location":"api/graph/outputs/#png","title":"png","text":"<p>This is the default and creates a PNG image for the graph. The mime type is <code>image/png</code>.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;format=png\n  &amp;q=\n    hourOfDay,:time,\n    minuteOfHour,:time,\n    NaN\n  &amp;s=e-3m\n  &amp;tz=UTC\n</pre> <p></p>"},{"location":"api/graph/outputs/#csv","title":"csv","text":"<p>Comma separated value output. The mime type is <code>text/csv</code>.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;format=csv\n  &amp;q=\n    hourOfDay,:time,\n    minuteOfHour,:time,\n    NaN\n  &amp;s=e-5m\n  &amp;tz=UTC\n</pre> <pre><code>\"timestamp\",\"hourOfDay\",\"minuteOfHour\",\"NaN\"\n2012-01-01T08:56:00Z,8.000000,56.000000,NaN\n2012-01-01T08:57:00Z,8.000000,57.000000,NaN\n2012-01-01T08:58:00Z,8.000000,58.000000,NaN\n2012-01-01T08:59:00Z,8.000000,59.000000,NaN\n2012-01-01T09:00:00Z,9.000000,0.000000,NaN\n</code></pre>"},{"location":"api/graph/outputs/#txt","title":"txt","text":"<p>Same as csv except that the separator is a tab character instead of a comma. The mime type will be <code>text/plain</code> so it is more likely to render directly in the browser rather than trigger a download.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;format=txt\n  &amp;q=\n    hourOfDay,:time,\n    minuteOfHour,:time,\n    NaN\n  &amp;s=e-5m\n  &amp;tz=UTC\n</pre> <pre><code>\"timestamp\" \"hourOfDay\" \"minuteOfHour\"  \"NaN\"\n2012-01-01T08:56:00Z    8.000000    56.000000   NaN\n2012-01-01T08:57:00Z    8.000000    57.000000   NaN\n2012-01-01T08:58:00Z    8.000000    58.000000   NaN\n2012-01-01T08:59:00Z    8.000000    59.000000   NaN\n2012-01-01T09:00:00Z    9.000000    0.000000    NaN\n</code></pre>"},{"location":"api/graph/outputs/#json","title":"json","text":"<p>JSON output representing the data. Note that it is not standard json as numeric values like <code>NaN</code> will not get quoted.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;format=json\n  &amp;q=\n    hourOfDay,:time,\n    minuteOfHour,:time,\n    NaN\n  &amp;s=e-5m\n  &amp;tz=UTC\n</pre> <pre><code>{\n  \"start\" : 1325408160000,\n  \"step\" : 60000,\n  \"legend\" : [ \"hourOfDay\", \"minuteOfHour\", \"NaN\" ],\n  \"metrics\" : [ {\n    \"atlas.offset\" : \"0w\",\n    \"name\" : \"hourOfDay\"\n  }, {\n    \"atlas.offset\" : \"0w\",\n    \"name\" : \"minuteOfHour\"\n  }, {\n    \"atlas.offset\" : \"0w\",\n    \"name\" : \"NaN\"\n  } ],\n  \"values\" : [ [ 8.0, 56.0, NaN ], [ 8.0, 57.0, NaN ], [ 8.0, 58.0, NaN ], [ 8.0, 59.0, NaN ], [ 9.0, 0.0, NaN ] ],\n  \"notices\" : [ ]\n}\n</code></pre>"},{"location":"api/graph/outputs/#stdjson","title":"std.json","text":"<p>Same as json except that numeric values which are not recognized by standard json will be quoted. The mime type is <code>application/json</code>.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;format=std.json\n  &amp;q=\n    hourOfDay,:time,\n    minuteOfHour,:time,\n    NaN\n  &amp;s=e-5m\n  &amp;tz=UTC\n</pre> <pre><code>{\n  \"start\" : 1325408160000,\n  \"step\" : 60000,\n  \"legend\" : [ \"hourOfDay\", \"minuteOfHour\", \"NaN\" ],\n  \"metrics\" : [ {\n    \"atlas.offset\" : \"0w\",\n    \"name\" : \"hourOfDay\"\n  }, {\n    \"atlas.offset\" : \"0w\",\n    \"name\" : \"minuteOfHour\"\n  }, {\n    \"atlas.offset\" : \"0w\",\n    \"name\" : \"NaN\"\n  } ],\n  \"values\" : [ [ 8.0, 56.0, \"NaN\" ], [ 8.0, 57.0, \"NaN\" ], [ 8.0, 58.0, \"NaN\" ], [ 8.0, 59.0, \"NaN\" ], [ 9.0, 0.0, \"NaN\" ] ],\n  \"notices\" : [ ]\n}\n</code></pre>"},{"location":"api/graph/outputs/#statsjson","title":"stats.json","text":"<p>Provides the summary stats for each line, but not all of the data points. The mime type is <code>application/json</code>.</p> <pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;format=stats.json\n  &amp;q=\n    hourOfDay,:time,\n    minuteOfHour,:time,\n    NaN\n  &amp;s=e-5m\n  &amp;tz=UTC\n</pre> <pre><code>{\n  \"start\" : 1325408160000,\n  \"end\" : 1325408460000,\n  \"step\" : 60000,\n  \"legend\" : [ \"hourOfDay\", \"minuteOfHour\", \"NaN\" ],\n  \"metrics\" : [ {\n    \"atlas.offset\" : \"0w\",\n    \"name\" : \"hourOfDay\"\n  }, {\n    \"atlas.offset\" : \"0w\",\n    \"name\" : \"minuteOfHour\"\n  }, {\n    \"atlas.offset\" : \"0w\",\n    \"name\" : \"NaN\"\n  } ],\n  \"stats\" : [ {\n    \"count\" : 5,\n    \"avg\" : 8.2,\n    \"total\" : 41.0,\n    \"max\" : 9.0,\n    \"min\" : 8.0,\n    \"last\" : 9.0\n  }, {\n    \"count\" : 5,\n    \"avg\" : 46.0,\n    \"total\" : 230.0,\n    \"max\" : 59.0,\n    \"min\" : 0.0,\n    \"last\" : 0.0\n  }, {\n    \"count\" : 0,\n    \"avg\" : NaN,\n    \"total\" : NaN,\n    \"max\" : NaN,\n    \"min\" : NaN,\n    \"last\" : NaN\n  } ],\n  \"notices\" : [ ]\n}\n</code></pre>"},{"location":"api/graph/tick/","title":"Tick Labels","text":"<p>The following tick (Y axis numeric labels) modes are supported:</p> <ul> <li>decimal</li> <li>binary</li> <li>duration</li> <li>off</li> </ul>"},{"location":"api/graph/tick/#decimal","title":"Decimal","text":"<p>This is the default mode. Y-axis tick labels will be formatted using the metric prefix to indicate the magnitude for values that are greater than one thousand or less than one.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by\n  &amp;s=e-1w\n  &amp;tick_labels=decimal\n</pre> <p></p> <p>Really large values will fallback to scientific notation, e.g.:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by,\n    1e180,:mul\n  &amp;s=e-1w\n  &amp;tick_labels=decimal\n</pre> <p></p>"},{"location":"api/graph/tick/#binary","title":"Binary","text":"<p>For values such as memory sizes it is sometimes more convenient to view the label using a power of 1024 rather than a power of 1000. If the tick label mode is set to <code>binary</code>, then the IEC binary prefix will be used.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by\n  &amp;s=e-1w\n  &amp;tick_labels=binary\n</pre> <p></p>"},{"location":"api/graph/tick/#duration","title":"Duration","text":"<p>Since 1.7.1.</p> <p>Useful for timers or percentiles that measure latency, provides ticks with time unit suffix.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,requestLatency,:eq,\n    nf.node,wii-node,:eq,\n    :and\n  &amp;tick_labels=duration\n</pre> <p></p>"},{"location":"api/graph/tick/#off","title":"Off","text":"<p>For presentations or sharing it is sometimes useful to anonymize the chart. One way of doing that is to disable the Y-axis labels by setting the tick label mode to <code>off</code>.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    (,nf.cluster,),:by\n  &amp;s=e-1w\n  &amp;tick_labels=off\n</pre> <p></p>"},{"location":"api/graph/tick/#offset-labels","title":"Offset Labels","text":"<p>In situations where a graph has very small changes in value that generate a significant number of digits per tick, ticks may be labeled with offsets in order to fit the labels in the layout. A base value is displayed at the bottom of the axis and positive or negative offsets from the base displayed next to the ticks. </p> <p>For example, if the amount of disk space used varies by 1 byte occasionally, the ticks will be labeled by in increments of <code>+1.0</code>.</p> <p></p> <p>Note</p> <p>It is possible for queries spanning different data sources to display offset labels due to differing schemes used to encode floating point values.</p> <p>If offsets are not desirable, try adjusting the y axis bounds. </p>"},{"location":"api/graph/time-shift/","title":"Time Shift","text":"<p>A common use-case is to compare a given line with a shifted line to compare week-over-week or day-over-day.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    nf.cluster,nccp-silverlight,:eq,\n    :and,\n    :sum,\n    :dup,\n    1w,:offset\n</pre> <p></p> <p>The <code>$(atlas.offset)</code> variable can be used to show the offset in a custom legend:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq,\n    nf.cluster,nccp-silverlight,:eq,\n    :and,\n    :sum,\n    :dup,\n    1w,:offset,\n    :list,\n    (,$nf.cluster+(offset=$atlas.offset),:legend,\n    ),:each\n</pre> <p></p>"},{"location":"api/graph/time-zone/","title":"Time Zones","text":"<p>Examples for specifying the time zone:</p> <ul> <li>Single Zone</li> <li>Multi Zone</li> <li>Daylight Savings Time</li> </ul>"},{"location":"api/graph/time-zone/#single-zone","title":"Single Zone","text":"<p>Most graphs will only show a single time zone. By default the zone is <code>US/Pacific</code>. To set to another zone such as <code>UTC</code> use the <code>tz</code> query parameter:</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq\n  &amp;tz=UTC\n</pre> <p></p>"},{"location":"api/graph/time-zone/#multi-zone","title":"Multi Zone","text":"<p>The <code>tz</code> parameter can be specified multiple times in which case one X-axis will be shown per zone. Start and end times will be based on the first time zone listed.</p> <pre>/api/v1/graph?\n  e=2012-01-01T00:00\n  &amp;q=\n    name,sps,:eq\n  &amp;s=e-2d\n  &amp;tz=US/Eastern\n  &amp;tz=US/Pacific\n  &amp;tz=UTC\n</pre> <p></p>"},{"location":"api/graph/time-zone/#daylight-savings-time","title":"Daylight Savings Time","text":"<p>If using a time zone that changes for daylight savings time, then you will see duplicate or missing hours on the time axis labels during the transition period. For example, a duplicate hour:</p> <pre>/api/v1/graph?\n  e=2015-11-01T08:00\n  &amp;q=\n    name,sps,:eq\n  &amp;s=e-12h\n  &amp;tz=US/Pacific\n  &amp;tz=UTC\n</pre> <p></p> <p>A missing hour:</p> <pre>/api/v1/graph?\n  e=2015-03-08T08:00\n  &amp;q=\n    name,sps,:eq\n  &amp;s=e-12h\n  &amp;tz=US/Pacific\n  &amp;tz=UTC\n</pre> <p></p> <p>If looking at a longer time frame, then it can also throw off the alignment so ticks will not be on significant time boundaries, e.g.:</p> <pre>/api/v1/graph?\n  e=2015-11-05T08:00\n  &amp;q=\n    name,sps,:eq\n  &amp;s=e-1w\n  &amp;tz=US/Pacific\n  &amp;tz=UTC\n</pre> <p></p>"},{"location":"api/graph/vision/","title":"Color Blindness","text":"<p>The vision parameter can be used to simulate different types of color blindness. Permitted values are:</p> <ul> <li>normal</li> <li>protanopia</li> <li>protanomaly</li> <li>deuteranopia</li> <li>deuteranomaly</li> <li>tritanopia</li> <li>tritanomaly</li> <li>achromatopsia</li> <li>achromatomaly</li> </ul>"},{"location":"api/graph/vision/#normal","title":"Normal","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;q=\n    1,1,1,1,1,1,1\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;vision=normal\n</pre>"},{"location":"api/graph/vision/#protanopia","title":"Protanopia","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;q=\n    1,1,1,1,1,1,1\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;vision=protanopia\n</pre>"},{"location":"api/graph/vision/#protanomaly","title":"Protanomaly","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;q=\n    1,1,1,1,1,1,1\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;vision=protanomaly\n</pre>"},{"location":"api/graph/vision/#deuteranopia","title":"Deuteranopia","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;q=\n    1,1,1,1,1,1,1\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;vision=deuteranopia\n</pre>"},{"location":"api/graph/vision/#deuteranomaly","title":"Deuteranomaly","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;q=\n    1,1,1,1,1,1,1\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;vision=deuteranomaly\n</pre>"},{"location":"api/graph/vision/#tritanopia","title":"Tritanopia","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;q=\n    1,1,1,1,1,1,1\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;vision=tritanopia\n</pre>"},{"location":"api/graph/vision/#tritanomaly","title":"Tritanomaly","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;q=\n    1,1,1,1,1,1,1\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;vision=tritanomaly\n</pre>"},{"location":"api/graph/vision/#achromatopsia","title":"Achromatopsia","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;q=\n    1,1,1,1,1,1,1\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;vision=achromatopsia\n</pre>"},{"location":"api/graph/vision/#achromatomaly","title":"Achromatomaly","text":"<pre>/api/v1/graph?\n  e=2012-01-01T09:00\n  &amp;no_legend=1\n  &amp;q=\n    1,1,1,1,1,1,1\n  &amp;stack=1\n  &amp;tz=UTC\n  &amp;vision=achromatomaly\n</pre>"},{"location":"asl/","title":"Index","text":"<p>The <code>asl-finetuning.tsv</code> file is a collection of ChatGPT training data manually extracted from the Markdown files in this section of the repo, that can be converted to a format suitable for helping ChatGPT learn about Atlas Stack Language.</p> <p>See the Fine-tuning section of the OpenAI documentation for more details.</p>"},{"location":"asl/alerting-expressions/","title":"Alerting Expressions","text":"<p>The stack language provides some basic techniques to convert an input line into a set of signals that can be used to trigger and visualize alert conditions. This section assumes a familiarity with the stack language and the alerting philosophy.</p>"},{"location":"asl/alerting-expressions/#signal-line","title":"Signal Line","text":"<p>A signal line is a time series that indicates whether or not a condition is true for a particular interval. They are modelled by having zero indicate false and non-zero, typically 1, indicating true. Alerting expressions map some input time series to a set of signal lines that indicate true when in a triggering state.</p>"},{"location":"asl/alerting-expressions/#threshold-alerts","title":"Threshold Alerts","text":"<p>To start we need an input metric. For this example the input will be a sample metric showing high CPU usage for a period:</p> <p></p> <pre>nf.app,alerttest,:eq,\nname,ssCpuUser,:eq,\n:and,\n:sum\n</pre> <p>Lets say we want to trigger an alert when the CPU usage goes above 80%. To do that simply use the :gt operator and append <code>80,:gt</code> to the query:</p> <p></p> <p>The result is a signal line that is non-zero, typically 1, when in a triggering state and zero when everything is fine.</p>"},{"location":"asl/alerting-expressions/#dampening","title":"Dampening","text":"<p>Our threshold alert above will trigger if the CPU usage is ever recorded to be above the threshold. Alert conditions are often combined with a check for the number of occurrences. This is done by using the :rolling-count operator to get a line showing how many times the input signal has been true withing a specified window and then applying a second threshold to the rolling count.</p> InputRolling CountDampened Signal <pre>nf.app,alerttest,:eq,\nname,ssCpuUser,:eq,\n:and,\n:sum,\n80,:gt\n</pre><pre>nf.app,alerttest,:eq,\nname,ssCpuUser,:eq,\n:and,\n:sum,\n80,:gt,\n5,:rolling-count\n</pre><pre>nf.app,alerttest,:eq,\nname,ssCpuUser,:eq,\n:and,\n:sum,\n80,:gt,\n5,:rolling-count,\n4,:gt\n</pre>"},{"location":"asl/alerting-expressions/#visualization","title":"Visualization","text":"<p>A signal line is useful to tell whether or not something is in a triggered state, but can be difficult for a person to follow. Alert expressions can be visualized by showing the input, threshold, and triggering state on the same graph.</p> <p></p> <pre>nf.app,alerttest,:eq,\nname,ssCpuUser,:eq,\n:and,\n:sum,\n80,:2over,\n:gt,\n:vspan,\n40,:alpha,\ntriggered,:legend,\n:rot,\ninput,:legend,\n:rot,\nthreshold,:legend,\n:rot\n</pre>"},{"location":"asl/alerting-expressions/#summary","title":"Summary","text":"<p>You should now know the basics of crafting an alert expression using the stack language. Other topics that may be of interest:</p> <ul> <li>Alerting Philosophy: overview of best practices associated with alerts.</li> <li>Stack Language Tutorial: comprehensive list of available operators.</li> <li>DES: double exponential smoothing. A technique for detecting anomalies in normally clean   input signals where a precise threshold is unknown. For example, the requests per second hitting   a service.</li> </ul>"},{"location":"asl/alerting-philosophy/","title":"Alerting Philosophy","text":"<p>It is recommended for all alerts to adhere to the follow guidelines:</p> <ol> <li>Keep conditions simple.</li> <li>Alerts should be actionable.</li> <li>Check for measured failure on critical paths rather than a lack of success.</li> <li>Alerts should not have special cases for routine maintenance.</li> <li>Consider how the alert check can fail.</li> </ol>"},{"location":"asl/alerting-philosophy/#keep-it-simple","title":"Keep It Simple","text":"<p>When an alert triggers, it should be easy to understand why. Similarly, if an alert  doesn't fire, then it should be easy to check and see what happened. The more  complicated an alert condition becomes, the harder it is to understand and debug.</p> <p>It is recommended to keep alert rules as a simple expression with a threshold and  number of occurrences. An example of this is the following rule:</p> <pre><code>CPU Usage &gt; 80% for at least 5 minutes\n</code></pre> <p>Multiple signals should only be combined if it improves the effectiveness of the  alert. For example, what is an appropriate threshold for the number of requests  that have error responses? What happens to that threshold if your cluster auto-scales? It is more effective to define the threshold as a percentage of total requests:</p> <pre><code>(Num Errors / Num Total) &gt; 0.01 for at least 5 minutes\n</code></pre> <p>In some cases, a low volume can make the percentages less meaningful and result  in false positives. For example, if your daily traffic pattern follows a sine curve, then the troughs may not represent a meaningful error percentage. Another example  might be during failover exercises, if traffic has been failed over to another  cluster. One way to compensate for this is to check the failure rate and overall volume:</p> <pre><code>Percentage of Failures &gt; X AND Volume &gt; Y\n</code></pre> <p>As a general rule, bias towards simplicity. If you are creating more complex  expressions, then stop and think about why that complexity is needed. Are there  other signals available that are easier to use? Can the application be changed  so that it reports metrics which make it easier to diagnose?</p>"},{"location":"asl/alerting-philosophy/#actionable-alerts","title":"Actionable Alerts","text":"<p>If an alert fires and sends a notification to users, someone should be motivated to  investigate the problem. Alerts that are noisy or not actionable train people to  ignore or filter out alert notifications.</p> <p>For cases where the response to an alert can be automated, such as terminating a bad  instance, it shouldn't send out a notification unless there is a failure to perform  the action. If you want a summary of cluster health, then use dashboards or  reporting tools for this function; don't attempt to do this via alert notifications.</p> <p>Alerts should check something important. To setup effective alerts, you need to  understand the application and have ways to detect failures for critical functionality.  Avoid general system-type alerts that won't be investigated. For example, should  you alert on high CPU usage? If you have done squeeze testing and you have  information to indicate how CPU usage impacts the application, then it can be  useful and it will provide a way to know a problem is coming before it impacts  clients of the service. If you do not have this knowledge, then your alert may be  under-tuned, leading to noisy notifications that may be ignored.</p>"},{"location":"asl/alerting-philosophy/#check-for-measured-failure","title":"Check for Measured Failure","text":"<p>It is better to check for failures rather than trying to trigger based on an  absence of information or a reduction in the amount of success.</p>"},{"location":"asl/alerting-philosophy/#absence-of-information","title":"Absence of Information","text":"<p>A typical example of this is a process that runs over a longer time period. For  example, suppose we have an application that updates a metadata cache once per day  and it takes an hour to refresh. It is not recommended to send an event on refresh  success and then configure alerts based on the absence of the success event. Design  the signals so you have a clear way to understand what error conditions may be  occurring on and then alert if there is a problem.</p> <p>In this example, a better design would use a gauge that reports the loading time  and a gauge that reports the age of the cache.  You can then add alerts when the  gauges for these error conditions exceed unacceptable thresholds.</p>"},{"location":"asl/alerting-philosophy/#reduction-in-success","title":"Reduction in Success","text":"<p>Let's say we have a server that is taking traffic and we want to know if users  are experiencing problems.  How should we go about this? It is often tempting  to look for things like a drop in the number of successful requests, because  this can be a generic catch-all for many types of problems.</p> <p>However, alerts of this sort are inherently noisy. How do you know what the  number of requests should be? While there are various schemes for trying to  predict the behavior, you will spend a lot of time tuning alerts of this nature  to get them to the point where they are not too noisy, but they still catch real  issues. Further, these schemes cannot differentiate between problems for the  service and unrelated drops such as a client having problems and failing to make  the request in the first place.</p> <p>If you're not going to investigate these alerts when they fire or invest in  tuning and maintaining them, just avoid this type of alert altogether.</p> <p>A better approach is to alert on the number of failures you are seeing from a  service. Thresholds can often be determined automatically by looking at the  percent of all requests that are failures. For middle tier services, it is also  likely that data from the clients can be used to see a percentage of failure  from a client perspective instead of, or in addition to, the server side view.</p>"},{"location":"asl/alerting-philosophy/#avoid-special-cases","title":"Avoid Special Cases","text":"<p>Alerts shouldn't have to be tuned or suppressed during regular maintenance such  as replacing instance or doing deployments. As a simple example, consider an  alert on the rate of failures. The general assumption would be that a deployment  should not be noticed by clients and therefore the alert is still relevant. Alerts  that are actionable and look for measured failure tend to work well. If a new  instance is coming up, a lack of activity will mean a lack of failures until  traffic is being received. At that time if there are failures they should be noticed.</p>"},{"location":"asl/alerting-philosophy/#startup-behavior","title":"Startup Behavior","text":"<p>What about different behavior during startup? Consider some examples for an  application that has a long initialization time (~20 minutes) before it can  take traffic:</p> <ul> <li>Discovery service state during initialization.</li> <li>Healthcheck failures during initialization.</li> <li>Performance may be different while starting. CPU usage is high while    initializing but stabilizes and remains low during normal operation.</li> </ul> <p>For a discovery service like Eureka, the  duration of the startup time shouldn't be an issue because the state clearly  indicates if it is STARTING vs DOWN.</p> <p>If the healthcheck is used for a load balancer, then the decision to send traffic  to instances should be fairly sensitive in order to minimize the impact to users.  The bigger concern is the number of occurrences of healthcheck failures in a  row, which can trigger automated actions like terminating an instance. When  evaluating healthcheck failures, there are two distinct conditions to evaluate:  non-200 responses and connection timeouts.</p> <p>The healthcheck logic should be tied to the Eureka heartbeat so that if the  healthcheck is failing due to a non-200 response, the discovery state will be  DOWN after initialization is complete. For the first condition, the alert  should check for the number of occurrence of the DOWN state in the discovery  service which will not trigger for the STARTING state used during application  initialization.</p> <p>For the second condition, you would need to check for a disparity between the  published discovery state and the healthcheck state:</p> <pre><code>(DiscoveryStatus is UP) AND (Healthcheck != 200) for N minutes\n</code></pre> <p>Note, unless you really need to do this it is probably better to just look at  the healthcheck and have the num occurrences set to be longer than the typical  startup time.</p> <p>For the CPU example, first reconsider whether general system check alerts are  actually useful. Is it going to help you catch a real problem and be investigated  when it triggers? If not, don't setup an alert on CPU and rely on alerts that  check for failures on the critical path.</p> <p>If it is useful and you have squeeze testing results or other information so  you know when a proxy metric like CPU actually indicates a problem, then you can configure it restricted with some signal that indicates the status. However, keep  in mind that not all systems will allow complex expressions. For example, if  you are auto-scaling will you be able to send the data such that it doesn't  incorrectly skew the alarm? The more signals that are combined the harder it  is to understand the alert and the more likely it is to fail in unexpected ways.  Before adding more layers of duct tape think hard about the application and if  you can change it to be easier to monitor and diagnose.</p>"},{"location":"asl/alerting-philosophy/#deployments","title":"Deployments","text":"<p>At Netflix, a common deployment model is red/black. In this model, a new  auto-scaling group the same size as the existing one will be created, traffic  will transition over, and eventually the old auto-scaling group (ASG) will be  deleted.  This can create false alarms if you haven't thought about the signals being used to fire alerts.</p> <p>The most common alerting problem that occurs during deployments is related the use of averages. For example, the average request rate will drop in half if a  new ASG comes up and you are aggregating across a cluster consisting of both  old and new ASGs. If you follow the advice given earlier about crafting alerts  based on a percentage of errors reported by clients of the application, then  aggregating across clusters by sum usually won't be a problem. If the  deployment is going well, then the overall failure rate seen by clients shouldn't  be impacted.</p> <p>Another example of a deployment alerting problem is latency measurements.  How can you tell the average latency across a cluster composed of new and old  ASGs? Rather than trying to special case or exclude the new group of instances,  you should define the alert signal based on the actual activity seen. If  there is no activity within an ASG, then it will not impact the signal.</p> <p>Metrics libraries like Spectator send both a totalTime and count measurement  separately to the backend. This allows the average to be computed using a simple  sum aggregate with division:</p> <pre><code>Sum(totalTime per instance in cluster) / Sum(count per instance in cluster)\n</code></pre> <p>This calculation demonstrates how instances that are not receiving traffic will  not contribute anything to the sums.</p>"},{"location":"asl/alerting-philosophy/#think-about-failure","title":"Think About Failure","text":"<p>An effective alert needs to be able to fire when there is a problem. However,  when problems occur, it is possible that the problem will also impact the underlying  data or mechanisms used to detect issues for the alert. It is worthwhile to  spend time thinking about the ways in which your alerts can fail to detect events.</p>"},{"location":"asl/alerting-philosophy/#how-can-signals-fail","title":"How Can Signals Fail?","text":"<p>The simplest area to think about is what is collecting and reporting the data.  For example, if data is being reported by the plugin running in the application,  then it won't work if the application crashes or cannot start. It is recommended  to have some basic alerts using a data pipeline that will fail independently  from the application. At Netflix, this typically involves checking the following  conditions:</p> <ul> <li>The healthcheck is responding with 200. This signal indicates that a remote    system was able to connect and query the application healthcheck. So the    application is running and inbound traffic made it in.</li> <li>The application is registered with Eureka. Eureka uses a heartbeat mechanism,    so checking the registration tells you the application is running and it is able    to successfully send the heartbeat request.</li> </ul> <p>The metric data for those signals comes from a separate poller application. If  these succeed, then the application should be healthy enough that alerts triggered  from data local to the instance should be working.</p>"},{"location":"asl/alerting-philosophy/#alerting-scopes","title":"Alerting Scopes","text":"<p>At Netflix, alert expressions for Atlas can be checked in three places:</p> <ul> <li>Backend. Alerts checked against the main backend server.</li> <li>Plugin. Alerts are checked by the plugin running on the instance.</li> <li>Poller. Alerts are checked by a poller service that collects data about instances.</li> </ul> <p>In practice, for a given application, the alerting scopes look like:</p> <p></p> <p>Alerting scopes can be used to provide some level of redundancy with different  failure modes. For example, the failure rate could be checked against the server  stats and the client stats. Further, it is recommended to check alerts as close as  possible to where the data is initially measured and collected. In other words, it  is better to check the alerts on the plugin or poller rather than against the backend.  The advantages of doing this are:</p> <ul> <li>Lower mean-time to detection (MTTD). Data going to the backend server has to be    handled by several layers, which need to allow time for data from all nodes to arrive,    time to index, etc. Alerts checked locally using the plugin or poller will get checked    as data is being published and so they can trigger at the same time that data would    hit the first step in the backend data pipeline.</li> <li>More robust to failure. When there are problems with the monitoring backends,    server side alerts won't work or may have incorrect or partial data. Alerts checked    locally on the plugin are immune to all problems off the instance other than being    able to forward to the alert server. If the Atlas plugin or the instance running it    are having issues, then it is likely that problems for the local alert check would    also impact publishing, so server side alerts are not likely to provide a better view.    Also, keep in mind that for most middle-tier services, the alert can be checked on    the instances that call the service and thus can still fire if the instance has    crashed. High-level instance health can be verified by an alert checked on the poller.</li> <li>Scales better as the amount of data and number of alerts increases. Many alerts,    in particular if checked per node, require expensive queries to run on the backends.    By checking alert using the plugin, the computation is spread out so each node is    checking the alerts for that instance.</li> </ul> <p>So why not check all alerts on the client or poller? The primary disadvantages:</p> <ul> <li>Client and poller scopes can only use data that is available at that location. For a    client, that means only the data that is reported by the plugin on that instance. For    the poller, it means only data about health checks, discovery, and system stats from SNMP.</li> <li>Data cannot be aggregated across nodes for the cluster. This can make it harder    to do things like outlier detection using a cluster-level aggregate as a baseline.    However, keep in mind that for middle-tier services there is often an option to check    on the plugin for the client.</li> </ul>"},{"location":"asl/des/","title":"Double Exponential Smoothing","text":"<p>Double exponential smoothing (DES) is a simple technique for generating a smooth trend line from another time series. This technique is often used to generate a dynamic threshold for alerting.</p> <p>Warning</p> <p>Alerts on dynamic thresholds should be expected to be noisy. They are looking for strange behavior rather than an actual problem causing impact. Make sure you will actually spend the time to tune and investigate the alarms before using this approach. See the alerting philosophy guide for more information on best practices.</p>"},{"location":"asl/des/#tuning","title":"Tuning","text":"<p>The :des operator takes 4 parameters:</p> <ul> <li>An input time series</li> <li><code>training</code> - the number of intervals to use for warming up before generating an output</li> <li><code>alpha</code> - is a data smoothing factor</li> <li><code>beta</code> - is a trend smoothing factor</li> </ul> <p>Note</p> <p>For most use cases, the sliding variant of DES, :sdes, should be used instead.</p>"},{"location":"asl/des/#training","title":"Training","text":"<p>The training parameter defines how many intervals to allow the DES to warmup. In the graph below the gaps from the start of the chart to the smoothed lines reflects the training window used:</p> <p></p> <p>Typically a training window of 10 has been sufficient as DES will adjust to the input fairly quick. However, in some cases if there is a massive change in the input it can cause DES to oscillate, for example:</p> <p></p>"},{"location":"asl/des/#alpha","title":"Alpha","text":"<p>Alpha is the data smoothing factor. A value of 1 means no smoothing. The closer the value gets to 0 the smoother the line should get. Example:</p> <p></p>"},{"location":"asl/des/#beta","title":"Beta","text":"<p>Beta is a trend smoothing factor. Visually it is most apparent when alpha is small. Example with <code>alpha = 0.01</code>:</p> <p></p>"},{"location":"asl/des/#recommended-values","title":"Recommended Values","text":"<p>Experimentally we have converged on 3 sets of values based on how quickly it should adjust to changing levels in the input signal.</p> Helper Alpha Beta :des-fast 0.1 0.02 :des-slower 0.05 0.03 :des-slow 0.03 0.04 <p>Here is an example of how they behave for a sharp drop and recovery:</p> <p></p> <p>For a more gradual drop:</p> <p></p> <p>If the drop is smooth enough then DES can adjust without ever triggering.</p>"},{"location":"asl/des/#alerting","title":"Alerting","text":"<p>For alerting purposes the DES line will typically get multiplied by a fraction and then checked to see whether the input line drops below the DES value for a given interval.</p> <pre><code># Query to generate the input line\nnf.cluster,alerttest,:eq,\nname,requestsPerSecond,:eq,:and,\n:sum,\n\n# Create a copy on the stack\n:dup,\n\n# Apply a DES function to generate a prediction\n:des-fast,\n\n# Used to set a threshold. The prediction should\n# be roughly equal to the line, in this case the\n# threshold would be 85% of the prediction.\n0.85,:mul,\n\n# Create a boolean signal line that is 1\n# for datapoints where the actual value is\n# less than the prediction and 0 where it\n# is greater than or equal the prediction.\n# The 1 values are where the alert should\n# trigger.\n:lt,\n\n# Apply presentation details.\n:rot,$name,:legend,\n</code></pre> <p>The vertical spans show when the expression would have triggered with due to the input dropping below the DES line at 85%:</p> <p></p> <p></p>"},{"location":"asl/des/#epic-macros","title":"Epic Macros","text":"<p>There are two helper macros, des-epic-signal and des-epic-viz, that match the behavior of the previous epic DES alarms. The first generates a signal line for the alarm. The second creates a visualization to make it easier to see what is happening. Both take the following arguments:</p> <ul> <li><code>line</code> - input line</li> <li><code>trainingSize</code> - training size parameter for DES</li> <li><code>alpha</code> - alpha parameter for DES</li> <li><code>beta</code> - beta parameter for DES</li> <li><code>maxPercent</code> - percentage offset to use for the upper bound. Can be set to NaN to disable the upper bound check.</li> <li><code>minPercent</code> - percentage offset to use for the lower bound. Can be set to NaN to disable the lower bound check.</li> <li><code>noise</code> - a fixed offset that is the minimum difference between the signal and prediction that is required before the signal should trigger. This is primarily used to avoid false alarms where the percentage bound can become ineffective for routine noise during the troughs.</li> </ul> <p>Examples:</p> <p></p> <pre>nf.cluster,alerttest,:eq,\nname,requestsPerSecond,:eq,\n:and,\n:sum,\n10,0.1,0.02,0.15,0.15,10,:des-epic-viz\n</pre> <p>Example with no lower bound:</p> <p></p> <pre>nf.cluster,alerttest,:eq,\nname,requestsPerSecond,:eq,\n:and,\n:sum,\n10,0.1,0.02,0.15,NaN,10,:des-epic-viz\n</pre>"},{"location":"asl/tutorial/","title":"Tutorial","text":"<p>Atlas Stack Language is designed to be a stable method of representing complex data queries in a URL-friendly format. It is loosely based on the RPN expressions supported by Tobias Oetiker's rrdtool. The following is an example of a stack language expression:</p> <p><code>nf.cluster,discovery,:eq,(,nf.zone,),:by</code></p> <p>This example pushes two strings <code>nf.cluster</code> and <code>discovery</code> onto the stack and then executes the command <code>:eq</code>. The equal command pops two strings from the stack and pushes a query object onto the stack. The behavior can be described by the stack effect <code>String:key String:value \u2013 Query</code>. We then push a list of tag keys to the stack and execute the command <code>:by</code> to group the results.</p>"},{"location":"asl/tutorial/#parts","title":"Parts","text":"<p>There are only four reserved symbols used for structuring the expression: <code>,:()</code></p> <ol> <li>Commas separate items on the stack. So <code>a,b</code> puts two strings on the stack with values <code>\"a\"</code>    and <code>\"b\"</code>.</li> <li>Colon is used to prefix operations. If the first character is a colon the item will be treated    as a command to run. For example, <code>a,:dup</code>, will push <code>\"a\"</code> on the stack and then execute the    duplicate operation.</li> <li>Parenthesis are used to indicate the start and end of a list. The expression <code>(,)</code> puts an    empty list on the stack. Commands inside of a list will not be executed unless the list is    passed to the call command. For example, <code>(,:dup,)</code> will push a list with a single    string value of <code>\":dup\"</code> on to the stack.</li> </ol>"},{"location":"asl/tutorial/#data-model","title":"Data Model","text":"<p>The stack language is primarily used for representing expressions over tagged time series data. A tag is a string key value pair used to describe a measurement. Atlas requires at least one tag with a key of <code>name</code>. Example tags represented as a JSON map:</p> <pre><code>{\n  \"name\":       \"jvm.gc.pause\",\n  \"cause\":      \"Allocation_Failure\",\n  \"statistic\":  \"count\",\n  \"nf.app\":     \"www\",\n  \"nf.cluster\": \"www-main\",\n  \"nf.asg\":     \"www-main-v001\",\n  \"nf.stack\":   \"main\",\n  \"nf.node\":    \"i-01\",\n  \"nf.region\":  \"us-east-1\",\n  \"nf.zone\":    \"us-east-1a\"\n}\n</code></pre> <p>Typically, tags should be dimensions that allow you to use the name as a pivot and other tags to drill down into the data. The tag keys are similar to columns in a traditional table, however, it is important to note that not all time series will have the same set of tag keys.</p> <p>The tags are used to identify a time series, which conceptually is a set of timestamp value pairs. Here is a simplified data set shown as a table:</p> name app node values cpuUsage www i-01 [(05:00, 33.0), (05:01, 31.0)] cpuUsage www i-02 [(05:00, 20.0), (05:01, 37.0)] cpuUsage db i-03 [(05:00, 57.0), (05:01, 62.0)] diskUsage www i-01 [(05:00,  9.0), (05:01,  9.0)] diskUsage www i-02 [(05:00,  7.0), (05:01,  8.0)] requestRate www [(05:00, 33.0), (05:01, 31.0)] <p>The table above will be used for the examples in later sections.</p>"},{"location":"asl/tutorial/#simple-expressions","title":"Simple Expressions","text":"<p>All expressions generally have four parts:</p> <ol> <li>Choosing: selects a set of time series.</li> <li>Aggregation: defines how to combine the selected time series.</li> <li>Math: manipulate the time series values or combine aggregated results with binary operations.</li> <li>Presentation: adjust how the data is presented in a chart.</li> </ol>"},{"location":"asl/tutorial/#choosing","title":"Choosing","text":"<p>The \"choosing\" or predicate section is used to select a set of time series. The  primary predicate operators are :eq and :and.</p> <p>Sample query to select all time series where the key <code>node</code> is equal to <code>i-01</code>:</p> <pre>node,i-01,:eq\n</pre> <p>If you are familiar with SQL and assume that tag keys are column names, then this would be equivalent to:</p> <pre><code>select * from time_series where node = 'i-01';\n</code></pre> <p>Using the example data set this query would return the following subset:</p> name app node values cpuUsage www i-01 [(05:00, 33.0), (05:01, 31.0)] diskUsage www i-01 [(05:00,  9.0), (05:01,  9.0)] <p>To get just the cpu usage for that node, use :and:</p> <pre>node,i-01,:eq,\nname,cpuUsage,:eq,\n:and\n</pre> <p>This would result in:</p> name app node values cpuUsage www i-01 [(05:00, 33.0), (05:01, 31.0)]"},{"location":"asl/tutorial/#aggregation","title":"Aggregation","text":"<p>An aggregation function maps a set of time series that matched the predicate to a single time series. Atlas supports four aggregate functions: sum, min, max, and count. If no aggregate is specified on an expression, then sum will be used implicitly.</p> <p>Using the example data set, these two expressions would be equivalent:</p> <pre>app,www,:eq,\nname,cpuUsage,:eq,\n:and\n</pre> <pre>app,www,:eq,\nname,cpuUsage,:eq,\n:and,\n:sum\n</pre> <p>And would result in a single output time series:</p> name app values cpuUsage www [(05:00, 53.0), (05:01, 68.0)] <p>Note that the node is not present in the output. The set of tags on the output will be ones with exact matches in the predicate clause or explicitly listed in the group by.</p> <p>If you wanted the max cpu for the application, then you would write:</p> <pre>app,www,:eq,\nname,cpuUsage,:eq,\n:and,\n:max\n</pre> <p>What if we want the average? The count aggregate is used to determine how many time series had a value for a given time. To get the average we divide the sum by the count.</p> <pre>app,www,:eq,\nname,cpuUsage,:eq,\n:and,\n:dup,\n:sum,\n:swap,\n:count,\n:div\n</pre> <p>There is a helper macro :avg that will do this for you, so you can write:</p> <pre>app,www,:eq,\nname,cpuUsage,:eq,\n:and,\n:avg\n</pre>"},{"location":"asl/tutorial/#group-by","title":"Group By","text":"<p>In many cases we want to group the results that were selected and return one aggregate per group. As an example suppose I want to see maximum cpu usage by application:</p> <pre>name,cpuUsage,:eq,\n:max,\n(,app,),:by\n</pre> <p>Using the example data set, this would result in a two output time series:</p> name app values cpuUsage www [(05:00, 33.0), (05:01, 37.0)] cpuUsage db [(05:00, 57.0), (05:01, 62.0)]"},{"location":"asl/tutorial/#math","title":"Math","text":"<p>Once you have a set of lines, it can be useful to manipulate them. The supported operations generally fall into two categories: unary operations to alter a single time series and binary operations that combine two time series.</p> <p>Examples of unary operations are negate and absolute value. To apply the absolute value:</p> <pre>app,web,:eq,\nname,cpu,:eq,\n:and,\n:sum,\n:abs\n</pre> <p>Multiple operations can be applied, for example, negating the line then applying the absolute value:</p> <pre>app,web,:eq,\nname,cpu,:eq,\n:and,\n:sum,\n:neg,\n:abs\n</pre> <p>Common binary operations are add, subtract, multiply, and divide. The aggregation section has an example of using divide to compute the average.</p>"},{"location":"asl/tutorial/#presentation","title":"Presentation","text":"<p>Once you have a final expression, you can apply presentation settings to alter how a time series is displayed in the chart. One of the most common examples is setting the label to use for the legend:</p> <pre>app,www,:eq,\nname,cpuUsage,:eq,\n:and,\n:avg,\naverage+cpu+usage,:legend\n</pre> <p>You can also use tag keys as variables in the legend text, for example, setting the legend to the application:</p> <pre>app,www,:eq,\nname,cpuUsage,:eq,\n:and,\n:avg,\n(,app,),:by,\n$(app),:legend\n</pre> <p>It is also common to adjust the how the lines are shown. For example, to stack each of the lines we can use the :stack command to adjust the line style:</p> <pre>app,www,:eq,\nname,cpuUsage,:eq,\n:and,\n:avg,\n(,app,),:by,\n:stack,\n$(app),:legend\n</pre>"},{"location":"asl/ref/-rot/","title":"-rot","text":"Input Stack:ba... \u21e8 Output Stack:a...b <p>Rotate the stack so that the item at the top is now at the bottom.</p> <p>Example: </p> <pre>a,b,c,d,:-rot\n</pre> PosInputOutput 0 d c 1 c b 2 b a 3 a d"},{"location":"asl/ref/2over/","title":"2over","text":"Input Stack:ba \u21e8 Output Stack:baba <p>Shorthand equivalent to writing: <code>:over,:over</code></p> <p>Example:</p> <pre>a,b,:2over\n</pre> PosInputOutput 0 b b 1 a a 2 b 3 a"},{"location":"asl/ref/abs/","title":"abs","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Compute a new time series where each interval has the absolute value of the input time series.</p> <p>Examples:</p> 064-64 <pre>0,:abs\n</pre><pre>64,:abs\n</pre><pre>-64,:abs\n</pre>"},{"location":"asl/ref/add/","title":"add","text":"Input Stack:ts2: TimeSeriesExprts1: TimeSeriesExpr \u21e8 Output Stack:(ts1 + ts2): TimeSeriesExpr <p>Compute a new time series where each interval has the value <code>(a addNaN b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series. Sample:</p> :add 3.0 0.0 1.0 1.0 NaN Input 1 1.0 0.0 1.0 1.0 NaN Input 2 2.0 0.0 0.0 NaN NaN <p>Use the fadd operator to get strict floating point behavior.</p> <p>Examples</p> <p>Example adding a constant:</p> BeforeAfter <pre>name,sps,:eq,\n30e3\n</pre><pre>name,sps,:eq,\n30e3,:add\n</pre> <p>Example adding two series:</p> BeforeAfter <pre>name,requestLatency,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by\n</pre><pre>name,requestLatency,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by,\n:add\n</pre>"},{"location":"asl/ref/all/","title":"all","text":"<p>Warning</p> <p>Deprecated: use :by instead. This operation is primarily intended for debugging and results can be confusing unless you have detailed understanding of Atlas internals.</p> Input Stack:Query \u21e8 Output Stack:DataExpr <p>Avoid aggregation and output all time series that match the query.</p>"},{"location":"asl/ref/alpha/","title":"alpha","text":"Input Stack:StringTimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Set the alpha value for the colors on the line. The value should be a two digit hex number where <code>00</code> is transparent and <code>ff</code> is opague. This setting will be ignored if the color setting is used for the same line.</p> BeforeAfter <pre>name,sps,:eq,\n:sum,\n:stack\n</pre><pre>name,sps,:eq,\n:sum,\n:stack,\n40,:alpha\n</pre> BeforeAfter <pre>name,sps,:eq,\n:sum,\n:stack,\nf00,:color\n</pre><pre>name,sps,:eq,\n:sum,\n:stack,\nf00,:color,\n40,:alpha\n</pre>"},{"location":"asl/ref/and/","title":"and","text":"<p>There are two variants of the <code>:and</code> operator.</p>"},{"location":"asl/ref/and/#choosing","title":"Choosing","text":"Input Stack:q2: Queryq1: Query \u21e8 Output Stack:(q1 AND q2): Query <p>This first variant is used for choosing the set of time series to operate on. It is a binary operator that matches if both of the sub-queries match. For example, consider the following query:</p> <pre>nf.app,alerttest,:eq,\nname,ssCpuUser,:eq,\n:and\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp i-0abc ssCpuUser api i-0456"},{"location":"asl/ref/and/#math","title":"Math","text":"Input Stack:ts2: TimeSeriesExprts1: TimeSeriesExpr \u21e8 Output Stack:(ts1 AND ts2): TimeSeriesExpr <p>Compute a new time series where each interval has the value <code>(a AND b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series. For example:</p> Time a b a AND b 00:01 0.0 0.0 0.0 00:01 0.0 1.0 0.0 00:02 1.0 0.0 0.0 00:03 1.0 1.0 1.0 00:04 0.5 1.7 1.0 <p>The result will be a signal time series that will be <code>1.0</code> for all intervals where the corresponding values of <code>a</code> and <code>b</code> are both non-zero. Example:</p> BeforeAfter <pre>minuteOfDay,:time,\n:dup,\n300,:gt,\n:swap,\n310,:lt\n</pre><pre>minuteOfDay,:time,\n:dup,\n300,:gt,\n:swap,\n310,:lt,\n:and\n</pre>"},{"location":"asl/ref/area/","title":"area","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Change the line style to be area. In this mode the line will be filled to 0 on the Y-axis.</p> <p>See the line style examples page for more information.</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n:area\n</pre>"},{"location":"asl/ref/as/","title":"as","text":"Input Stack:replacement: Stringoriginal: StringTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Map a tag key name to an alternate name. This can be useful for cases where it is desirable to perform a binary math operation, but the two sides use different tag keys for the same concept. The common IPC metrics are an example where it might be desirable to compare RPS for servers and their clients. The server side RPS would group by <code>nf.app</code> while the client side view would group by <code>ipc.server.app</code>.</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\nnf.cluster,c,:as,\n$c,:legend\n</pre>"},{"location":"asl/ref/avg/","title":"avg","text":"<p>Average or mean aggregation operator. There are two variants of the <code>:avg</code> operator.</p>"},{"location":"asl/ref/avg/#aggregation","title":"Aggregation","text":"Input Stack:Query \u21e8 Output Stack:TimeSeriesExpr <p>A helper method that computes the average or mean from one or more time series using the  count aggregate to determine how many time series have data at an interval and  dividing the sum of the values by the count. This avoids issues where one or time series are missing data at a specific time resulting in an artificially low average. E.g. the  expression:</p> <pre>name,ssCpuUser,:eq,\n:avg\n</pre> <p>when matching against the sample data in the table below, the highlighted time series would be included in the aggregate result:</p> Namenf.appnf.nodeData ssCpuUser alerttest i-0123 [1.0, 2.0, NaN] ssCpuSystem alerttest i-0123 [3.0, 4.0, 5.0] ssCpuUser nccp i-0abc [8.0, 7.0, 6.0] ssCpuSystem nccp i-0abc [6.0, 7.0, 8.0] numRequests nccp i-0abc [1.0, 2.0, 4.0] ssCpuUser api i-0456 [1.0, 2.0, 2.0] <p>The values from the corresponding intervals will be aggregated. For the first interval using the sample data above the values are <code>1.0</code>, <code>8.0</code>, and <code>1.0</code>. Each value other than <code>NaN</code> contributes one to the average. This leads to a final result of:</p> NameData ssCpuUser [3.33, 3.66, 4.0] <p>The only tags for the aggregated result are those that are matched exactly (:eq clause) as part of the choosing criteria or are included in a group by.</p>"},{"location":"asl/ref/avg/#math","title":"Math","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Compute the average of all the time series from the input expression. This is typically used when there is a need to use some other aggregation for the grouping. Example:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n:max,\n(,nf.cluster,),:by,\n:avg\n</pre>"},{"location":"asl/ref/axis/","title":"axis","text":"Input Stack:IntTimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Specify which Y-axis to use for the line. The value specified is the axis number and should be an integer in the range 0 to 4 inclusive.</p> <p>Example:</p> BeforeAfter <pre>name,sps,:eq,\n:sum,\n42\n</pre><pre>name,sps,:eq,\n:sum,\n42,1,:axis\n</pre>"},{"location":"asl/ref/bottomk-others-avg/","title":"bottomk-others-avg","text":"Input Stack:k: Intstat: StringTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Since: 1.7</p> <p>Restrict the output for a grouped expression to the <code>k</code> time series with the smallest value for the specified summary statistic and computes an average aggregate for the other time series. Example of usage:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\nmax,2,:bottomk-others-avg\n</pre>"},{"location":"asl/ref/bottomk-others-max/","title":"bottomk-others-max","text":"Input Stack:k: Intstat: StringTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Since: 1.7</p> <p>Restrict the output for a grouped expression to the <code>k</code> time series with the smallest value for the specified summary statistic and computes a max aggregate for the other time series. Example of usage:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\nmax,2,:bottomk-others-max\n</pre>"},{"location":"asl/ref/bottomk-others-min/","title":"bottomk-others-min","text":"Input Stack:k: Intstat: StringTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Since: 1.7</p> <p>Restrict the output for a grouped expression to the <code>k</code> time series with the smallest value for the specified summary statistic and computes a min aggregate for the other time series. Example of usage:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\nmax,2,:bottomk-others-min\n</pre>"},{"location":"asl/ref/bottomk-others-sum/","title":"bottomk-others-sum","text":"Input Stack:k: Intstat: StringTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Since: 1.7</p> <p>Restrict the output for a grouped expression to the <code>k</code> time series with the smallest value for the specified summary statistic and computes a sum aggregate for the other time series. Example of usage:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\nmax,2,:bottomk-others-sum\n</pre>"},{"location":"asl/ref/bottomk/","title":"bottomk","text":"Input Stack:k: Intstat: StringTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Since: 1.7</p> <p>Restrict the output for a grouped expression to the <code>k</code> time series with the smallest value for the specified summary statistic. Example of usage:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\nmax,2,:bottomk\n</pre> <p>In some cases it can be useful to see an aggregate summary of the other time series that were not part of the bottom set. This can be accomplished using the <code>:bottomk-others-$(aggr)</code> operators. For more details see:</p> <ul> <li>:bottomk-others-avg</li> <li>:bottomk-others-max</li> <li>:bottomk-others-min</li> <li>:bottomk-others-sum</li> </ul>"},{"location":"asl/ref/by/","title":"by","text":"<p>Group by operator. There are two variants of the <code>:by</code> operator.</p>"},{"location":"asl/ref/by/#aggregation","title":"Aggregation","text":"Input Stack:keys: List[String]AggregationFunction \u21e8 Output Stack:DataExpr <p>Groups the matching time series by a set of keys and applies an aggregation to matches of the group.</p> <pre>name,ssCpu,:re,\n(,name,),:by\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the aggregate result:</p> Namenf.appnf.nodeData ssCpuUser alerttest i-0123 [1.0, 2.0, NaN] ssCpuSystem alerttest i-0123 [3.0, 4.0, 5.0] ssCpuUser nccp i-0abc [8.0, 7.0, 6.0] ssCpuSystem nccp i-0abc [6.0, 7.0, 8.0] numRequests nccp i-0abc [1.0, 2.0, 4.0] ssCpuUser api i-0456 [1.0, 2.0, 2.0] <p>The aggregation function will be applied independently for each group. In this example above there are two matching values for the group by key <code>name</code>. This leads to a final result of:</p> NameData ssCpuSystem [9.0, 11.0, 13.0] ssCpuUser [10.0, 11.0, 8.0] <p>The <code>name</code> tag is included in the result set since it is used for the grouping.</p>"},{"location":"asl/ref/by/#math","title":"Math","text":"Input Stack:keys: List[String]TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Groups the time series from the input expression by a set of keys and applies an aggregation to matches of the group. The keys used for this grouping must be a subset of keys from the initial group by clause. Example:</p> BeforeAfter <pre>name,sps,:eq,\n:sum,\n(,nf.cluster,nf.node,),:by\n</pre><pre>name,sps,:eq,\n:sum,\n(,nf.cluster,nf.node,),:by,\n:count,\n(,nf.cluster,),:by\n</pre>"},{"location":"asl/ref/call/","title":"call","text":"Input Stack:?List \u21e8 Output Stack:? <p>Pops a list off the stack and executes it as a program.</p> <p>Example:</p> <pre>(,a,),:call\n</pre> Pos Input Output 0 List(a) a"},{"location":"asl/ref/cf-avg/","title":"cf-avg","text":"Input Stack:AggregationFunction \u21e8 Output Stack:AggregationFunction <p>Force the consolidation function to be average.</p>"},{"location":"asl/ref/cf-max/","title":"cf-max","text":"Input Stack:AggregationFunction \u21e8 Output Stack:AggregationFunction <p>Force the consolidation function to be max.</p>"},{"location":"asl/ref/cf-min/","title":"cf-min","text":"Input Stack:AggregationFunction \u21e8 Output Stack:AggregationFunction <p>Force the consolidation function to be min.</p>"},{"location":"asl/ref/cf-sum/","title":"cf-sum","text":"Input Stack:AggregationFunction \u21e8 Output Stack:AggregationFunction <p>Force the consolidation function to be sum.</p>"},{"location":"asl/ref/cg/","title":"cg","text":"Input Stack:keys: List[String]Expr \u21e8 Output Stack:Expr <p>Recursively add a list of keys to group by expressions. This can be useful for tooling that needs to adjust existing expressions to include keys in the grouping. </p> BeforeAfter <pre>name,sps,:eq,\n(,nf.app,),:by\n</pre><pre>name,sps,:eq,\n(,nf.app,),:by,\n(,nf.cluster,),:cg\n</pre>"},{"location":"asl/ref/clamp-max/","title":"clamp-max","text":"Input Stack:DoubleTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Restricts the maximum value of the output time series to the specified value. Values from the input time series that are less than or equal to the maximum will not be changed.</p> <p>A common use-case is to allow for auto-scaled axis up to a specified bound. The axis parameters for controlling the axis bounds have the following limitations:</p> <ul> <li>They apply to everything on the axis and cannot be targeted to a specific line.</li> <li>Are either absolute or set based on the data. For data with occasional spikes   this can hide important details.</li> </ul> <p>Consider the following graph:</p> <p></p> <p>The spike makes it difficult to make out any detail for other times. One option to handle this is to use an alternate axis scale such as logarithmic that gives a higher visual weight to the smaller values. However, it is often easier for a user to reason about a linear scale, in particular, for times when there is no spike in the graph window. If there is a known max reasonable value, then the <code>:clamp-max</code> operator can be used to restrict the line if and only if it exceeds the designated max. For example, if we limit the graph above to 25:</p> <p></p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n60e3,:clamp-max\n</pre>"},{"location":"asl/ref/clamp-min/","title":"clamp-min","text":"Input Stack:DoubleTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Restricts the minimum value of the output time series to the specified value. Values from the input time series that are greater than or equal to the minimum will not be changed. A common use-case is to allow for auto-scaled axis up to a specified bound. For more details see :clamp-max.</p> <p>Example:</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n200e3,:clamp-min\n</pre>"},{"location":"asl/ref/clear/","title":"clear","text":"Input Stack:... \u21e8 Output Stack: <p>Remove all items from the stack. </p> <p>Example:</p> <pre>a,b,c,:clear\n</pre> PosInputOutput 0 c 1 b 2 a"},{"location":"asl/ref/color/","title":"color","text":"Input Stack:StringTimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Set the color for the line. The value should be one of:</p> <ul> <li>Hex triplet, e.g. f00 is red.</li> <li>6 digit hex RBG, e.g. ff0000 is red.</li> <li>8 digit hex ARGB, e.g. ffff0000 is red. The first byte is the alpha   setting to use with the color.</li> </ul> <p>For queries with multiple time series, color palettes are available to automatically assign different colors to the various series. See Color Palettes.</p> BeforeAfter <pre>name,sps,:eq\n</pre><pre>name,sps,:eq,\nff0000,:color\n</pre>"},{"location":"asl/ref/const/","title":"const","text":"Input Stack:Double \u21e8 Output Stack:TimeSeriesExpr <p>Generates a line where each datapoint is a constant value. Any double value that is left on the stack will get implicitly converted to a constant line, so this operator is typically not used explicitly.</p> BeforeAfter <pre>42\n</pre><pre>42,:const\n</pre>"},{"location":"asl/ref/contains/","title":"contains","text":"Input Stack:v: Stringk: String \u21e8 Output Stack:Query <p>Select time series where the value for a key includes the specified substring. For example, consider the following query:</p> <pre>name,Cpu,:contains\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp i-0abc ssCpuUser api i-0456"},{"location":"asl/ref/count/","title":"count","text":"<p>Count aggregation operator. There are two variants of the <code>:count</code> operator.</p>"},{"location":"asl/ref/count/#aggregation","title":"Aggregation","text":"Input Stack:Query \u21e8 Output Stack:AggregationFunction <p>Compute the number of time series that match the query and have a value for a given interval.</p> <pre>name,ssCpuUser,:eq,\n:count\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the aggregate result:</p> Namenf.appnf.nodeData ssCpuUser alerttest i-0123 [1.0, 2.0, NaN] ssCpuSystem alerttest i-0123 [3.0, 4.0, 5.0] ssCpuUser nccp i-0abc [8.0, 7.0, 6.0] ssCpuSystem nccp i-0abc [6.0, 7.0, 8.0] numRequests nccp i-0abc [1.0, 2.0, 4.0] ssCpuUser api i-0456 [1.0, 2.0, 2.0] <p>The values from the corresponding intervals will be aggregated. For the first interval using the sample data above the values are <code>1.0</code>, <code>8.0</code>, and <code>1.0</code>. Each value other than <code>NaN</code> contributes one to the count. This leads to a final result of:</p> NameData ssCpuUser [3.0, 3.0, 2.0] <p>The only tags for the aggregated result are those that are matched exactly (:eq clause) as part of the choosing criteria or are included in a group by.</p>"},{"location":"asl/ref/count/#math","title":"Math","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Compute the number of time series from the input expression and have a value for a given interval. Example:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:count\n</pre>"},{"location":"asl/ref/cq/","title":"cq","text":"Input Stack:QueryExpr \u21e8 Output Stack:Expr <p>Recursively AND a common query to all queries in an expression. If the first parameter is not an expression, then it will be not be modified.</p> <p>Example:</p> <pre>name,ssCpuUser,:eq,\nname,DiscoveryStatus_UP,:eq,\n:mul,\nnf.app,alerttest,:eq,\n:cq\n</pre> BeforeAfter <pre>name,ssCpuUser,:eq,\nname,DiscoveryStatus_UP,:eq,\n:mul,\nnf.app,alerttest,:eq\n</pre><pre>name,ssCpuUser,:eq,\nname,DiscoveryStatus_UP,:eq,\n:mul,\nnf.app,alerttest,:eq,\n:cq\n</pre> BeforeAfter <pre>42,nf.app,alerttest,:eq\n</pre><pre>42,nf.app,alerttest,:eq,\n:cq\n</pre>"},{"location":"asl/ref/decode/","title":"decode","text":"Input Stack:StringTimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Note</p> <p>It is recommended to avoid using special symbols or trying to encode structural information into tag values. This feature should be used sparingly and with great care to ensure it will not result in a combinatorial explosion.</p> <p>Perform decoding of the legend strings. Generally data going into Atlas is restricted to simple ascii characters that are easy to use as part of a URI. Most commonly the clients will convert unsupported characters to an <code>_</code>. In some case it is desirable to be able to reverse that for the purposes of presentation.</p> <ul> <li><code>none</code>: this is the default. It will not modify the legend string.</li> <li><code>hex</code>: perform a hex decoding of the legend string. This is similar to   url encoding except   that the <code>_</code> character is used instead of <code>%</code> to indicate the start of   an encoded symbol. The decoding is lenient, if the characters following   the <code>_</code> are not valid hexadecimal digits then it will just copy those   characters without modification.</li> </ul> <p>Since: 1.5</p> <p>Example:</p> Hex to ASCII <pre>1,one_21_25_26_3F,:legend,\nhex,:decode\n</pre>"},{"location":"asl/ref/delay/","title":"delay","text":"Input Stack:n: IntTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Delays the values by the window size. This is similar to the <code>:offset</code> operator except that it can be applied to any input line instead of just changing the time window fetched with a DataExpr. Short delays can be useful for alerting to detect changes in slightly shifted trend lines.</p> <p>Since: 1.6</p> BeforeAfterCombined <pre>name,requestsPerSecond,:eq,\n:sum\n</pre><pre>name,requestsPerSecond,:eq,\n:sum,\n5,:delay\n</pre><pre>name,requestsPerSecond,:eq,\n:sum,\n:dup,\n5,:delay\n</pre>"},{"location":"asl/ref/depth/","title":"depth","text":"Input Stack:... \u21e8 Output Stack:Int... <p>Push the depth of the stack.</p> <p>Since: 1.5.0 </p> <p>Examples:</p> <pre>,:depth\n</pre> PosInputOutput 0 0 <pre>a,:depth\n</pre> PosInputOutput 0 a 1 1 a <pre>a,b,:depth\n</pre> PosInputOutput 0 b 2 1 a b 2 a"},{"location":"asl/ref/derivative/","title":"derivative","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Opposite of :integral. Computes the rate of change per step of the input time series.</p> DerivativeIntegralIntegral Then Derivative <pre>1,:derivative\n</pre><pre>1,:integral\n</pre><pre>1,:integral,\n:derivative\n</pre>"},{"location":"asl/ref/des-epic-signal/","title":"des-epic-signal","text":"Input Stack:noise: DoubleminPercent: DoublemaxPercent: Doublebeta: Doublealpha: Doubletraining: IntTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Helper for configuring DES in a manner compatible with legacy epic alerts. For more information see the epic macros section of the DES page.</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n10,0.1,0.5,0.2,0.2,4,:des-epic-signal\n</pre>"},{"location":"asl/ref/des-epic-viz/","title":"des-epic-viz","text":"Input Stack:noise: DoubleminPercent: DoublemaxPercent: Doublebeta: Doublealpha: Doubletraining: IntTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Helper for configuring DES in a manner compatible with legacy Epic alerts. For more information see the epic macros section of the DES page.</p> Example <pre>name,sps,:eq,\n:sum,\n10,0.1,0.5,0.2,0.2,4,:des-epic-viz\n</pre>"},{"location":"asl/ref/des-fast/","title":"des-fast","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Helper for computing DES using settings to quickly adjust to the input line. See recommended values for more information. For most use-cases the sliding DES variant :sdes-fast should be used instead.</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n:des-fast\n</pre>"},{"location":"asl/ref/des-simple/","title":"des-simple","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Helper for computing DES using default values.</p> <p>Warning</p> <p>The values used by this operation are prone to wild oscillations. See recommended values for better options.</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n:des-simple\n</pre>"},{"location":"asl/ref/des-slow/","title":"des-slow","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Helper for computing DES using settings to slowly adjust to the input line. See recommended values for more information. For most use-cases the sliding DES variant :sdes-slow should be used instead.</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n:des-slow\n</pre>"},{"location":"asl/ref/des-slower/","title":"des-slower","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Helper for computing DES using settings to slowly adjust to the input line. See recommended values for more information. For most use-cases the sliding DES variant :sdes-slower should be used instead.</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n:des-slower\n</pre>"},{"location":"asl/ref/des/","title":"des","text":"Input Stack:beta: Doublealpha: Doubletraining: IntTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Double exponential smoothing. For most use-cases sliding DES should be used instead to ensure a deterministic prediction.</p> BeforeAfter <pre>name,requestsPerSecond,:eq,\n:sum\n</pre><pre>name,requestsPerSecond,:eq,\n:sum,\n5,0.1,0.5,:des\n</pre>"},{"location":"asl/ref/dist-avg/","title":"dist-avg","text":"Input Stack:Query \u21e8 Output Stack:TimeSeriesExpr <p>Compute the average recorded value for timers and distribution summaries. This is calculated by dividing the total amount recorded by the number of recorded values.</p> <p>For [Timer] and Distribution Summary metrics, the <code>totalTime</code> (timers) /<code>totalAmount</code> (distributions) and <code>count</code> are collected each time a measurement is taken. If this technique was applied to a request latency metric, then you would have the average latency per request for an arbitrary grouping. These types of metrics have an explicit count based on activity. To get an average per measurement manually:</p> <pre>statistic,totalTime,:eq,\n:sum,\nstatistic,count,:eq,\n:sum,\n:div\n</pre> <p>This expression can be bound to a query using the :cq (common query) operator:</p> <pre>statistic,totalTime,:eq,\n:sum,\nstatistic,count,:eq,\n:sum,\n:div,\nnf.cluster,foo,:eq,\nname,http.req.latency,:eq,\n:and,\n:cq\n</pre> <p>Using the <code>:dist-avg</code> function reduces the query to:</p> <pre>nf.cluster,foo,:eq,\nname,http.req.latency,:eq,\n:and,\n:dist-avg\n</pre> <p>To compute the average by group, apply the group after the <code>:dist-avg</code> function:</p> <pre>nf.cluster,foo,:eq,\nname,http.req.latency,:eq,\n:and,\n:dist-avg,\n(,nf.asg,),:by\n</pre> BeforeAfter <pre>name,playback.startLatency,:eq\n</pre><pre>name,playback.startLatency,:eq,\n:dist-avg\n</pre>"},{"location":"asl/ref/dist-max/","title":"dist-max","text":"Input Stack:Query \u21e8 Output Stack:TimeSeriesExpr <p>Compute the maximum recorded value for timers and distribution summaries. This is a helper for aggregating by the max of the max statistic for the meter.</p> <p>A manual query would look like:</p> <pre>nf.cluster,foo,:eq,\nname,http.req.latency,:eq,\n:and,\nstatistic,max,:eq,\n:and,\n:max\n</pre> <p>Using <code>:dist-max</code> the query is reduced to:</p> <pre>nf.cluster,foo,:eq,\nname,http.req.latency,:eq,\n:and,\n:dist-max\n</pre> BeforeAfter <pre>name,playback.startLatency,:eq\n</pre><pre>name,playback.startLatency,:eq,\n:dist-max\n</pre>"},{"location":"asl/ref/dist-stddev/","title":"dist-stddev","text":"Input Stack:Query \u21e8 Output Stack:TimeSeriesExpr <p>Compute the standard deviation for timers and distribution summaries.</p> <p>A manual query would look like:</p> <pre>statistic,count,:eq,\n:sum,\nstatistic,totalOfSquares,:eq,\n:sum,\n:mul,\nstatistic,totalTime,:eq,\n:sum,\n:dup,\n:mul,\n:sub,\nstatistic,count,:eq,\n:sum,\n:dup,\n:mul,\n:div,\n:sqrt,\nnf.cluster,foo,:eq,\n name,http.req.latency,:eq,\n:and,\n:cq\n</pre> <p>This is much simpler using the <code>:dist-stddev</code> function:</p> <pre>nf.cluster,foo,:eq,\nname,http.req.latency,:eq,\n:and,\n:dist-stddev\n</pre> BeforeAfter <pre>name,playback.startLatency,:eq\n</pre><pre>name,playback.startLatency,:eq,\n:dist-stddev\n</pre>"},{"location":"asl/ref/div/","title":"div","text":"Input Stack:ts2: TimeSeriesExprts1: TimeSeriesExpr \u21e8 Output Stack:(ts1 / ts2): TimeSeriesExpr <p>Compute a new time series where each interval has the value <code>(a / b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series. If <code>a</code> and <code>b</code> are 0, then 0 will be returned for the interval. If only <code>b</code> is 0, then NaN will be returned as the value for the interval. Sample data:</p> :div 0.5 0.0 NaN NaN NaN Input 1 1.0 0.0 1.0 1.0 NaN Input 2 2.0 0.0 0.0 NaN NaN <p>Use the fdiv operator to get strict floating point behavior.</p> <p>Example dividing a constant:</p> BeforeAfter <pre>name,sps,:eq,\n42\n</pre><pre>name,sps,:eq,\n42,:div\n</pre> <p>Example adding two series:</p> BeforeAfter <pre>name,sps,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by\n</pre><pre>name,sps,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by,\n:div\n</pre>"},{"location":"asl/ref/drop/","title":"drop","text":"Input Stack:a \u21e8 Output Stack: <p>Remove the item on the top of the stack. </p> <p>Example:</p> <pre>a,b,c,:drop\n</pre> PosInputOutput 0 c b 1 b a 2 a <pre>:drop\n</pre> <p>Warning</p> <p>Throws an exception due to an empty stack.</p>"},{"location":"asl/ref/dup/","title":"dup","text":"Input Stack:a: ? \u21e8 Output Stack:a: ?a: ? <p>Duplates the item on the top of the stack.</p> <p>Example:</p> BeforeAfter <pre>minuteOfDay,:time\n</pre><pre>minuteOfDay,:time,\n:dup\n</pre>"},{"location":"asl/ref/each/","title":"each","text":"Input Stack:function: Listitems: List \u21e8 Output Stack:function(items[N-1])...function(items[0]) <p>Pops a list off the stack and executes it as a program. </p> <p>Example:</p> <pre>(,a,b,),(,:dup,\n),:each\n</pre> PosInputOutput 0 List(:dup) a 1 List(a, b) a 2 b 3 b"},{"location":"asl/ref/ends/","title":"ends","text":"Input Stack:v: Stringk: String \u21e8 Output Stack:Query <p>Select time series where the value for a key has the specified suffix. For example, consider the following query:</p> <pre>name,ssCpuUser,:ends\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp i-0abc ssCpuUser api i-0456"},{"location":"asl/ref/eq/","title":"eq","text":"Input Stack:v: Stringk: String \u21e8 Output Stack:(k == v): Query <p>Select time series that have a specified value for a key. For example, consider the following query:</p> <pre>name,ssCpuUser,:eq\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp i-0abc ssCpuUser api i-0456"},{"location":"asl/ref/eureka-avg/","title":"eureka-avg","text":"Input Stack:Query \u21e8 Output Stack:TimeSeriesExpr <p>A helper to compute an average using the number of instances in the <code>UP</code> state based on the <code>discovery.status</code> metric as the denominator. The common infrastructure tags will be used to restrict the scope for the denominator. This operator should be used if the numerator is based on incoming traffic that is routed via the Eureka service and goal is to compute an average per node receiving traffic.</p> <pre>name,sps,:eq,\nnf.app,nccp,:eq,\n:and,\n:eureka-avg\n</pre>"},{"location":"asl/ref/fadd/","title":"fadd","text":"Input Stack:ts2: TimeSeriesExprts1: TimeSeriesExpr \u21e8 Output Stack:(ts1 + ts2): TimeSeriesExpr <p>Floating point addition operator. Compute a new time series where each interval has the value <code>(a + b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series.</p> :fadd 3.0 0.0 1.0 NaN NaN Input 1 2.0 0.0 1.0 1.0 NaN Input 2 1.0 0.0 0.0 NaN NaN <p>Note in many cases <code>NaN</code> will appear in data, e.g., if a node was brought up and started reporting in the middle of the time window for the graph. This can lead to confusing behavior if added to a line that does have data as the result will be <code>NaN</code>. Use the add operator to treat <code>NaN</code> values as zero for combining with other time series.</p> <p>Example adding a constant:</p> BeforeAfter <pre>name,sps,:eq,\n30e3\n</pre><pre>name,sps,:eq,\n30e3,:fadd\n</pre> <p>Example adding two series:</p> BeforeAfter <pre>name,requestLatency,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by\n</pre><pre>name,requestLatency,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by,\n:fadd\n</pre>"},{"location":"asl/ref/false/","title":"false","text":"Input Stack: \u21e8 Output Stack:Query <p>Query expression that will not match any input time series. See also :true.</p>"},{"location":"asl/ref/fcall/","title":"fcall","text":"Input Stack:String... \u21e8 Output Stack:? <p>Shorthand equivalent to writing: <code>:get,:call</code> </p> <p>Example:</p> <pre>duplicate,(,:dup,\n),:set,\na,duplicate,:fcall\n</pre> PosInputOutput 0 duplicate a 1 a a"},{"location":"asl/ref/fdiv/","title":"fdiv","text":"Input Stack:ts2: TimeSeriesExprts1: TimeSeriesExpr \u21e8 Output Stack:(ts1 / ts2): TimeSeriesExpr <p>Floating point division operator. Compute a new time series where each interval has the value <code>(a / b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series.</p> :fdiv 2.0 NaN Inf NaN NaN Input 1 2.0 0.0 1.0 1.0 NaN Input 2 1.0 0.0 0.0 NaN NaN <p>Note in many cases <code>NaN</code> will appear in data, e.g., if a node was brought up and started reporting in the middle of the time window for the graph. Zero divided by zero can also occur due to lack of activity in some windows. Unless you really need strict floating point behavior, use the div operator to get behavior more appropriate for graphs.</p> <p>Example dividing a constant:</p> BeforeAfter <pre>name,sps,:eq\n</pre><pre>name,sps,:eq,\n1024,:fdiv\n</pre> <p>Example dividing two series:</p> BeforeAfter <pre>name,requestLatency,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by\n</pre><pre>name,requestLatency,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by,\n:fdiv\n</pre>"},{"location":"asl/ref/filter/","title":"filter","text":"Input Stack:TimeSeriesExprTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Filters the results of a grouped expression by another expression. The filter expression is a set of signal time series indicating if the corresponding time series from the original expression should be shown. Simple example that suppresses all lines:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n0,:filter\n</pre> <p>Filtering is most commonly performed using the summary statistics for the original expression. For example, to show only the lines that have an average value across the query window greater than 5k and less than 20k:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:dup,\navg,:stat,\n5e3,:gt,\n:over,\navg,:stat,\n20e3,:lt,\n:and,\n:filter\n</pre> <p>There are helpers, <code>:stat-$(name)</code>, to express this common pattern more easily for filters. They act as place holders for the specified statistic on the input time series. The filter operator will automatically fill in the input when used so the user does not need to repeat the input expression for the filtering criteria. See the :stat operator for more details on available statistics. For this example, :stat-avg would be used:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:stat-avg,\n5e3,:gt,\n:stat-avg,\n20e3,:lt,\n:and,\n:filter\n</pre>"},{"location":"asl/ref/fmul/","title":"fmul","text":"Input Stack:ts2: TimeSeriesExprts1: TimeSeriesExpr \u21e8 Output Stack:(ts1 * ts2): TimeSeriesExpr <p>Compute a new time series where each interval has the value <code>(a * b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series.</p> <p>Example multiplying a constant:</p> BeforeAfter <pre>name,sps,:eq\n</pre><pre>name,sps,:eq,\n1024,:fmul\n</pre> <p>Example multiplying two series:</p> BeforeAfter <pre>name,requestLatency,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by\n</pre><pre>name,requestLatency,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by,\n:fmul\n</pre>"},{"location":"asl/ref/format/","title":"format","text":"Input Stack:args: Listpattern: String \u21e8 Output Stack:str: String <p>Format a string using a printf style pattern.</p> <p>Example:</p> <pre>foo%s,(,bar,),:format\n</pre> PosInputOutput 0 List(bar) foobar 1 foo%s"},{"location":"asl/ref/freeze/","title":"freeze","text":"Input Stack:... \u21e8 Output Stack: <p>Freeze removes all data from the stack and pushes it to a separate frozen stack that cannot be modified other than to push additional items using the freeze operation. The final stack at the end of the execution will include the frozen contents along with any thing that is on the normal stack.</p> <p>This operation is useful for isolating common parts of the stack while still allowing tooling to manipulate the main stack using concatenative rewrite operations. The most common example of this is the :cq operation used to apply a common query to graph expressions. For a concrete example, suppose you want to have an overlay expression showing network errors on a switch that you want to add in to graphs on a dashboard. The dashboard allows drilling into the graphs by selecting a particular cluster. To make this work the dashboard appends a query rewrite to the expression like:</p> <pre><code>,:list,(,nf.cluster,{{ selected_cluster }},:eq,:cq,),:each\n</code></pre> <p>This :list operator will apply to everything on the stack. However, this is problematic because the cluster restriction will break the overlay query. Using the freeze operator the overlay expression can be isolated from the main stack. So the final expression would look something like:</p> <pre><code># Query that should be used as is and not modified further\nname,networkErrors,:eq,:sum,50,:gt,:vspan,40,:alpha,\n:freeze,\n\n# Normal contents of the stack\nname,ssCpuUser,:eq,:avg,1,:axis,\nname,loadavg1,:eq,:avg,2,:axis,\n\n# Rewrite appended by tooling, only applies to main stack\n:list,(,nf.cluster,{{ selected_cluster }},:eq,:cq,),:each\n</code></pre> <p>Since: 1.6</p> <p>Example:</p> <pre>a,b,c,:freeze\n</pre> PosInputOutput 0 c c 1 b b 2 a a"},{"location":"asl/ref/fsub/","title":"fsub","text":"Input Stack:ts2: TimeSeriesExprts1: TimeSeriesExpr \u21e8 Output Stack:(ts1 - ts2): TimeSeriesExpr <p>Floating point subtraction operator. Compute a new time series where each interval has the value <code>(a - b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series.</p> :fsub 1.0 0.0 1.0 NaN NaN Input 1 2.0 0.0 1.0 1.0 NaN Input 2 1.0 0.0 0.0 NaN NaN <p>Note in many cases <code>NaN</code> will appear in data, e.g., if a node was brought up and started reporting in the middle of the time window for the graph. This can lead to confusing behavior if added to a line that does have data as the result will be <code>NaN</code>. Use the sub operator to treat <code>NaN</code> values as zero for combining with other time series.</p> <p>Example subtracting a constant:</p> BeforeAfter <pre>name,sps,:eq\n</pre><pre>name,sps,:eq,\n30000,:fsub\n</pre> <p>Example subtracting two series:</p> BeforeAfter <pre>name,requestLatency,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by\n</pre><pre>name,requestLatency,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by,\n:fsub\n</pre>"},{"location":"asl/ref/ge/","title":"ge","text":"<p>Greater than or equal operator. There are two variants of the <code>:ge</code> operator.</p>"},{"location":"asl/ref/ge/#choosing","title":"Choosing","text":"Input Stack:v: Stringk: String \u21e8 Output Stack:(k &gt;= v): Query <p>This first variant is used for choosing the set of time series to operate on. It selects time series that have a value for a key that is greater than or equal to a specified value. For example, consider the following query:</p> <pre>name,ssCpuSystem,:ge\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp i-0abc ssCpuUser api i-0456"},{"location":"asl/ref/ge/#math","title":"Math","text":"Input Stack:ts2: TimeSeriesExprts1: TimeSeriesExpr \u21e8 Output Stack:(ts1 &gt;= ts2): TimeSeriesExpr <p>Compute a new time series where each interval has the value <code>(a &gt;= b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series. For example:</p> Time a b a &gt;= b 00:01 0.0 0.0 0.0 00:01 0.0 1.0 0.0 00:02 1.0 0.0 1.0 00:03 1.0 1.0 1.0 00:04 0.5 1.7 0.0 <p>The result will be a signal time series that will be <code>1.0</code> for intervals where the condition is true and <code>0.0</code> for intervals where it is false.</p> <p>Info</p> <p>Note, the data points have floating point values. It is advisable to avoid relying on an exact equality match.</p> <p>Example:</p> BeforeAfter <pre>minuteOfHour,:time,\nhourOfDay,:time\n</pre><pre>minuteOfHour,:time,\nhourOfDay,:time,\n:ge\n</pre>"},{"location":"asl/ref/get/","title":"get","text":"Input Stack:k \u21e8 Output Stack:vars[k] <p>Get the value of a variable and push it on the stack. </p> <p>Example:</p> <pre>k,v,:set,\nk,:get\n</pre> PosInputOutput 0 k v"},{"location":"asl/ref/gt/","title":"gt","text":"<p>Greater than operator. There are two variants of the <code>:gt</code> operator.</p>"},{"location":"asl/ref/gt/#choosing","title":"Choosing","text":"Input Stack:v: Stringk: String \u21e8 Output Stack:(k &gt; v): Query <p>This first variant is used for choosing the set of time series to operate on. It selects time series that have a value for a key that is greater than a specified value. For example, consider the following query:</p> <pre>name,ssCpuSystem,:gt\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp i-0abc ssCpuUser api i-0456"},{"location":"asl/ref/gt/#math","title":"Math","text":"Input Stack:ts2: TimeSeriesExprts1: TimeSeriesExpr \u21e8 Output Stack:(ts1 &gt; ts2): TimeSeriesExpr <p>Compute a new time series where each interval has the value <code>(a &gt; b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series. For example:</p> Time a b a &gt; b 00:01 0.0 0.0 0.0 00:01 0.0 1.0 0.0 00:02 1.0 0.0 1.0 00:03 1.0 1.0 0.0 00:04 0.5 1.7 0.0 <p>The result will be a signal time series that will be <code>1.0</code> for intervals where the condition is true and <code>0.0</code> for intervals where it is false.</p> <p>Example:</p> BeforeAfter <pre>minuteOfHour,:time,\nhourOfDay,:time\n</pre><pre>minuteOfHour,:time,\nhourOfDay,:time,\n:gt\n</pre>"},{"location":"asl/ref/has/","title":"has","text":"Input Stack:k: String \u21e8 Output Stack:Query <p>Select time series that have a specified key. For example, consider the following query:</p> <pre>nf.node,:has\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp ssCpuUser api i-0456"},{"location":"asl/ref/head/","title":"head","text":"Input Stack:n: IntTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Shorthand equivalent to writing: <code>:limit</code></p> <p>Example:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n2,:head\n</pre>"},{"location":"asl/ref/heatmap/","title":"heatmap","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Since 1.8.</p> <p>Plot the time series as a heatmap.</p> <p>See heatmap for more information.</p> <p>Example:</p> Default <pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:heatmap\n</pre>"},{"location":"asl/ref/in/","title":"in","text":"Input Stack:vs: List[String]k: String \u21e8 Output Stack:(k in vs): Query <p>Select time series where the value for a key is in the specified set. For example, consider the following query:</p> <pre>name,(,ssCpuUser,ssCpuSystem,),:in\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp i-0abc ssCpuUser api i-0456"},{"location":"asl/ref/integral/","title":"integral","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Sum the values across the evaluation context. This is typically used to approximate the distinct number of events that occurred. If the input is non-negative, then each datapoint for the output line will represent the area under the input line from the start of the graph to the time for that datapoint. Missing values, <code>NaN</code>, will be treated as zeroes. For example:</p> Input :integral 0 0 1 1 -1 0 NaN 0 0 0 1 1 2 3 1 4 1 5 0 5 <p>For a counter, each data point represents the average rate per second over the step interval. To compute the total amount incremented, the value first needs to be converted to a rate per step interval. This conversion can be performed using the :per-step operation.</p> <p>Examples: </p> BeforeAfter <pre>1\n</pre><pre>1,:integral\n</pre> BeforeAfter <pre>name,requestsPerSecond,:eq,\n:sum,\n:per-step\n</pre><pre>name,requestsPerSecond,:eq,\n:sum,\n:per-step,\n:integral\n</pre>"},{"location":"asl/ref/le/","title":"le","text":"<p>Less than or equal operator. There are two variants of the <code>:le</code> operator.</p>"},{"location":"asl/ref/le/#choosing","title":"Choosing","text":"Input Stack:v: Stringk: String \u21e8 Output Stack:(k &lt;= v): Query <p>This first variant is used for choosing the set of time series to operate on. It selects time series that have a value for a key that is less than or equal to a specified value. For example, consider the following query:</p> <pre>name,ssCpuSystem,:le\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp i-0abc ssCpuUser api i-0456"},{"location":"asl/ref/le/#math","title":"Math","text":"Input Stack:ts2: TimeSeriesExprts1: TimeSeriesExpr \u21e8 Output Stack:(ts1 &lt;= ts2): TimeSeriesExpr <p>Compute a new time series where each interval has the value <code>(a &lt;= b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series. For example:</p> Time a b a &lt;= b 00:01 0.0 0.0 1.0 00:01 0.0 1.0 1.0 00:02 1.0 0.0 0.0 00:03 1.0 1.0 1.0 00:04 0.5 1.7 1.0 <p>The result will be a signal time series that will be <code>1.0</code> for intervals where the condition is true and <code>0.0</code> for intervals where it is false.</p> <p>Example:</p> BeforeAfter <pre>minuteOfHour,:time,\nhourOfDay,:time\n</pre><pre>minuteOfHour,:time,\nhourOfDay,:time,\n:le\n</pre>"},{"location":"asl/ref/legend/","title":"legend","text":"Input Stack:StringTimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Set the legend text. Legends can contain variables based on the exact keys matched in the query clause and keys used in a group by. Variables start with a <code>$</code> sign and can optionally be enclosed between parentheses. The parentheses are required for cases where the characters immediately following the name could be a part of the name. If a variable is not defined, then the name of the variable will be used as the substitution value.</p> <p>The variable <code>atlas.offset</code> can be used to indicate the time shift used for the underlying data.</p> <p>Examples:</p> BeforeAfter <pre>name,sps,:eq,\n(,name,),:by\n</pre><pre>name,sps,:eq,\n(,name,),:by,\n$name,:legend\n</pre> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\ncluster+$nf.cluster,:legend\n</pre>"},{"location":"asl/ref/limit/","title":"limit","text":"Input Stack:n: IntTimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Restrict the output to the first <code>N</code> lines from the input expression. The lines will be chosen in order based on the sort and order used.</p> <p>Example:</p> AfterAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n3,:limit\n</pre>"},{"location":"asl/ref/line/","title":"line","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Change the line style to be line. This is the default mode and usually does not need to be set explicitly.</p> <p>See the line style examples page for more information.</p> <p>Example:</p> Default <pre>name,sps,:eq,\n:sum,\n:line\n</pre>"},{"location":"asl/ref/list/","title":"list","text":"Input Stack:... \u21e8 Output Stack:List[?] <p>Pop all items off the stack and push them as a list.</p> <p>Example:</p> <pre>a,b,:list\n</pre> PosInputOutput 0 b List(b, a) 1 a <pre>,:list\n</pre> PosInputOutput 0 List()"},{"location":"asl/ref/ls/","title":"ls","text":"Input Stack:StringTimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Set the line style. The value should be one of:</p> <ul> <li><code>line</code>: this is the default, draws a normal line.</li> <li><code>area</code>: fill in the space between the line value and 0 on the Y-axis.</li> <li><code>stack</code>: stack the filled area on to the previous stacked lines on the same axis.</li> <li><code>vspan</code>: non-zero datapoints will be drawn as a vertical span.</li> </ul> <p>See the line style examples page for more information.</p> <p>Example:</p> LineArea <pre>name,sps,:eq,\n:sum,\n(,name,),:by,\nline,:ls\n</pre><pre>name,sps,:eq,\n:sum,\n(,name,),:by,\narea,:ls\n</pre> StackVSpan <pre>name,sps,:eq,\n:sum,\n(,nf.cluster,),:by,\nstack,:ls\n</pre><pre>name,sps,:eq,\n:sum,\n(,name,),:by,\n200e3,:gt,\nvspan,:ls\n</pre>"},{"location":"asl/ref/lt/","title":"lt","text":"<p>Less than operator. There are two variants of the <code>:lt</code> operator.</p>"},{"location":"asl/ref/lt/#choosing","title":"Choosing","text":"Input Stack:v: Stringk: String \u21e8 Output Stack:(k &lt; v): Query <p>This first variant is used for choosing the set of time series to operate on. It selects time series that have a value for a key that is less than a specified value. For example, consider the following query:</p> <pre>name,ssCpuSystem,:lt\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp i-0abc ssCpuUser api i-0456"},{"location":"asl/ref/lt/#math","title":"Math","text":"Input Stack:ts2: TimeSeriesExprts1: TimeSeriesExpr \u21e8 Output Stack:(ts1 &lt; ts2): TimeSeriesExpr <p>Compute a new time series where each interval has the value <code>(a &lt; b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series. For example:</p> Time a b a &lt; b 00:01 0.0 0.0 0.0 00:01 0.0 1.0 1.0 00:02 1.0 0.0 0.0 00:03 1.0 1.0 0.0 00:04 0.5 1.7 1.0 <p>The result will be a signal time series that will be <code>1.0</code> for intervals where the condition is true and <code>0.0</code> for intervals where it is false.</p> <p>Example:</p> BeforeAfter <pre>minuteOfHour,:time,\nhourOfDay,:time\n</pre><pre>minuteOfHour,:time,\nhourOfDay,:time,\n:lt\n</pre>"},{"location":"asl/ref/lw/","title":"lw","text":"Input Stack:IntTimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>The width of the stroke used when drawing the line.</p> <p>Example:</p> BeforeAfter <pre>name,sps,:eq,\n:sum,\n(,name,),:by\n</pre><pre>name,sps,:eq,\n:sum,\n(,name,),:by,\n2,:lw\n</pre>"},{"location":"asl/ref/map/","title":"map","text":"Input Stack:function: Listitems: List \u21e8 Output Stack:List(function(items[0], ..., items[N-1]) <p>Create a new list by applying a function to all elements of a list. </p> <p>Example:</p> <pre>(,a%s,b%s,),(,(,.netflix.com,),:format,\n),:map\n</pre> PosInputOutput 0 List((, .netflix.com, ), :format) List(a.netflix.com, b.netflix.com) 1 List(a%s, b%s)"},{"location":"asl/ref/max/","title":"max","text":"<p>Max aggregation operator. There are two variants of the <code>:max</code> operator.</p>"},{"location":"asl/ref/max/#aggregation","title":"Aggregation","text":"Input Stack:Query \u21e8 Output Stack:AggregationFunction <p>Select the maximum value for corresponding times across all matching time series.</p> <pre>name,ssCpuUser,:eq,\n:max\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the aggregate result:</p> Namenf.appnf.nodeData ssCpuUser alerttest i-0123 [1.0, 2.0, NaN] ssCpuSystem alerttest i-0123 [3.0, 4.0, 5.0] ssCpuUser nccp i-0abc [8.0, 7.0, 6.0] ssCpuSystem nccp i-0abc [6.0, 7.0, 8.0] numRequests nccp i-0abc [1.0, 2.0, 4.0] ssCpuUser api i-0456 [1.0, 2.0, 2.0] <p>The values from the corresponding intervals will be aggregated. For the first interval using the sample data above the values are <code>1.0</code>, <code>8.0</code>, and <code>1.0</code>. Each value other than <code>NaN</code> contributes one to the max. This leads to a final result of:</p> NameData ssCpuUser [8.0, 7.0, 6.0] <p>The only tags for the aggregated result are those that are matched exactly (:eq clause) as part of the choosing criteria or are included in a group by.</p>"},{"location":"asl/ref/max/#math","title":"Math","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Select the maximum value for corresponding times across the time series resulting from the input expression. This is typically used when there is a need to use some other aggregation for the grouping. Example:</p> BeforeAfter <pre>name,sps,:eq,\n:sum,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n:sum,\n(,nf.cluster,),:by,\n:max\n</pre>"},{"location":"asl/ref/median/","title":"median","text":"Input Stack:Query \u21e8 Output Stack:TimeSeriesExpr <p>Shorthand equivalent to writing: <code>(,50,),:percentiles</code></p> BeforeAfter <pre>name,requestLatency,:eq\n</pre><pre>name,requestLatency,:eq,\n:median\n</pre>"},{"location":"asl/ref/min/","title":"min","text":"<p>Min aggregation operator. There are two variants of the <code>:min</code> operator.</p>"},{"location":"asl/ref/min/#aggregation","title":"Aggregation","text":"Input Stack:Query \u21e8 Output Stack:AggregationFunction <p>Select the minimum value for corresponding times across all matching time series.</p> <pre>name,ssCpuUser,:eq,\n:min\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the aggregate result:</p> Namenf.appnf.nodeData ssCpuUser alerttest i-0123 [1.0, 2.0, NaN] ssCpuSystem alerttest i-0123 [3.0, 4.0, 5.0] ssCpuUser nccp i-0abc [8.0, 7.0, 6.0] ssCpuSystem nccp i-0abc [6.0, 7.0, 8.0] numRequests nccp i-0abc [1.0, 2.0, 4.0] ssCpuUser api i-0456 [1.0, 2.0, 2.0] <p>The values from the corresponding intervals will be aggregated. For the first interval using the sample data above the values are <code>1.0</code>, <code>8.0</code>, and <code>1.0</code>. Each value other than <code>NaN</code> contributes one to the max. This leads to a final result of:</p> NameData ssCpuUser [1.0, 2.0, 2.0] <p>The only tags for the aggregated result are those that are matched exactly (:eq clause) as part of the choosing criteria or are included in a group by.</p>"},{"location":"asl/ref/min/#math","title":"Math","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Select the minimum value for corresponding times across the time series resulting from the input expression. This is typically used when there is a need to use some other aggregation for the grouping. Example:</p> BeforeAfter <pre>name,sps,:eq,\n:sum,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n:sum,\n(,nf.cluster,),:by,\n:min\n</pre>"},{"location":"asl/ref/mul/","title":"mul","text":"Input Stack:ts2: TimeSeriesExprts1: TimeSeriesExpr \u21e8 Output Stack:(ts1 * ts2): TimeSeriesExpr <p>Compute a new time series where each interval has the value <code>(a * b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series. <code>NaN</code>s in a series when other series are present are treated as <code>1</code>.</p> <p>Example multiplying a constant:</p> BeforeAfter <pre>name,sps,:eq\n</pre><pre>name,sps,:eq,\n1024,:mul\n</pre> <p>Example multiplying two series:</p> BeforeAfter <pre>name,requestLatency,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by\n</pre><pre>name,requestLatency,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by,\n:mul\n</pre>"},{"location":"asl/ref/named-rewrite/","title":"named-rewrite","text":"Input Stack:name: Stringrewritten: TimeSeriesExproriginal: TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Internal operation used by some macros to provide a more user friendly display expression. The expanded version will get used for evaluation, but if a new expression is generated from the parsed expression tree it will use the original version along with the named of the macro.</p> BeforeAfter <pre>name,ssCpuUser,:eq,\n:dup,\n:dup,\n:sum,\n:swap,\n:count,\n:div\n</pre><pre>name,ssCpuUser,:eq,\n:dup,\n:dup,\n:sum,\n:swap,\n:count,\n:div,\navg,:named-rewrite\n</pre>"},{"location":"asl/ref/ndrop/","title":"ndrop","text":"Input Stack:Na0...aN \u21e8 Output Stack:aN <p>Remove the top N items on the stack.</p> <p>Example:</p> <pre>a,0,:ndrop\n</pre> PosInputOutput 0 0 a 1 a <pre>a,b,c,2,:ndrop\n</pre> PosInputOutput 0 2 a 1 c 2 b 3 a <pre>a,b,c,4,:ndrop\n</pre> PosInputOutput 0 4 1 c 2 b 3 a <pre>,:ndrop\n</pre> <p>Warning</p> <p>Throws an exception due to missing the <code>N</code> param.</p>"},{"location":"asl/ref/neg/","title":"neg","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Compute a new time series where each interval has the negated value of the input time series.</p> <p>Example:</p> 064-64 <pre>0,:neg\n</pre><pre>64,:neg\n</pre><pre>-64,:neg\n</pre>"},{"location":"asl/ref/nip/","title":"nip","text":"Input Stack:? \u21e8 Output Stack:? <p>Shorthand equivalent to writing: <code>:swap,:drop</code></p> <p>Example:</p> <pre>a,b,:nip\n</pre> PosInputOutput 0 b b 1 a"},{"location":"asl/ref/nlist/","title":"nlist","text":"Input Stack:Na0...aN \u21e8 Output Stack:List(aN-1, ..., a0)aN <p>Create a list with the top N items on the stack.</p> <p>Since: 1.5.0</p> <p>Examples:</p> <pre>a,0,:nlist\n</pre> PosInputOutput 0 0 List() 1 a a <pre>a,b,c,2,:nlist\n</pre> PosInputOutput 0 2 List(b, c) 1 c a 2 b 3 a <pre>a,b,c,4,:nlist\n</pre> PosInputOutput 0 4 List(a, b, c) 1 c 2 b 3 a"},{"location":"asl/ref/node-avg/","title":"node-avg","text":"Input Stack:Query \u21e8 Output Stack:TimeSeriesExpr <p>A helper to compute an average using the <code>poller.asg.instance</code> metric as the denominator. The common infrastructure tags will be used to restrict the scope for the denominator. This operator should be used instead of :avg if the goal is to compute an average per node.</p> <pre>name,sps,:eq,\nnf.app,nccp,:eq,\n:and,\n:node-avg\n</pre>"},{"location":"asl/ref/not/","title":"not","text":"Input Stack:q: Query \u21e8 Output Stack:(!q): Query <p>Select time series that have a specified key. For example, consider the following query:</p> <pre>nf.node,:has,\n:not\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp ssCpuUser api i-0456"},{"location":"asl/ref/offset/","title":"offset","text":"Input Stack:DurationTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Warning</p> <p>Note that there is a deprecated <code>List[Duration]</code> variant that only modifes the presentation at the end. It cannot be used along with math operations.</p> <p>Shift the time frame to use when fetching the data. This is used to look at a previous interval as a point of reference, e.g., day-over-day or week-over-week. Offset cannot be used with streaming execution of the query, consider using the delay operator for short intervals to detect a change.</p> <p>Examples:</p> BeforeAfterCombined <pre>name,sps,:eq,\n(,name,),:by\n</pre><pre>name,sps,:eq,\n(,name,),:by,\n1w,:offset\n</pre><pre>name,sps,:eq,\n(,name,),:by,\n:dup,\n1w,:offset\n</pre> BeforeAfterCombined <pre>name,sps,:eq,\n(,name,),:by\n</pre><pre>name,sps,:eq,\n(,name,),:by,\nPT1H,:offset\n</pre><pre>name,sps,:eq,\n(,name,),:by,\n:dup,\nPT1H,:offset\n</pre>"},{"location":"asl/ref/or/","title":"or","text":"<p>There are two variants of the <code>:or</code> operator.</p>"},{"location":"asl/ref/or/#choosing","title":"Choosing","text":"Input Stack:q2: Queryq1: Query \u21e8 Output Stack:(q1 OR q2): Query <p>This first variant is used for choosing the set of time series to operate on. It is a binary operator that matches if either of the sub-queries match. For example, consider the following query:</p> <pre>nf.app,alerttest,:eq,\nname,ssCpuUser,:eq,\n:or\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp i-0abc ssCpuUser api i-0456"},{"location":"asl/ref/or/#math","title":"Math","text":"Input Stack:ts2: TimeSeriesExprts1: TimeSeriesExpr \u21e8 Output Stack:(ts1 OR ts2): TimeSeriesExpr <p>Compute a new time series where each interval has the value <code>(a OR b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series. For example:</p> Time a b a OR b 00:01 0.0 0.0 0.0 00:01 0.0 1.0 1.0 00:02 1.0 0.0 1.0 00:03 1.0 1.0 1.0 00:04 0.5 1.7 1.0 <p>The result will be a signal time series that will be <code>1.0</code> for all intervals where the corresponding values of <code>a</code> or <code>b</code> are non-zero. Example:</p> BeforeAfter <pre>minuteOfDay,:time,\n:dup,\n300,:gt,\n:swap,\n290,:lt\n</pre><pre>minuteOfDay,:time,\n:dup,\n300,:gt,\n:swap,\n290,:lt,\n:or\n</pre>"},{"location":"asl/ref/order/","title":"order","text":"Input Stack:StringTimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Order to use for sorting results. Supported values are <code>asc</code> and <code>desc</code> for ascending and descending order respectively. Default is <code>asc</code>.</p> <p>Since: 1.5</p> <p>Examples:</p> SortedDefault <pre>name,sps,:eq,\n:sum,\n(,nf.cluster,),:by,\nmax,:sort,\nasc,:order\n</pre><pre>name,sps,:eq,\n:sum,\n(,nf.cluster,),:by,\ndesc,:order\n</pre>"},{"location":"asl/ref/over/","title":"over","text":"Input Stack:ba \u21e8 Output Stack:aba <p>Copy the item in the second position on the stack to the top. </p> <p>Example:</p> <pre>a,b,:over\n</pre> PosInputOutput 0 b a 1 a b 2 a"},{"location":"asl/ref/palette/","title":"palette","text":"Input Stack:StringTimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Set the palette to use for the results of an expression. This operator is allows for scoping a palette to a particular group by instead of to all lines that share the same axis. A common use-case is to have multiple stacked group by expressions using different palettes. For example, suppose I want to create a graph showing overall request per second hitting my services with successful requests shown in shades of green and errors in shades of red. This can make it easy to visually see if a change is due to an increase in errors:</p> <p></p> <p>Or a spike in successful requests:</p> <p></p> <p>Examples:</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\nreds,:palette\n</pre> BeforeAfter <pre>name,sps,:eq,\n:sum,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n:sum,\n(,nf.cluster,),:by,\nreds,:palette\n</pre>"},{"location":"asl/ref/pct/","title":"pct","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Shorthand equivalent to writing: <code>:dup,:dup,:sum,:div,100,:mul,pct,:named-rewrite</code> The percent contribution of an individual time series to a group.</p> <p>Example:</p> <pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:pct\n</pre> BeforeAfterStack to 100% <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:pct\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:pct,\n:stack\n</pre>"},{"location":"asl/ref/per-step/","title":"per-step","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Converts a line from a rate per second to a rate based on the step size of the graph. This is useful for getting an estimate of the raw number of events for a given interval.</p> 064-64 <pre>0,:per-step\n</pre><pre>64,:per-step\n</pre><pre>-64,:per-step\n</pre>"},{"location":"asl/ref/percentiles-heatmap/","title":"percentiles-heatmap","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Since 1.8.</p> <p>Group the metric by the <code>percentiles</code> tag and plot the data as a heatmap. Requires  that the metric to be recorded as a percentile.</p> <p>See heatmap for more information.</p> <p>Shorthand equivalent of writing <code>(,percentile,),:by,:heatmap</code></p> <p>Example:</p> Default <pre>name,requestLatency,:eq,\n:percentiles-heatmap\n</pre>"},{"location":"asl/ref/percentiles/","title":"percentiles","text":"Input Stack:percentiles: ListQuery \u21e8 Output Stack:TimeSeriesExpr <p>Estimate percentiles for a timer or distribution summary. The data must have been published appropriately to allow the approximation. If using spectator, then see PercentileTimer and PercentileDistributionSummary helper classes.</p> <p>The percentile values can be shown in the legend using <code>$percentile</code>.</p> <p>Since: 1.5.0 (first in 1.5.0-rc.4)</p> BeforeAfter <pre>name,requestLatency,:eq\n</pre><pre>name,requestLatency,:eq,\n(,25,50,90,),:percentiles\n</pre>"},{"location":"asl/ref/pick/","title":"pick","text":"Input Stack:Na0...aN \u21e8 Output Stack:aN-1a0...aN <p>Pick an item in the stack and put a copy on the top.</p> <p>Since: 1.5.0</p> <p>Example:</p> <pre>a,0,:pick\n</pre> PosInputOutput 0 0 a 1 a a <pre>a,b,0,:pick\n</pre> PosInputOutput 0 0 b 1 b b 2 a a <pre>a,b,1,:pick\n</pre> PosInputOutput 0 1 a 1 b b 2 a a"},{"location":"asl/ref/pow/","title":"pow","text":"Input Stack:TimeSeriesExprTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Compute a new time series where each interval has the value <code>(a power b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series.</p> <p>Examples:</p> BeforeAfter <pre>name,sps,:eq\n</pre><pre>name,sps,:eq,\n42,:pow\n</pre> BeforeAfter <pre>name,sps,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by\n</pre><pre>name,sps,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by,\n:pow\n</pre>"},{"location":"asl/ref/random/","title":"random","text":"Input Stack: \u21e8 Output Stack:TimeSeriesExpr <p>Generate a time series that appears to be random noise for the purposes of experimentation and generating sample data. To ensure that the line is deterministic and reproducible it actually is based on a hash of the timestamp. Each datapoint is a value between 0.0 and 1.0.</p> Random <pre>:random\n</pre>"},{"location":"asl/ref/re/","title":"re","text":"Input Stack:v: Stringk: String \u21e8 Output Stack:(k=~/^v/): Query <p>Warning</p> <p>Regular expressions can be expensive to check and should be avoided if possible. When designing data to publish ensure that common query patterns would not need the use of regular expressions.</p> <p>Select time series where the value for a key matches the specified regular expression. For example, consider the following query:</p> <pre>name,ssCpu,:re\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp i-0abc ssCpuUser api i-0456 <p>The regular expression value will be automatically anchored at the start and the matching is case sensitive. Always try to have a simple prefix on the expression to allow for more efficient matching of the expression. For more information on supported patterns, see the Java regular expressions documentation.</p>"},{"location":"asl/ref/reic/","title":"reic","text":"Input Stack:v: Stringk: String \u21e8 Output Stack:(k=~/^v/i): Query <p>Warning</p> <p>Ignoring the case will always result if a full scan for the key. This should be used sparingly and only for tag queries. If a case-insensitive match is not required, use :re intead.</p> <p>Select time series where the value for a key matches the specified regular expression with case insensitive matching. For example, consider the following query:</p> <pre>name,ssCPU,:reic\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp i-0abc ssCpuUser api i-0456 <p>Notice that the casing for the query does not match the data. The regular expression value will be automatically anchored at the start. For more information on supported patterns, see the Java regular expressions documentation.</p>"},{"location":"asl/ref/roll/","title":"roll","text":"Input Stack:Na0...aN \u21e8 Output Stack:aN-1a0...aN-2aN <p>Rotate an item in the stack and put it on the top.</p> <p>Since: 1.5.0 </p> <p>Example:</p> <pre>a,0,:roll\n</pre> PosInputOutput 0 0 a 1 a <pre>a,b,0,:roll\n</pre> PosInputOutput 0 0 b 1 b a 2 a <pre>a,b,1,:roll\n</pre> PosInputOutput 0 1 a 1 b b 2 a"},{"location":"asl/ref/rolling-count/","title":"rolling-count","text":"Input Stack:n: IntTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Number of occurrences within a specified window. This operation is frequently used in alerting expressions to reduce noise. For example:</p> <pre><code># Check to see if average cpu usage is &gt; 80%\nname,cpuUser,:eq,:avg,80,:gt,\n\n# Only alert if that is true for more than 3 of the last 5\n# datapoints\n5,:rolling-count,3,:gt\n</code></pre> <p>A value is counted if it is non-zero. Missing values, <code>NaN</code>, will be treated as zeroes. For example:</p> Input 3,:rolling-count 0 0 1 1 -1 2 NaN 2 0 1 1 1 1 2 1 3 1 3 0 2 <p>The window size, <code>n</code>, is the number of datapoints to consider including the current value. Note that it is based on datapoints not a specific amount of time. As a result the number of occurrences will be reduced when transitioning to a larger time frame that causes consolidation.</p> BeforeAfter <pre>:random,\n0.4,:gt\n</pre><pre>:random,\n0.4,:gt,\n5,:rolling-count\n</pre>"},{"location":"asl/ref/rolling-max/","title":"rolling-max","text":"Input Stack:n: IntTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Maximum value within a specified window. This operation can be used in alerting expressions to find a lower bound for noisy data based on recent samples. For example:</p> <pre><code>name,sps,:eq,:sum,\n:dup,\n5,:rolling-max\n</code></pre> <p>Missing values, <code>NaN</code>, will be ignored when computing the min. If all values within the window are <code>NaN</code>, then <code>NaN</code> will be emitted. For example:</p> Input 3,:rolling-max 0 0 1 1 -1 1 NaN 1 0 0 1 1 1 1 1 1 1 1 0 1 <p>The window size, <code>n</code>, is the number of datapoints to consider including the current value. Note that it is based on datapoints not a specific amount of time. As a result the number of occurrences will be reduced when transitioning to a larger time frame that causes consolidation.</p> <p>Since: 1.6</p> BeforeAfter <pre>:random,\n0.4,:gt\n</pre><pre>:random,\n0.4,:gt,\n5,:rolling-max\n</pre>"},{"location":"asl/ref/rolling-mean/","title":"rolling-mean","text":"Input Stack:minNumValues: Intn: IntTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Mean of the values within a specified window. The mean will only be emitted if there are at least a minimum number of actual values (not <code>NaN</code>) within the window. Otherwise <code>NaN</code> will be emitted for that time period.</p> Input 3,2,:rolling-mean 0 NaN 1 0.5 -1 0.0 NaN 0.0 NaN NaN 0 NaN 1 0.5 1 0.667 1 1 0 0.667 <p>The window size, <code>n</code>, is the number of datapoints to consider including the current value. There must be at least <code>minNumValues</code> non-NaN values within that window before it will emit a mean. Note that it is based on datapoints, not a specific amount of time. As a result the number of occurrences will be reduced when transitioning to a larger time frame that causes consolidation.</p> <p>Since: 1.6</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n5,3,:rolling-mean\n</pre>"},{"location":"asl/ref/rolling-min/","title":"rolling-min","text":"Input Stack:n: IntTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Minimum value within a specified window. This operation can be used in alerting expressions to find a lower bound for noisy data based on recent samples. For example:</p> <pre><code>name,sps,:eq,:sum,\n:dup,\n5,:rolling-min\n</code></pre> <p>Missing values, <code>NaN</code>, will be ignored when computing the min. If all values within the window are <code>NaN</code>, then <code>NaN</code> will be emitted. For example:</p> Input 3,:rolling-min 0 0 1 0 -1 -1 NaN -1 0 -1 1 0 1 0 1 1 1 1 0 0 <p>The window size, <code>n</code>, is the number of datapoints to consider including the current value. Note that it is based on datapoints not a specific amount of time. As a result the number of occurrences will be reduced when transitioning to a larger time frame that causes consolidation.</p> <p>Since: 1.6</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n5,:rolling-min\n</pre>"},{"location":"asl/ref/rolling-sum/","title":"rolling-sum","text":"Input Stack:n: IntTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Sum of the values within a specified window.</p> Input 3,:rolling-sum 0 0.0 1 1.0 -1 0.0 NaN 0.0 NaN -1.0 NaN NaN 1 1.0 1 2.0 1 3.0 0 2.0 <p>The window size, <code>n</code>, is the number of datapoints to consider including the current value. Note that it is based on datapoints, not a specific amount of time. As a result the number of occurrences will be reduced when transitioning to a larger time frame that causes consolidation.</p> <p>Since: 1.6</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n5,:rolling-sum\n</pre>"},{"location":"asl/ref/rot/","title":"rot","text":"Input Stack:b...a \u21e8 Output Stack:ab... <p>Rotate the stack so that the item at the bottom is now at the top.</p> <p>Example:</p> <pre>a,b,c,d,:rot\n</pre> PosInputOutput 0 d a 1 c d 2 b c 3 a b"},{"location":"asl/ref/s/","title":"s","text":"Input Stack:replacement: StringsearchPattern: StringTimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Perform a search and replace on the legend strings. This command is similar to the global search and replace (<code>s/regexp/replace/g</code>) operation from tools like vim or sed.</p> <p>The replacement string can use variables to refer to the capture groups of the input expression. The syntax is that same as for legends.</p> <p>Since: 1.6</p> <p>Examples:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by,\n$nf.cluster,:legend\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n$nf.cluster,:legend,\n^nccp-(.*)$,$1,:s\n</pre> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by,\n$nf.cluster,:legend\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n$nf.cluster,:legend,\n^nccp-(?.*)$,$stack,:s\n\n\n\nBeforeAfter\n\n<pre>name,sps,:eq,\n(,nf.cluster,),:by,\n$nf.cluster,:legend\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n$nf.cluster,:legend,\nnccp-,_,:s\n</pre>\n\n\nBeforeAfter\n\n<pre>name,sps,:eq,\n(,nf.cluster,),:by,\n$nf.cluster,:legend\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n$nf.cluster,:legend,\n([a-z]),_$1,:s\n</pre>"},{"location":"asl/ref/sdes-fast/","title":"sdes-fast","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Helper for computing sliding DES using settings to quickly adjust to the input line. See recommended values for more information.</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n:sdes-fast\n</pre>"},{"location":"asl/ref/sdes-simple/","title":"sdes-simple","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Shorthand equivalent to writing: <code>:dup,10,0.1,0.5,:sdes,sdes-simple,:named-rewrite</code></p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n:sdes-simple\n</pre>"},{"location":"asl/ref/sdes-slow/","title":"sdes-slow","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Helper for computing sliding DES using settings to slowly adjust to the input line. See recommended values for more information. </p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n:sdes-slow\n</pre>"},{"location":"asl/ref/sdes-slower/","title":"sdes-slower","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Helper for computing sliding DES using settings to slowly adjust to the input line. See recommended values for more information. </p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n:sdes-slower\n</pre>"},{"location":"asl/ref/sdes/","title":"sdes","text":"Input Stack:beta: Doublealpha: Doubletraining: IntTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Variant of :des that is deterministic as long as the step size does not change. One of the common complaints with DES is that to get the same value for a given time you must start feeding in data at exactly the same time. So for normal graphs where it is computed using the window of the chart it will have slightly different predictions for a given time. As it is often used for alerting this makes it cumbersome to try and determine:</p> <ol> <li>Why an alarm fired</li> <li>When alarms would have fired for tuning</li> </ol> <p>Sliding DES uses two DES functions and alternates between them. One will get trained while the other is getting used, and then the one that was getting used will get reset and the roles swapped.</p> <pre><code> F1 | A |-- T1 --|-- P1 --|-- T1 --|-- P1 --|-- T1 --|\n F2 | A |        |-- T2 --|-- P2 --|-- T2 --|-- P2 --|\n\nResult:\n\n R  |-- NaN -----|-- P1 --|-- P2 --|-- P1 --|-- P2 --|\n</code></pre> <p>Both functions will ignore any data until it reaches a boundary, even multiple, of the training window. That is shown as <code>A</code> in the diagram above. The first function will then start training, <code>T1</code>, and after the training window the first predicted values, <code>P1</code>, will get generated. The ouput line will alternate between the predictions from both DES functions.</p> <p>The alternation between functions can cause the prediction line to look choppier than DES, e.g., on a gradual drop:</p> <p></p> <p>Further, since each prediction only considers data for a narrow window it will adjust to sharp changes faster. For example:</p> <p></p> <p>Since: 1.5.0</p> BeforeAfter <pre>name,requestsPerSecond,:eq,\n:sum,\n:per-step\n</pre><pre>name,requestsPerSecond,:eq,\n:sum,\n5,0.1,0.5,:sdes\n</pre>"},{"location":"asl/ref/set/","title":"set","text":"Input Stack:vk \u21e8 Output Stack: <p>Set the value of a variable.</p> <p>Example:</p> <pre>k,v,:set\n</pre> PosInputOutput 0 v 1 k"},{"location":"asl/ref/sort/","title":"sort","text":"Input Stack:StringTimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Sort the results of an expression in the legend by one of the summary statistics or by the legend text. The default behavior is to sort by the legend text. This will sort in ascending order by default, for descending order use order.</p> <p>Since: 1.5</p> <p>Example:</p> BeforeAfter <pre>name,sps,:eq,\n:sum,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n:sum,\n(,nf.cluster,),:by,\nmax,:sort\n</pre>"},{"location":"asl/ref/sqrt/","title":"sqrt","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Compute a new time series where each interval has the square root of the value from the input time series.</p> 064-64 <pre>0,:sqrt\n</pre><pre>64,:sqrt\n</pre><pre>-64,:sqrt\n</pre>"},{"location":"asl/ref/srandom/","title":"srandom","text":"Input Stack:seed: Int \u21e8 Output Stack:TimeSeriesExpr <p>Generate a time series that appears to be random noise for the purposes of experimentation and generating sample data. To ensure that the line is deterministic and reproducible it actually is based on a hash of the timestamp. The seed value is used to vary the values for the purposes of creating multiple different sample lines. Each datapoint is a value between 0.0 and 1.0.</p> <p>Example:</p> Seeded Random: /api/v1/graph?w=200&amp;h=125&amp;s=e-3h&amp;e=2012-01-01T07:00&amp;tz=UTC&amp;q=42,:srandom @@@"},{"location":"asl/ref/sset/","title":"sset","text":"Input Stack:kv \u21e8 Output Stack: <p>Shorthand equivalent to writing: <code>:swap,:set</code> </p> <p>Example:</p> <pre>a,b,:sset\n</pre> PosInputOutput 0 b 1 a"},{"location":"asl/ref/stack/","title":"stack","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Change the line style to be stack. In this mode the line will be filled to the previous stacked line on the same axis.</p> <p>See the line style examples page for more information.</p> <p>Example:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:stack\n</pre>"},{"location":"asl/ref/starts/","title":"starts","text":"Input Stack:v: Stringk: String \u21e8 Output Stack:Query <p>Select time series where the value for a key has the specified prefix. For example, consider the following query:</p> <pre>name,ssCpu,:starts\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the result set:</p> Namenf.appnf.node ssCpuUser alerttest i-0123 ssCpuSystem alerttest i-0123 ssCpuUser nccp i-0abc ssCpuSystem nccp i-0abc numRequests nccp i-0abc ssCpuUser api i-0456"},{"location":"asl/ref/stat-avg-mf/","title":"stat-avg-mf","text":"<p>Warning</p> <p>Deprecated: use :stat instead.</p> Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Equivalent to <code>avg,:stat</code>. Example of usage:</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n:stat-avg-mf\n</pre>"},{"location":"asl/ref/stat-avg/","title":"stat-avg","text":"Input Stack: \u21e8 Output Stack:TimeSeriesExpr <p>Represents the <code>avg,:stat</code> of the input time series when used with the filter operation. The filter operator will automatically fill in the input when used so the user does not need to repeat the input expression for the filtering criteria.</p> <p>Example of restricting to lines that have an average value greater than 5k and less than 20k:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:stat-avg,\n5e3,:gt,\n:stat-avg,\n20e3,:lt,\n:and,\n:filter\n</pre>"},{"location":"asl/ref/stat-count/","title":"stat-count","text":"Input Stack: \u21e8 Output Stack:TimeSeriesExpr <p>Represents the <code>count,:stat</code> of the input time series when used with the filter operation. The filter operator will automatically fill in the input when used so the user does not need to repeat the input expression for the filtering criteria.</p> <p>Example of restricting to lines where the count value is greater than 50:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:stat-count,\n50,:gt,\n:filter\n</pre>"},{"location":"asl/ref/stat-last/","title":"stat-last","text":"Input Stack: \u21e8 Output Stack:TimeSeriesExpr <p>Represents the <code>last,:stat</code> of the input time series when used with the filter operation. The filter operator will automatically fill in the input when used so the user does not need to repeat the input expression for the filtering criteria.</p> <p>Example of restricting to lines where the last value is greater than 5k and less than 20k:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:stat-last,\n5e3,:gt,\n:stat-last,\n20e3,:lt,\n:and,\n:filter\n</pre>"},{"location":"asl/ref/stat-max-mf/","title":"stat-max-mf","text":"<p>Warning</p> <p>Deprecated: use :stat instead.</p> Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Equivalent to <code>max,:stat</code>. Example of usage:</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n:stat-max-mf\n</pre>"},{"location":"asl/ref/stat-max/","title":"stat-max","text":"Input Stack: \u21e8 Output Stack:TimeSeriesExpr <p>Represents the <code>max,:stat</code> of the input time series when used with the filter operation. The filter operator will automatically fill in the input when used so the user does not need to repeat the input expression for the filtering criteria.</p> <p>Example of restricting to lines that have a maximum value greater than 5k and less than 20k:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:stat-max,\n5e3,:gt,\n:stat-max,\n20e3,:lt,\n:and,\n:filter\n</pre>"},{"location":"asl/ref/stat-min-mf/","title":"stat-min-mf","text":"<p>Warning</p> <p>Deprecated: use :stat instead.</p> Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Equivalent to <code>min,:stat</code>. Example of usage:</p> BeforeAfter <pre>name,sps,:eq,\n:sum\n</pre><pre>name,sps,:eq,\n:sum,\n:stat-min-mf\n</pre>"},{"location":"asl/ref/stat-min/","title":"stat-min","text":"Input Stack: \u21e8 Output Stack:TimeSeriesExpr <p>Represents the <code>min,:stat</code> of the input time series when used with the filter operation. The filter operator will automatically fill in the input when used so the user does not need to repeat the input expression for the filtering criteria.</p> <p>Example of restricting to lines that have a minimum value greater than 5k and less than 20k:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:stat-min,\n5e3,:gt,\n:stat-min,\n20e3,:lt,\n:and,\n:filter\n</pre>"},{"location":"asl/ref/stat-total/","title":"stat-total","text":"Input Stack: \u21e8 Output Stack:TimeSeriesExpr <p>Represents the <code>total,:stat</code> of the input time series when used with the filter operation. The filter operator will automatically fill in the input when used so the user does not need to repeat the input expression for the filtering criteria.</p> <p>Example of restricting to lines where the sum of all data points for the line is greater than 1M and less than 4M:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:stat-total,\n1e6,:gt,\n:stat-total,\n4e6,:lt,\n:and,\n:filter\n</pre>"},{"location":"asl/ref/stat/","title":"stat","text":"Input Stack:StringTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Create a summary time series showing the value of the specified summary statistic for the data points of the input time series. Valid statistic values are <code>avg</code>, <code>count</code>, <code>max</code>, <code>min</code>, <code>last</code>, and <code>total</code>. The graph below shows <code>avg</code>, <code>max</code>, <code>min</code>, and <code>last</code> for a simple input time series:</p> <p></p> <p>The <code>count</code> is the number of data points for the time series. In the example above, that is five since the last value is <code>NaN</code>. The <code>total</code> is the sum of the data points for the time series.</p> <p>The most common usage of stats is in conjunction with :filter to restrict the set of results for grouped expression. When filtering, helper macros, <code>:stat-$(name)</code>, can be used to represent applying the statistic to the input time series being filtered without explicitly repeating the input expression.</p> <p>Example of usage:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\navg,:stat\n</pre>"},{"location":"asl/ref/stddev/","title":"stddev","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Compute the standard deviation for the results of a group by. If the underlying data is for a timer or distribution summary, then dist-stddev is likely a better choice.</p> <p>Since: 1.6</p> <p>Example:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\n:stddev\n</pre>"},{"location":"asl/ref/sub/","title":"sub","text":"Input Stack:ts2: TimeSeriesExprts1: TimeSeriesExpr \u21e8 Output Stack:(ts1 - ts2): TimeSeriesExpr <p>Compute a new time series where each interval has the value <code>(a subtractNaN b)</code> where <code>a</code> and <code>b</code> are the corresponding intervals in the input time series.</p> :sub 1.0 0.0 1.0 1.0 NaN Input 1 2.0 0.0 1.0 1.0 NaN Input 2 1.0 0.0 0.0 NaN NaN <p>Use the fsub operator to get strict floating point behavior.</p> <p>Example subtracting a constant:</p> BeforeAfter <pre>name,sps,:eq\n</pre><pre>name,sps,:eq,\n30e3,:sub\n</pre> <p>Example subtracting two series:</p> BeforeAfter <pre>name,requestLatency,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by\n</pre><pre>name,requestLatency,:eq,\n:sum,\nname,requestsPerSecond,:eq,\n:max,\n(,name,),:by,\n:sub\n</pre>"},{"location":"asl/ref/sum/","title":"sum","text":"<p>Sum aggregation operator. There are two variants of the <code>:sum</code> operator.</p>"},{"location":"asl/ref/sum/#aggregation","title":"Aggregation","text":"Input Stack:Query \u21e8 Output Stack:AggregationFunction <p>Compute the sum of all the time series that match the query. Sum is the default aggregate used if a query is specified with no explicit aggregate function. Example with implicit sum:</p> <pre>name,ssCpuUser,:eq\n</pre> <p>Equivalent example with explicit sum:</p> <pre>name,ssCpuUser,:eq,\n:sum\n</pre> <p>When matching against the sample data in the table below, the highlighted time series would be included in the aggregate result:</p> Namenf.appnf.nodeData ssCpuUser alerttest i-0123 [1.0, 2.0, NaN] ssCpuSystem alerttest i-0123 [3.0, 4.0, 5.0] ssCpuUser nccp i-0abc [8.0, 7.0, 6.0] ssCpuSystem nccp i-0abc [6.0, 7.0, 8.0] numRequests nccp i-0abc [1.0, 2.0, 4.0] ssCpuUser api i-0456 [1.0, 2.0, 2.0] <p>The values from the corresponding intervals will be aggregated. For the first interval using the sample data above the values are <code>1.0</code>, <code>8.0</code>, and <code>1.0</code>. Each value other than <code>NaN</code> contributes one to the sum. This leads to a final result of:</p> NameData ssCpuUser [10.0, 11.0, 8.0] <p>The only tags for the aggregated result are those that are matched exactly (:eq clause) as part of the choosing criteria or are included in a group by.</p>"},{"location":"asl/ref/sum/#math","title":"Math","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Compute the sum of all the time series from the input expression. This is typically used when there is a need to use some other aggregation for the grouping. Example:</p> BeforeAfter <pre>name,sps,:eq,\n:max,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n:max,\n(,nf.cluster,),:by,\n:sum\n</pre>"},{"location":"asl/ref/swap/","title":"swap","text":"Input Stack:ba \u21e8 Output Stack:ab <p>Swap the top two items on the stack. </p> <p>Example:</p> <pre>a,b,:swap\n</pre> PosInputOutput 0 b a 1 a b"},{"location":"asl/ref/time-span/","title":"time-span","text":"Input Stack:e: Strings: String \u21e8 Output Stack:TimeSeriesExpr <p>Generates a signal line based on the specified time range. The line will be 1 within the range and 0 for all other times. The format of the start and end times is the same as the start and end time parameters on the Graph API. If the time zone is not explicitly specified, then the value from the <code>tz</code> variable will get used. The default value for the <code>tz</code> variable is the primary time zone used for the graph.</p> <p>The following named times are supported for time spans:</p> Name Description gs Graph start time. ge Graph end time. s Start time for the span, can only be used for the end time. e End time for the span, can only be used for the start time. now Current time. epoch January 1, 1970 UTC. <p>Since: 1.6</p> <p>Example:</p> RelativeAbsolute <pre>e-30m,ge,:time-span\n</pre><pre>2014-02-20T13:00,s%2B30m,:time-span\n</pre>"},{"location":"asl/ref/time/","title":"time","text":"Input Stack:String \u21e8 Output Stack:TimeSeriesExpr <p>Generates a line based on the current time. Supported modes are:</p> <ul> <li>secondOfMinute</li> <li>secondOfDay</li> <li>minuteOfHour</li> <li>minuteOfDay</li> <li>hourOfDay</li> <li>dayOfWeek</li> <li>dayOfMonth</li> <li>dayOfYear</li> <li>monthOfYear</li> <li>yearOfCentury</li> <li>yearOfEra</li> <li>seconds (since epoch)</li> <li>days (since epoch)</li> </ul> <p>The mode can also be a value of the enum ChronoField.</p> <p>Examples:</p> Hour of DayEnum <pre>hourOfDay,:time\n</pre><pre>HOUR_OF_DAY,:time\n</pre>"},{"location":"asl/ref/topk-others-avg/","title":"topk-others-avg","text":"Input Stack:k: Intstat: StringTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Since: 1.7</p> <p>Restrict the output for a grouped expression to the <code>k</code> time series with the largest value for the specified summary statistic and computes an average aggregate for the other time series. Example of usage:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\nmax,2,:topk-others-avg\n</pre>"},{"location":"asl/ref/topk-others-max/","title":"topk-others-max","text":"Input Stack:k: Intstat: StringTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Since: 1.7</p> <p>Restrict the output for a grouped expression to the <code>k</code> time series with the largest value for the specified summary statistic and computes a max aggregate for the other time series. Example of usage:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\nmax,2,:topk-others-max\n</pre>"},{"location":"asl/ref/topk-others-min/","title":"topk-others-min","text":"Input Stack:k: Intstat: StringTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Since: 1.7</p> <p>Restrict the output for a grouped expression to the <code>k</code> time series with the largest value for the specified summary statistic and computes a min aggregate for the other time series. Example of usage:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\nmax,2,:topk-others-min\n</pre>"},{"location":"asl/ref/topk-others-sum/","title":"topk-others-sum","text":"Input Stack:k: Intstat: StringTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Since: 1.7</p> <p>Restrict the output for a grouped expression to the <code>k</code> time series with the largest value for the specified summary statistic and computes a sum aggregate for the other time series. Example of usage:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\nmax,2,:topk-others-sum\n</pre>"},{"location":"asl/ref/topk/","title":"topk","text":"Input Stack:k: Intstat: StringTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Since: 1.7</p> <p>Restrict the output for a grouped expression to the <code>k</code> time series with the largest value for the specified summary statistic. Example of usage:</p> BeforeAfter <pre>name,sps,:eq,\n(,nf.cluster,),:by\n</pre><pre>name,sps,:eq,\n(,nf.cluster,),:by,\nmax,2,:topk\n</pre> <p>In some cases it can be useful to see an aggregate summary of the other time series that were not part of the top set. This can be accomplished using the <code>:topk-others-$(aggr)</code> operators. For more details see:</p> <ul> <li>:topk-others-avg</li> <li>:topk-others-max</li> <li>:topk-others-min</li> <li>:topk-others-sum</li> </ul>"},{"location":"asl/ref/trend/","title":"trend","text":"Input Stack:window: DurationTimeSeriesExpr \u21e8 Output Stack:TimeSeriesExpr <p>Warning</p> <p>Deprecated: Use :rolling-mean instead.</p> <p>Computes a moving average over the input window. Until there is at least one sample for the whole window it will emit <code>NaN</code>. If the input line has <code>NaN</code> values, then they will be treated as zeros. Example:</p> Input 2m,:trend 5m,:trend 0 NaN NaN 1 0.5 NaN -1 0.0 NaN NaN -0.5 NaN 0 0.0 0.0 1 0.5 0.2 2 1.5 0.4 1 1.5 0.8 1 1.0 1.0 0 0.5 1.0 <p>The window size is specified as a range of time. If the window size is not evenly divisible by the step size, then the window size will be rounded down. So a 5m window with a 2m step would result in a 4m window with two datapoints per average. A step size larger than the window will result in the trend being a no-op.</p> <p>Examples:</p> 5 Minutes20 Minutes <pre>:random,\nPT5M,:trend\n</pre><pre>:random,\n20m,:trend\n</pre>"},{"location":"asl/ref/true/","title":"true","text":"Input Stack: \u21e8 Output Stack:Query <p>Query expression that will match any input time series. See also :false.</p>"},{"location":"asl/ref/tuck/","title":"tuck","text":"Input Stack:ba \u21e8 Output Stack:bab <p>Shorthand equivalent to writing: <code>:swap,:over</code> </p> <p>Example:</p> <pre>a,b,:tuck\n</pre> PosInputOutput 0 b b 1 a a 2 b"},{"location":"asl/ref/vspan/","title":"vspan","text":"Input Stack:TimeSeriesExpr \u21e8 Output Stack:StyleExpr <p>Change the line style to be a vertical span. In this mode any non-zero datapoints on the line will be shown as a span. This is frequently used to visualize when an alert would have fired.</p> <p>See the line style examples page for more information.</p> <p>Example:</p> BeforeAfter <pre>name,sps,:eq,\n:sum,\n:dup,\n20e3,:gt\n</pre><pre>name,sps,:eq,\n:sum,\n:dup,\n20e3,:gt,\n:vspan\n</pre>"},{"location":"concepts/consolidation/","title":"Consolidation","text":"<p>TODO</p>"},{"location":"concepts/naming/","title":"Naming","text":""},{"location":"concepts/naming/#summary","title":"Summary","text":"<ol> <li>Names<ul> <li>Describe the measurement being collected</li> <li>Use camelCase</li> <li>Static</li> <li>Succinct</li> </ul> </li> <li>Tags<ul> <li>Should be used for dimensional filtering</li> <li>Be careful about combinatorial explosion</li> <li>Tag keys should be static</li> <li>Use <code>id</code> to distinguish between instances</li> </ul> </li> <li>Use Base Units</li> </ol>"},{"location":"concepts/naming/#names","title":"Names","text":""},{"location":"concepts/naming/#describe-the-measurement","title":"Describe the Measurement","text":""},{"location":"concepts/naming/#use-camelcase","title":"Use camelCase","text":"<p>The main goal here is to promote consistency, which makes it easier for users. The choice of style is somewhat arbitrary, but camelCase was chosen because:</p> <ul> <li>Used by SNMP</li> <li>Used by Java</li> <li>It was commonly used at Netflix when the guideline was written</li> </ul> <p>The exception to this rule is where there is an established common case. For example, with Amazon regions, it is preferred to use <code>us-east-1</code> rather than <code>usEast1</code> as it is the more common form.</p>"},{"location":"concepts/naming/#static","title":"Static","text":"<p>There should not be any dynamic content in a metric name, such as <code>requests.$APP_NAME</code>. Metric names and tag keys are how users interact with the data, and dynamic values make them difficult to use. Dynamic information is better suited for tag values, such as <code>nf.app</code> or <code>status</code>. </p>"},{"location":"concepts/naming/#succinct","title":"Succinct","text":"<p>Long names should be avoided. In many cases, long names are the result of combining many pieces of information together into a single string. In this case, consider either discarding information that is not useful or encoding the information in tag values.  </p>"},{"location":"concepts/naming/#tags","title":"Tags","text":"<p>Historically, tags have been used to play one of two roles:</p> <ul> <li>Dimensions. This is the primary use of tags and this feature allows the data to be filtered into subsets by values of interest.</li> <li>Namespace. Similar to packages in Java, this allows grouping related data. This type of usage is discouraged.</li> </ul> <p>As a general rule, it should be possible to use the name as a pivot. If only the name is selected, then the user should be able to use other dimensions to filter the data and successfully reason about the value being shown. </p> <p>As a concrete example, suppose we have two metrics:</p> <ol> <li>The number of threads currently in a thread pool.</li> <li>The number of rows in a database table.</li> </ol>"},{"location":"concepts/naming/#discouraged-approach","title":"Discouraged Approach","text":"<pre><code>Id poolSize = registry.createId(\"size\")\n  .withTag(\"class\", \"ThreadPool\")\n  .withTag(\"id\", \"server-requests\");\n\nId poolSize = registry.createId(\"size\")\n  .withTag(\"class\", \"Database\")\n  .withTag(\"table\", \"users\");  \n</code></pre> <p>In this approach, if you select the name <code>size</code>, then it will match both the <code>ThreadPool</code> and <code>Database</code> classes. This results in a value that is the an aggregate of the number of threads and the number of items in a database, which has no meaning. </p>"},{"location":"concepts/naming/#recommended-approach","title":"Recommended Approach","text":"<pre><code>Id poolSize = registry.createId(\"threadpool.size\")\n  .withTag(\"id\", \"server-requests\");\n\nId poolSize = registry.createId(\"db.size\")\n  .withTag(\"table\", \"users\");  \n</code></pre> <p>This variation provides enough context, so that if just the name is selected, the value can be reasoned about and is at least potentially meaningful.</p> <p>This variation provides enough context in the name so that the meaning is more apparent and you can successfully reason about the values. For example, if you select <code>threadpool.size</code>, then you can see the total number of threads in all pools. You can then group by or select an <code>id</code> to further filter the data to a subset in which you have an interest.</p>"},{"location":"concepts/naming/#use-base-units","title":"Use Base Units","text":"<p>Keep measurements in base units where possible. It is better to have all timers in seconds, disk sizes in bytes, and network rates in bytes/second. This allows any SI unit prefixes applied to tick labels on a graph to have an obvious meaning, such as 1k meaning 1 kilobyte, as opposed to 1 kilo-megabyte.</p>"},{"location":"concepts/normalization/","title":"Normalization","text":"<p>In Atlas, this usually refers to normalizing data points to step boundaries. Suppose that values are actually getting reported at 30 seconds after the minute, instead of exactly on the minute. The values will get normalized to the minute boundary, so that all time series in the system are consistent.</p> <p>How a normalized value is computed depends on the data source type. Atlas supports three types indicated by the value of the <code>atlas.dstype</code> tag. In general, you should not need to worry about that, client libraries like Spectator will automatically handle tagging based on the data source type.</p> <p>It is recommended to at least skim through the normalization for gauges and rates to better understand how the values you see actually relate to measured data.</p>"},{"location":"concepts/normalization/#gauge","title":"Gauge","text":"<p>A value that is sampled from some source and the value is used as is. The last value received will be the value used for the interval. For example:</p> <pre><code>                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502    8    \u2502                                    \u2502    8    \u2502\n                \u2502         \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500                             \u2502         \u2502\n                \u2502         \u2502    6                               \u2502         \u2502\n\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502         \u2502                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502         \u2502\n 4    \u2502         \u2502         \u2502                \u2502    4    \u2502         \u2502         \u2502\n      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524         \u2502           to   \u2502         \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524         \u2502\n      \u2502    2    \u2502         \u2502                \u2502         \u2502    2    \u2502         \u2502\n \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524           \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n1:00      1:01      1:02      1:03        1:00      1:01      1:02      1:03\n</code></pre>"},{"location":"concepts/normalization/#rate","title":"Rate","text":"<p>A rate is a value representing the rate per second since the last reported value. Rate values are normalized using a weighted average. For example:</p> <pre><code>                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502    8    \u2502                                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502         \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500                             \u2502    7    \u2502\n                \u2502         \u2502    6                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524         \u2502\n\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502         \u2502                          \u2502    5    \u2502         \u2502\n 4    \u2502         \u2502         \u2502                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524         \u2502         \u2502\n      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524         \u2502           to   \u2502    3    \u2502         \u2502         \u2502\n      \u2502    2    \u2502         \u2502                \u2502         \u2502         \u2502         \u2502\n \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524           \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n1:00      1:01      1:02      1:03        1:00      1:01      1:02      1:03\n</code></pre> <p>Here, the data is reported at exactly 30s after the minute boundary. So each value represents the average rate per second for 50% of the minute.</p> Time Value 1:01 4 * 0.5 + 2 * 0.5 = 2 + 1 = 3 1:02 2 * 0.5 + 8 * 0.5 = 1 + 4 = 5 1:03 8 * 0.5 + 6 * 0.5 = 4 + 3 = 7 <p>If many samples are received for a given interval, then they will each be weighted based on the fraction of the interval they represent. When no previous sample exists, the value will be treated as the average rate per second over the previous step. This behavior is important to avoid under-counting the contribution from a previous interval. The example below shows what happens if there is no previous or next sample:</p> <pre><code>                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502    8    \u2502\n                \u2502         \u2502\n                \u2502         \u2502                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502         \u2502                          \u2502    5    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502         \u2502                          \u2502         \u2502    4    \u2502\n      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524         \u2502           to        1    \u2502         \u2502         \u2502\n      \u2502    2    \u2502         \u2502                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524         \u2502         \u2502\n \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524           \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n1:00      1:01      1:02      1:03        1:00      1:01      1:02      1:03\n</code></pre> <p>Why perform weighted averaging for rates instead of the simpler last value approach used with gauges? Because it gives us a better summary of what we actually know from the measurements received. In practical terms:</p> <ul> <li>Avoids dropping information if samples are more frequent than the step. Suppose we have   a 1 minute step, but data is actually getting reported every 10s. For this example, assume   we get 1, 5, 90, 5, 4, and 2. The last value normalization used with Gauges would end up   with a value of 2. The rate normalization will give 17.833. Each value is a rate per second,   so if you take the <code>(1 + 5 + 90 + 5 + 4 + 2) * 10 = 1070</code> actual events measured during the   interval. That is equivalent to <code>17.833 * 60</code> indicating we have an accurate average rate   for the step size.</li> <li>Avoids skewing the data causing misleading spikes or drops in the aggregates. Using Atlas   you will typically be looking at an aggregate of time series rather than an individual time   series that was reported. With last value it can have the effect of skewing samples to a later   interval. Suppose the client is reporting once a minute at 5s after the minute. That value   indicates more about the previous interval than it does the current one. During traffic   transitions, such as moving traffic over to a new cluster or even some auto-scaling events,   differences in this skew can result in the appearance of a drop because there will be many   new time series getting reported with a delayed start. For existing time series it is still   skewed, but tends to be less noticeable. The weighted averaging avoids these problems for   the most part.</li> </ul>"},{"location":"concepts/normalization/#counter","title":"Counter","text":"<p>Counter is similar to rate, except that the value reported is monotonically increasing and will be converted to a rate by the backend. The conversion is done by computing the delta between the current sample and the previous sample and dividing by the time between the samples. After that it is the same as a rate.</p> <p>Note, that unless the input is a montonically increasing counter it is generally better to have the client perform rate conversion. Since, the starting value is unknown, at least two samples must be received before the first delta can be computed. This means that new time series relying on counter type will be delayed by one interval.</p>"},{"location":"concepts/time-series/","title":"Time Series","text":"<p>A time series is a sequence of data points reported at a consistent interval over time. The time interval between successive data points is called the step size. In Atlas, each time series is paired with metadata called tags that allow us to query and group the data.</p>"},{"location":"concepts/time-series/#tags","title":"Tags","text":"<p>A set of key value pairs associated with a time series. Each time series must have at least one tag with a key of <code>name</code>. To make it more concrete, here is an example of a tag set represented as a JSON object:</p> <pre><code>{\n  \"name\":       \"server.requestCount\",\n  \"status\":     \"200\",\n  \"endpoint\":   \"api\",\n  \"nf.app\":     \"fooserver\",\n  \"nf.cluster\": \"fooserver-main\",\n  \"nf.stack\":   \"main\",\n  \"nf.region\":  \"us-east-1\",\n  \"nf.zone\":    \"us-east-1c\",\n  \"nf.node\":    \"i-12345678\"\n}\n</code></pre> <p>Usage of tags typically falls into two categories:</p> <ol> <li>Namespace. These are tags necessary to qualify a name, so that it can be meaningfully aggregated. Using the sample above, consider computing the sum of all metrics for application <code>fooserver</code>. That number would be meaningless. Properly modelled data should try to make the aggregates meaningful by selecting the <code>name</code>. The sum of all metrics with <code>name = server.requestCount</code> is the overall request count for the service.</li> <li>Dimensions. These are tags used to filter the data to a meaningful subset. They can be used to see the number of successful requests across the cluster by querying for <code>status = 200</code> or the number of requests for a single node by querying for <code>nf.node = i-12345678</code>. Most tags should fall into this category.</li> </ol> <p>When creating metrics, it is important to carefully think about how the data should be tagged. See the naming docs for more information.</p>"},{"location":"concepts/time-series/#metric","title":"Metric","text":"<p>A metric is a specific quantity being measured, e.g., the number of requests received by a server. In casual language about Atlas metric is often used interchangeably with time series. A time series is one way to track a metric and is the method supported by Atlas. In most cases there will be many time series for a given metric. Going back to the example, request count would usually be tagged with additional dimensions such as status and node. There is one time series for each distinct combination of tags, but conceptually it is the same metric.</p>"},{"location":"concepts/time-series/#data-point","title":"Data Point","text":"<p>A data point is a triple consisting of tags, timestamp, and a value. It is important to understand at a high level how data points correlate with the measurement. Consider requests hitting a server, this would typically be measured using a counter. Each time a request is received the counter is incremented. There is not one data point per increment, a data point represents the behavior over a span of time called the step size. The client library will sample the counter once for each interval and report a single value.</p> <p>Suppose that each circle in the diagram below represents a request:</p> <pre><code>1:00       1:01       1:02       1:03\n \u251c\u2500\u25cf\u2500\u2500\u2500\u2500\u25cf\u25cf\u25cf\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n</code></pre> <p>There are 5 requests shown, 4 from 1:00 to 1:01, and 1 from 1:02 to 1:03. Assuming all requests incremented the same time series, i.e. all other dimensions such as status code are the same, then this would result in three data points. For counters values are always a rate per second, so for a one minute step size the total number of requests would be divided by 60 seconds. So the values stored would be:</p> Time Value 1:01 4 / 60 = 0.0667 1:02 0 / 60 = 0.0000 1:03 1 / 60 = 0.0167"},{"location":"concepts/time-series/#step-size","title":"Step Size","text":"<p>The amount of time between two successive data points in a time series. For Atlas the datapoints will always be on even boundaries of the step size. If data is not reported on step boundaries, it will get normalized to the boundary.</p>"},{"location":"spectator/","title":"Overview","text":"<p>Simple library for instrumenting code to record dimensional time series data.</p> <p>At a minimum, you need to:</p> <ol> <li> <p>Understand core concepts.</p> <ul> <li>Time Series</li> <li>Normalization</li> <li>Naming</li> <li>Clock</li> </ul> </li> <li> <p>Install the metrics agent.</p> <ul> <li>SpectatorD</li> </ul> </li> <li> <p>Install the language-specific library and configuration bindings, where available.</p> <ul> <li>Support Class Descriptions<ul> <li>Language Overview</li> </ul> </li> <li>First-Class Support<ul> <li>C++</li> <li>Go</li> <li>Java</li> <li>Node.js</li> <li>Python</li> </ul> </li> <li>Best-Effort Support<ul> <li>Rust (internal library)   </li> </ul> </li> </ul> </li> <li> <p>Instrument some code, referring to the core usage guides on the following meter types:</p> <ul> <li>Counters</li> <li>Distribution Summaries</li> <li>Gauges</li> <li>Percentile Timers</li> <li>Timers</li> </ul> </li> </ol> <p>After you are more familiar with the library and need assistance with more advanced topics, see the Patterns section on the left.</p>"},{"location":"spectator/agent/metrics/","title":"SpectatorD Metrics","text":""},{"location":"spectator/agent/metrics/#spectatormeasurements","title":"spectator.measurements","text":"<p>The number of measurements that have either been sent to an Atlas backend or dropped.</p> <p>Unit: measurements/second</p> <p>Dimensions:</p> <ul> <li><code>id</code>: One of <code>sent</code> or <code>dropped</code>.</li> <li><code>error</code>: The type of error that occurred, one of <code>http-error</code>, <code>validation</code>, or <code>other</code>.</li> <li><code>owner</code>: <code>spectatord</code></li> <li>Common Infrastructure</li> </ul>"},{"location":"spectator/agent/metrics/#spectatorregistrysize","title":"spectator.registrySize","text":"<p>The number of measurements stored in the registry.</p> <p>Unit: measurements</p> <p>Dimensions:</p> <ul> <li><code>owner</code>: <code>spectatord</code></li> <li>Common Infrastructure</li> </ul>"},{"location":"spectator/agent/metrics/#spectatordparsedcount","title":"spectatord.parsedCount","text":"<p>The number of input lines parsed.</p> <p>Unit: lines/second</p> <p>Dimensions:</p> <ul> <li>Common Infrastructure</li> </ul>"},{"location":"spectator/agent/metrics/#spectatordparseerrors","title":"spectatord.parseErrors","text":"<p>The number of errors that have occurred while parsing input lines.</p> <p>Unit: lines/second</p> <p>Dimensions:</p> <ul> <li>Common Infrastructure</li> </ul>"},{"location":"spectator/agent/metrics/#spectatordpercentilecachesize","title":"spectatord.percentileCacheSize","text":"<p>The number of Distribution Summaries and/or Percentile Timers that have been updated recently in the dedicated cache.</p> <p>Unit: meters</p> <p>Dimensions:</p> <ul> <li><code>id</code>: One of <code>dist-summary</code> or <code>timer</code>.</li> <li>Common Infrastructure</li> </ul>"},{"location":"spectator/agent/metrics/#spectatordpercentileexpired","title":"spectatord.percentileExpired","text":"<p>The number of Distribution Summaries and/or Percentile Timers that have been expired from the dedicated cache.</p> <p>Unit: meters/second</p> <p>Dimensions:</p> <ul> <li><code>id</code>: One of <code>dist-summary</code> or <code>timer</code>.</li> <li>Common Infrastructure</li> </ul>"},{"location":"spectator/agent/metrics/#spectatordpoolallocsize","title":"spectatord.poolAllocSize","text":"<p>The size of the internal string pool.</p> <p>Unit: bytes</p> <p>Dimensions:</p> <ul> <li>Common Infrastructure</li> </ul>"},{"location":"spectator/agent/metrics/#spectatordpoolentries","title":"spectatord.poolEntries","text":"<p>The number of entries in the internal string pool.</p> <p>Unit: entries</p>"},{"location":"spectator/agent/usage/","title":"Usage","text":""},{"location":"spectator/agent/usage/#spectatord-introduction","title":"SpectatorD Introduction","text":"<p>SpectatorD is a high-performance telemetry agent that listens for metrics specified by a text-based protocol and publishes updates periodically to an Atlas aggregator service. It consolidates the logic required to apply common tagging to all metrics received, maintain metric lifetimes, and route metrics to the correct backend.</p> <p>The preferred method of using <code>spectatord</code> is to use one of the thin-client implementations, however, the text-based protocol was designed to make it easy for community-supported clients to be developed. It is also easy to use in shell scripts with common command line tools.  </p>"},{"location":"spectator/agent/usage/#command-line-configuration-flags","title":"Command Line Configuration Flags","text":"<pre><code>spectatord --help\nspectatord: A daemon that listens for metrics and reports them to Atlas.\n\n    --admin_port (Port number for the admin server.); default: 1234;\n    --age_gauge_limit (The maximum number of age gauges that may be reported by\n      this process.); default: 1000;\n    --common_tags (Common tags: nf.app=app,nf.cluster=cluster. Override the\n      default common tags. If empty, then spectatord will use the default set.\n      This flag should only be used by experts who understand the risks.);\n      default: \"\";\n    --debug (Debug spectatord. All values will be sent to a dev aggregator and\n      dropped.); default: false;\n    --enable_external (Enable external publishing.); default: false;\n    --enable_socket (Enable UNIX domain socket support. Default is true on Linux\n      and false on MacOS.); default: true;\n    --enable_statsd (Enable statsd support.); default: false;\n    --ipv4_only (Enable IPv4-only UDP listeners. This option should only be used\n      in environments where it is impossible to run IPv6.); default: false;\n    --metatron_dir (Path to the Metatron certificates, which are used for\n      external publishing. A number of well-known directories are searched by\n      default. This option is only necessary if your certificates are in an\n      unusual location.); default: \"\";\n    --meter_ttl (Meter TTL: expire meters after this period of inactivity.);\n      default: 15m;\n    --no_common_tags (No common tags will be provided for metrics. Since no\n      common tags are available, no internal status metrics will be recorded.\n      Only use this feature for special cases where it is absolutely necessary\n      to override common tags such as nf.app, and only use it with a secondary\n      spectatord process.); default: false;\n    --port (Port number for the UDP socket.); default: 1234;\n    --socket_path (Path to the UNIX domain socket.);\n      default: \"/run/spectatord/spectatord.unix\";\n    --statsd_port (Port number for the statsd socket.); default: 8125;\n    --uri (Optional override URI for the aggregator.); default: \"\";\n    --verbose (Use verbose logging.); default: false;\n    --verbose_http (Output debug info for HTTP requests.); default: false;\n\nTry --helpfull to get a list of all flags or --help=substring shows help for\nflags which include specified substring in either in the name, or description or\npath.\n</code></pre>"},{"location":"spectator/agent/usage/#endpoints","title":"Endpoints","text":"<p>By default, the daemon will listen on the following endpoints:</p> <ul> <li>Metrics Message Protocol</li> <li><code>1234/udp</code> (~430K reqs/sec with 16MB buffers)</li> <li><code>/run/spectatord/spectatord.unix</code> Domain Socket (~1M reqs/sec with batching)</li> <li>Admin Server: <code>1234/tcp</code></li> </ul> <p>The choice of which endpoint to use is determined by your performance and access requirements; the Unix domain socket offers higher performance, but requires filesystem access, which may not be tenable under some container configurations. See Performance Numbers for more details.</p>"},{"location":"spectator/agent/usage/#usage-examples","title":"Usage Examples","text":"<p>:warning: In container environments, the <code>-w0</code> option may not work and <code>-w1</code> should be used instead.</p> <pre><code>echo \"c:server.numRequests,id=failed:1\" | nc -u -w0 localhost 1234\necho \"t:server.requestLatency:0.042\" | nc -u -w0 localhost 1234\necho \"d:server.responseSizes:1024\" | nc -w0 -uU /run/spectatord/spectatord.unix\necho \"g:someGauge:60\" | nc -w0 -uU /run/spectatord/spectatord.unix\necho \"g,300:anotherGauge:60\" | nc -w0 -uU /run/spectatord/spectatord.unix\necho \"X,1543160297100:monotonic.Source:42\" | nc -w0 -uU /run/spectatord/spectatord.unix\necho \"X,1543160298100:monotonic.Source:43\" | nc -w0 -uU /run/spectatord/spectatord.unix\necho \"A:age.gauge:0\" | nc -u -w0 localhost 1234\n</code></pre>"},{"location":"spectator/agent/usage/#message-format","title":"Message Format","text":"<p>The message sent to the server has the following format, where the <code>,options</code> and <code>,tags</code> portions are optional:</p> <pre><code>metric-type,options:name,tags:value\n</code></pre> <p>Multiple lines may be sent in the same packet, separated by newlines (<code>\\n</code>):</p> <pre><code>echo -e \"t:server.requestLatency:0.042\\nd:server.responseSizes:1024\" | nc -u -w0 localhost 1234\n</code></pre>"},{"location":"spectator/agent/usage/#metric-types","title":"Metric Types","text":"Metric Type Symbol Description Age Gauge <code>A</code> The value is the time in seconds since the epoch at which an event has successfully occurred, or <code>0</code> to use the current time in epoch seconds. After an Age Gauge has been set, it will continue reporting the number of seconds since the last time recorded, for as long as the spectatord process runs. The purpose of this metric type is to enable users to more easily implement the Time Since Last Success alerting pattern.  To set a specific time as the last success: <code>A:time.sinceLastSuccess:1611081000</code>.  To set <code>now()</code> as the last success: <code>A:time.sinceLastSuccess:0</code>.  By default, a maximum of <code>1000</code> Age Gauges are allowed per <code>spectatord</code> process, because there is no mechanism for cleaning them up. This value may be tuned with the <code>--age_gauge_limit</code> flag on the spectatord binary. Counter <code>c</code> The value is the number of increments that have occurred since the last time it was recorded. The value will be reported to the backend as a rate-per-second. Distribution Summary <code>d</code> The value tracks the distribution of events. It is similar to a Timer, but more general, because the size does not have to be a period of time.  For example, it can be used to measure the payload sizes of requests hitting a server or the number of records returned from a query. Gauge <code>g</code> The value is a number that was sampled at a point in time. The default time-to-live (TTL) for gauges is 900 seconds (15 minutes) - they will continue reporting the last value set for this duration of time.  Optionally, the TTL may be specified in seconds, with a minimum TTL of 5 seconds. For example, <code>g,120:gauge:42.0</code> spcifies a gauge with a 120 second (2 minute) TTL. Max Gauge <code>m</code> The value is a number that was sampled at a point in time, but it is reported as a maximum gauge value to the backend. Monotonic Counter (double) <code>C</code> The value is a monotonically increasing number. A minimum of two samples must be received in order for <code>spectatord</code> to calculate a delta value and report it to the backend as a rate-per-second. The value is a <code>double</code> data type, and negative deltas are ignored. This data type provides flexibility for transforming values into base units with division.  Commonly used with networking metrics. Monotonic Counter (uint64) <code>U</code> The value is a monotonically increasing number. A minimum of two samples must be received in order for <code>spectatord</code> to calculate a delta value and report it to the backend as a rate-per-second. The value is a <code>uint64</code> data type, and it will handle rollovers.  Commonly used with networking metrics. Monotonic Counter (double) with Millisecond Timestamps <code>X</code> The value is a monotonically increasing number, sampled at a specified number of milliseconds since the epoch. A minimum of two samples must be received in order for <code>spectatord</code> to calculate a delta value and report it to the backend. The value should be a <code>uint64</code> data type, and it will handle rollovers.  This is an experimental metric type that can be used to track monotonic sources that were sampled in the recent past, with the value normalized over the reported time period.  The timestamp in milliseconds since the epoch when the value was sampled must be included as a metric option: <code>X,1543160297100:monotonic.Source:42</code> Percentile Distribution Summary <code>D</code> The value tracks the distribution of events, with percentile estimates. It is similar to a Percentile Timer, but more general, because the size does not have to be a period of time.  For example, it can be used to measure the payload sizes of requests hitting a server or the number of records returned from a query.  In order to maintain the data distribution, they have a higher storage cost, with a worst-case of up to 300X that of a standard Distribution Summary. Be diligent about any additional dimensions added to Percentile Distribution Summaries and ensure that they have a small bounded cardinality. Percentile Timer <code>T</code> The value is the number of seconds that have elapsed for an event, with percentile estimates.  This metric type will track the data distribution by maintaining a set of Counters. The distribution can then be used on the server side to estimate percentiles, while still allowing for arbitrary slicing and dicing based on dimensions.  In order to maintain the data distribution, they have a higher storage cost, with a worst-case of up to 300X that of a standard Timer. Be diligent about any additional dimensions added to Percentile Timers and ensure that they have a small bounded cardinality. Timer <code>t</code> The value is the number of seconds that have elapsed for an event. <p>The data type for all numbers except <code>U</code> is <code>double</code>. The <code>U</code> values are recorded as <code>uint64_t</code>, and the calculated deltas are passed to the backend as <code>double</code>. Passing negative values for <code>uint64_t</code> data types will cause the parsed string value to rollover.</p>"},{"location":"spectator/agent/usage/#metric-name-and-tags","title":"Metric Name and Tags","text":"<p>The metric name and tags must follow Atlas restrictions, which are described in the sections below.</p> <p>Tags are optional. They may be specified as comma-separated <code>key=value</code> pairs after the metric name. For example:</p> <pre><code>fooIsTheName,some.tag=val1,some.otherTag=val2\n</code></pre> <p>See Atlas Naming Conventions for recommendations on naming metrics.</p>"},{"location":"spectator/agent/usage/#length-restrictions","title":"Length Restrictions","text":"Limit Min Max Length of <code>name</code> 1 255 Tag key length 2 60 Tag value length 1 120"},{"location":"spectator/agent/usage/#allowed-characters","title":"Allowed Characters","text":"<p>The metric name, tag keys and values may only use characters in the following set: <code>-._A-Za-z0-9</code>.</p> <p>All others characters will be converted to an underscore (<code>_</code>) by the client.</p> <p>To avoid issues with parsing metrics, avoid using the SpectatorD protocol delimiter characters (<code>,=:</code>) rather than relying on the client to rewrite them to <code>_</code>.</p>"},{"location":"spectator/agent/usage/#metric-value","title":"Metric Value","text":"<p>A double value, or a uint64 value for one kind of Monotonic Counters. The meaning of the value depends on the metric type.</p>"},{"location":"spectator/agent/usage/#metrics","title":"Metrics","text":"<p>See Metrics for a list of metrics published by this service.</p>"},{"location":"spectator/agent/usage/#admin-server","title":"Admin Server","text":"<p>An administrative server is provided with SpectatorD, so that debugging information and few data management tasks may be completed. By default, this server listens on port <code>1234/TCP</code>, but this can be modified with the <code>--admin_port</code> flag. The endpoints which change data may only be accessed from localhost.</p> <ul> <li><code>GET /</code><ul> <li>Returns a service description and list of available endpoints. </li> </ul> </li> <li><code>GET /config</code><ul> <li>Returns the current SpectatorD configuration, including the current set of common tags.</li> </ul> </li> <li><code>GET /config/common_tags</code><ul> <li>Returns a description of how to use this endpoint to modify common tags.</li> </ul> </li> <li><code>POST /config/common_tags</code><ul> <li>Create, modify or delete common tags from the allowed set of Mantis common tags. No other common tags may be modified. Create or update a tag by setting it to a string. Delete a tag by setting the value to an empty string.</li> <li>Allowed tags:<ul> <li><code>mantisJobId</code></li> <li><code>mantisJobName</code></li> <li><code>mantisUser</code></li> <li><code>mantisWorkerIndex</code></li> <li><code>mantisWorkerNumber</code></li> <li><code>mantisWorkerStageNumber</code></li> </ul> </li> <li>Example:     <pre><code>curl -X POST \\\n-d '{\"mantisJobId\": \"foo\", \"mantisJobName\": \"bar\", \"mantisUser\": \"\"}' \\\n-w \" %{http_code}\\n\" \\\nhttp://localhost:1234/config/common_tags\n</code></pre></li> </ul> </li> <li><code>GET /metrics</code><ul> <li>Return an object containing lists of all metrics currently known to the Registry, grouped by type.</li> </ul> </li> <li><code>DELETE /metrics/A</code><ul> <li>Delete all AgeGauge metrics from the Registry. </li> </ul> </li> <li><code>DELETE /metrics/A/{id}</code><ul> <li>Delete one AgeGauge metric from the Registry, identified by the <code>id</code>.</li> <li>Example:     <pre><code>curl -X DELETE \\\n-w \" %{http_code}\\n\" \\\nhttp://localhost:1234/metrics/A/fooIsTheName,some.tag=val1,some.otherTag=val2\n</code></pre></li> </ul> </li> <li><code>DELETE /metrics/g</code><ul> <li>Delete all Gauge metrics from the Registry. </li> </ul> </li> <li><code>DELETE /metrics/g/{id}</code><ul> <li>Delete one Gauge metric from the Registry, identified by the <code>id</code>.</li> <li>Example:     <pre><code>curl -X DELETE \\\n-w \" %{http_code}\\n\" \\\nhttp://localhost:1234/metrics/g/fooIsTheName,some.tag=val1,some.otherTag=val2\n</code></pre></li> </ul> </li> </ul>"},{"location":"spectator/agent/usage/#performance-numbers","title":"Performance Numbers","text":"<p>A key goal of this project is to deliver high performance. This means that we need to use few resources for the common use case, where the number of metric updates is relatively small (&lt; 10k reqs/sec), and it also needs to be able to handle hundreds of thousands of updates per second when required.</p> <p>Using Unix domain sockets, we can handle close to 1M metric updates per second, assuming the client batches the updates and sends a few at a time. Sending every single metric update requires a lot of context switching, but is something that works well for the majority of our use cases. This simplicity means the user does not have to maintain any local state.</p> <pre><code>Transport          Batch Size    First 10M          Second 10M\nUnix Dgram         1             22.98s (435k rps)  20.58s (486k rps)\nUnix Dgram         8             11.46s (873k rps)   9.89s (1011k rps)\nUnix Dgram         32            10.38s (963k rps)   8.49s (1178k rps)\n</code></pre> <p>The UDP transport is particularly sensitive the max receive buffer size (16MB on our systems). </p> <p>Our tests indicate that sending 430K rps to the UDP port did not drop packets, but if there is a need for higher throughput, then tweaking <code>/proc/sys/net/unix/max_dgram_qlen</code> is recommended.</p>"},{"location":"spectator/core/clock/","title":"Clock","text":"<p>When taking measurements or working with timers it is recommended to use the Clock interface. It provides two methods for measuring time:</p>"},{"location":"spectator/core/clock/#wall-time","title":"Wall Time","text":"<p>This is what most users think of for time. It can be used to get the current time like what you would see on a wall clock. In most cases when not running in tests this will call System.currentTimeMillis().</p> <p>Note that the values returned by this method may not be monotonically increasing. Just like a clock on your wall, this value can go back in time or jump forward at unpredictable intervals, if someone sets the time. On many systems, ntpd or similar daemons will be constantly keeping the time synced up with an authoritative source.</p> <p>With Spectator, the Clock is typically accessed via the Registry.</p> <p>Java usage example:</p> <pre><code>// Current time in milliseconds since the epoch\nlong currentTime = registry.clock().wallTime();\n</code></pre>"},{"location":"spectator/core/clock/#monotonic-time","title":"Monotonic Time","text":"<p>While it is good in general for the wall clock to show the correct time, the unpredictable changes mean it is not a good choice for measuring how long an operation took. Consider a simple example of measuring request latency on a server:</p> <pre><code>long start = registry.clock().wallTime();\nhandleRequest(request, response);\nlong end = registry.clock().wallTime();\nreqLatencyTimer.record(end - start, TimeUnit.MILLISECONDS);\n</code></pre> <p>If ntp fixes the server time between <code>start</code> and <code>end</code>, then the recorded latency will be wrong. Spectator will protect against obviously wrong measurements like negative latencies by dropping those values when they are recorded. However, the change could incorrectly shorten or lengthen the measured latency.</p> <p>The clock interface also provides access to a monotonic source that is only useful for measuring elapsed time, for example:</p> <pre><code>long start = registry.clock().monotonicTime();\nhandleRequest(request, response);\nlong end = registry.clock().monotonicTime();\nreqLatencyTimer.record(end - start, TimeUnit.NANOSECONDS);\n</code></pre> <p>In most cases this will map to System.nanoTime(). Note the actual value returned is not meaningful unless compared with another sample to get a delta.</p>"},{"location":"spectator/core/clock/#manual-clock","title":"Manual Clock","text":"<p>If timing code is written to the Clock interface, then alternative implementations can be plugged-in. For test cases, it is common to use ManualClock so that tests can be reliable and fast without having to rely on hacks like sleep or assuming something will run in less than a certain amount of time. </p> <pre><code>ManualClock clock = new ManualClock();\nRegistry registry = new DefaultRegistry(clock);\n\nTimer timer = registry.timer(\"test\");\ntimer.record(() -&gt; {\n  doSomething();\n  clock.setMonotonicTime(42L);\n});\n\nAssert.assertEquals(timer.totalTime(), 42L);\n</code></pre>"},{"location":"spectator/core/meters/counter/","title":"Counter","text":"<p>A Counter is used to measure the rate at which some event is occurring. Considering a simple queue, Counters could be used to measure things like the rate at which items are being inserted and removed.</p> <p>Counters are reported to the backend as a rate-per-second. This makes it much easier to reason about the measurement and allows for aggregating the counter across instances.</p> <p>In Atlas, the <code>:per-step</code> operator can be used to convert them back into a count-per-step on a graph. </p> <p>Note</p> <p>For high performance code, such as incrementing in a tight loop that lasts less than a  reporting interval, increment a local variable and add the final value to the counter after  the loop has completed.</p>"},{"location":"spectator/core/meters/counter/#languages","title":"Languages","text":""},{"location":"spectator/core/meters/counter/#first-class-support","title":"First-Class Support","text":"<ul> <li>C++</li> <li>Go</li> <li>Java</li> <li>Node.js</li> <li>Python</li> </ul>"},{"location":"spectator/core/meters/counter/#best-effort-support","title":"Best-Effort Support","text":"<ul> <li>Rust (internal library)</li> </ul>"},{"location":"spectator/core/meters/dist-summary/","title":"Distribution Summary","text":"<p>A Distribution Summary is used to track the distribution of events. It is similar to a [Timer], but more general, in that the size does not have to be a period of time. For example, a distribution summary could be used to measure the payload sizes of requests hitting a server or the number of records returned from a query.</p> <p>It is recommended to always use base units when recording the data. So, if measuring the payload size use bytes, not kilobytes or some other unit. This allows the presentation layer for graphing to use either SI or IEC prefixes in a natural manner, and you do not need to consider the meaning of something like \"milli-milliseconds\".</p>"},{"location":"spectator/core/meters/dist-summary/#querying","title":"Querying","text":"<p>Note</p> <p>Distribution summaries report summarized statistics about the measurements for a time window including the <code>totalAmount</code>, <code>count</code>, <code>max</code> and <code>totalOfSquares</code>. If you were to simply query for the name of your timer via</p> <pre>nf.cluster,foo,:eq,\nname,http.req.payload.size,:eq,\n:and\n</pre> <p>you would get a nonsense value that is the sum of the reported statistics.</p> <p>When querying the results of a distribution summary, either select one of the statistics above via a filter, or use one of the operators below to generate a useful response.</p>"},{"location":"spectator/core/meters/dist-summary/#average-measurement-dist-avg","title":"Average Measurement (:dist-avg)","text":"<p>To compute the average size across an arbitrary group, use the :dist-avg function:</p> <pre>nf.cluster,foo,:eq,\nname,http.req.payload.size,:eq,\n:and,\n:dist-avg,\n(,nf.asg,),:by\n</pre>"},{"location":"spectator/core/meters/dist-summary/#maximum-measurement-dist-max","title":"Maximum Measurement (:dist-max)","text":"<p>To compute the maximum size across a group, use :dist-max:</p> <pre>nf.cluster,foo,:eq,\nname,http.req.payload.size,:eq,\n:and,\n:dist-max,\n(,nf.asg,),:by\n</pre>"},{"location":"spectator/core/meters/dist-summary/#standard-deviation-of-measurement-dist-stddev","title":"Standard Deviation of Measurement (:dist-stddev)","text":"<p>To compute the standard deviation of measurements across all instances for a time interval:</p> <pre>nnf.cluster,foo,:eq,\nname,http.req.payload.size,:eq,\n:and,\n:dist-stddev\n</pre>"},{"location":"spectator/core/meters/dist-summary/#raw-statistics","title":"Raw Statistics","text":"<p>Note that it is possible to plot the individual statics by filtering on the <code>statistic</code> tag. If you choose to do so, note that the <code>count</code>, <code>totalAmount</code> and <code>totalOfSquares</code> are counters thus reported as rates per second, while the <code>max</code> is reported as a gauge.</p>"},{"location":"spectator/core/meters/dist-summary/#languages","title":"Languages","text":""},{"location":"spectator/core/meters/dist-summary/#first-class-support","title":"First-Class Support","text":"<ul> <li>C++</li> <li>Go</li> <li>Java</li> <li>Node.js</li> <li>Python</li> </ul>"},{"location":"spectator/core/meters/dist-summary/#best-effort-support","title":"Best-Effort Support","text":"<ul> <li>Rust (internal library)</li> </ul>"},{"location":"spectator/core/meters/gauge/","title":"Gauge","text":"<p>A Gauge is a value that is sampled at some point in time. Typical examples for Gauges would be the size of a queue, or the number of threads in a running state. Since Gauges are not updated inline when a state change occurs, there is no information about what might have occurred between samples.</p> <p>Consider monitoring the behavior of a queue of tasks. If the data is being collected once a minute, then a Gauge for the size will show the size when it was sampled (a.k.a. last-write-wins). The size may have been much higher or lower at some point during interval, but that is not known.</p>"},{"location":"spectator/core/meters/gauge/#languages","title":"Languages","text":""},{"location":"spectator/core/meters/gauge/#first-class-support","title":"First-Class Support","text":"<ul> <li>C++</li> <li>Go</li> <li>Java</li> <li>Node.js</li> <li>Python</li> </ul>"},{"location":"spectator/core/meters/gauge/#best-effort-support","title":"Best-Effort Support","text":"<ul> <li>Rust (internal library)</li> </ul>"},{"location":"spectator/core/meters/timer/","title":"Timer","text":"<p>A Timer is used to measure how long (in seconds) some event is taking. Timer measurements are typically short, less than 1 minute. </p> <p>A selection of specialized timers include: </p> <ul> <li><code>LongTaskTimer</code> - Periodically reports the time taken for a long running task (&gt; 1 minute). See   the Long Task Timer pattern for details.</li> <li><code>PercentileTimer</code> - Useful if percentile approximations are needed in addition to basic stats.   See the Percentile Timer pattern for details.</li> </ul>"},{"location":"spectator/core/meters/timer/#querying","title":"Querying","text":"<p>Note</p> <p>Timers report summarized statistics about the measurements for a time window including the <code>totalTime</code>, <code>count</code>, <code>max</code> and <code>totalOfSquares</code>. If you were to simply query for the name of your timer via</p> <pre>nnf.cluster,foo,:eq,\nname,http.req.latency,:eq,\n:and\n</pre> <p>you would get a nonsense value that is the sum of the reported statistics.</p> <p>When querying the results of a timer, use one of the operators below to generate a useful  response.</p>"},{"location":"spectator/core/meters/timer/#average-measurement-dist-avg","title":"Average Measurement (:dist-avg)","text":"<p>To compute the average latency across an arbitrary group, use the :dist-avg function:</p> <pre>nf.cluster,foo,:eq,\nname,http.req.latency,:eq,\n:and,\n:dist-avg,\n(,nf.asg,),:by\n</pre>"},{"location":"spectator/core/meters/timer/#maximum-measurement-dist-max","title":"Maximum Measurement (:dist-max)","text":"<p>To compute the maximum latency across a group, use :dist-max:</p> <pre>nf.cluster,foo,:eq,\nname,http.req.latency,:eq,\n:and,\n:dist-max,\n(,nf.asg,),:by\n</pre>"},{"location":"spectator/core/meters/timer/#standard-deviation-of-measurement-dist-stddev","title":"Standard Deviation of Measurement (:dist-stddev)","text":"<p>To compute the standard deviation of measurements across all instances for a time interval:</p> <pre>nnf.cluster,foo,:eq,\nname,http.req.latency,:eq,\n:and,\n:dist-stddev\n</pre>"},{"location":"spectator/core/meters/timer/#raw-statistics","title":"Raw Statistics","text":"<p>Note that it is possible to plot the individual statics by filtering on the <code>statistic</code> tag. If you choose to do so, note that the <code>count</code>, <code>totalAmount</code> and <code>totalOfSquares</code> are counters thus reported as rates per second, while the <code>max</code> is reported as a gauge.</p>"},{"location":"spectator/core/meters/timer/#languages","title":"Languages","text":""},{"location":"spectator/core/meters/timer/#first-class-support","title":"First-Class Support","text":"<ul> <li>C++</li> <li>Go</li> <li>Java</li> <li>Node.js</li> <li>Python</li> </ul>"},{"location":"spectator/core/meters/timer/#best-effort-support","title":"Best-Effort Support","text":"<ul> <li>Rust (internal library)</li> </ul>"},{"location":"spectator/lang/overview/","title":"Overview","text":"<p>The original Spectator library was written in Java, with the first stable version (0.35.0) released on Jan 18, 2016. Since then, there has been a proliferation of languages at Netflix which seek first-class observability support.</p> <p>After some thought and experimentation, we have settled on a strategy of developing minimal Spectator implementations in many languages, which function as thin clients that send data to Atlas. Our goal is to have partners invested in each experimental language who will provide the necessary expertise to develop idiomatic solutions, deliver real-world feedback on library usage, and shoulder some of the support and maintenance burden.</p> <p>We think this is a more sustainable path over the long-term than expanding our team to support N different languages for this singular polyglot use case.</p>"},{"location":"spectator/lang/overview/#first-class-support","title":"First-Class Support","text":"<p>These libraries are fully-supported by the team and see wide use across Netflix. Issues are fixed in a timely manner and updates are published regularly.</p> <ul> <li>C++</li> <li>Go</li> <li>Java</li> <li>Node.js</li> <li>Python</li> </ul>"},{"location":"spectator/lang/overview/#best-effort-support","title":"Best-Effort Support","text":"<ul> <li>Rust (internal library)</li> </ul>"},{"location":"spectator/lang/cpp/usage/","title":"spectator-cpp Usage","text":"<p>C++ thin-client metrics library for use with Atlas and SpectatorD.</p>"},{"location":"spectator/lang/cpp/usage/#instrumenting-code","title":"Instrumenting Code","text":"<pre><code>#include &lt;spectator/registry.h&gt;\n\n// use default values\nstatic constexpr auto kDefault = 0;\n\nstruct Request {\n  std::string country;\n};\n\nstruct Response {\n  int status;\n  int size;\n};\n\nclass Server {\n public:\n  explicit Server(spectator::Registry* registry)\n      : registry_{registry},\n        request_count_id_{registry-&gt;CreateId(\"server.requestCount\", spectator::Tags{})},\n        request_latency_{registry-&gt;GetTimer(\"server.requestLatency\")},\n        response_size_{registry-&gt;GetDistributionSummary(\"server.responseSizes\")} {}\n\n  Response Handle(const Request&amp; request) {\n    auto start = std::chrono::steady_clock::now();\n\n    // do some work and obtain a response...\n    Response res{200, 64};\n\n    // Update the Counter id with dimensions, based on information in the request. The Counter\n    // will be looked up in the Registry, which is a fairly cheap operation, about the same as\n    // the lookup of an id object in a map. However, it is more expensive than having a local\n    // variable set to the Counter.\n    auto cnt_id = request_count_id_\n        -&gt;WithTag(\"country\", request.country)\n        -&gt;WithTag(\"status\", std::to_string(res.status));\n    registry_-&gt;GetCounter(std::move(cnt_id))-&gt;Increment();\n    request_latency_-&gt;Record(std::chrono::steady_clock::now() - start);\n    response_size_-&gt;Record(res.size);\n    return res;\n  }\n\n private:\n  spectator::Registry* registry_;\n  std::shared_ptr&lt;spectator::Id&gt; request_count_id_;\n  std::shared_ptr&lt;spectator::Timer&gt; request_latency_;\n  std::shared_ptr&lt;spectator::DistributionSummary&gt; response_size_;\n};\n\nRequest get_next_request() {\n  return Request{\"US\"};\n}\n\nint main() {\n  auto logger = spdlog::stdout_color_mt(\"console\"); \n  std::unordered_map&lt;std::string, std::string&gt; common_tags('xatlas.process', 'some-sidecar');\n  spectator::Config cfg{\"unix:/run/spectatord/spectatord.unix\", common_tags};\n  spectator::Registry registry{std::move(cfg), logger);\n\n  Server server{&amp;registry};\n\n  for (auto i = 1; i &lt;= 3; ++i) {\n    // get a request\n    auto req = get_next_request();\n    server.Handle(req);\n  }\n}\n</code></pre>"},{"location":"spectator/lang/cpp/usage/#usage","title":"Usage","text":"<p>We do not publish this library as a binary artifact, because it can be used across a variety of CPU and OS platforms, and we do not want to incur this support overheard for a library that is not on the Paved Path. However, this is a Conan 2 and CMake project, so you can pull the latest code, and add some build configuration to use it in your project.</p> <p>As an example of how this is done, see the atlas-system-agent project.</p> <ul> <li>Download the latest <code>spectator-cpp</code> code (conanfile.py#L39-L57).</li> <li>Add the library to your CMake build (lib/CMakeLists.txt#L1-L32).</li> </ul> <p>This library has a few dependencies (conanfile.py#L6-L13), including a recent <code>abseil</code>.</p>"},{"location":"spectator/lang/cpp/usage/#high-volume-publishing","title":"High-Volume Publishing","text":"<p>By default, the library sends every meter change to the <code>spectatord</code> sidecar immediately. This involves a blocking <code>send</code> call and underlying system calls, and may not be the most efficient way to publish metrics in high-volume use cases.</p> <p>For this purpose, a simple buffering functionality in <code>Publisher</code> is implemented, and it can be turned on by passing a buffer size to the <code>spectator::Config</code> constructor (config.h#L8-L12). It is important to note that, until this buffer fills up, the <code>Publisher</code> will not send any meters to the sidecar. Therefore, if your application doesn't emit meters at a high rate, you should either keep the buffer very small, or do not configure a buffer size at all, which will fall back to the \"publish immediately\" mode of operation.</p>"},{"location":"spectator/lang/go/migrations/","title":"Migrations","text":""},{"location":"spectator/lang/go/migrations/#migrating-from-0x-to-2x","title":"Migrating from 0.X to 2.X","text":"<p>Version 2.X consists of a major rewrite that turns spectator-go into a thin client designed to send metrics through spectatord. As a result some functionality has been moved to other packages or removed.</p>"},{"location":"spectator/lang/go/migrations/#new","title":"New","text":""},{"location":"spectator/lang/go/migrations/#writers","title":"Writers","text":"<p><code>spectator.Registry</code> now supports different writers. The default writer is <code>writer.UdpWriter</code> which sends metrics to spectatord through UDP.</p> <p>Writers can be configured through <code>spectator.Config.Location</code>.</p> <p>Possible values are:</p> <ul> <li><code>none</code>: Configures a no-op writer that does nothing. Can be used to disable metrics collection.</li> <li><code>stdout</code>: Writes metrics to stdout.</li> <li><code>stderr</code>: Writes metrics to stderr.</li> <li><code>memory</code>: Writes metrics to memory. Useful for testing.</li> <li><code>file:///path/to/file</code>: Writes metrics to a file.</li> <li><code>unix:///path/to/socket</code>: Writes metrics to a Unix domain socket.</li> <li><code>udp://host:port</code>: Writes metrics to a UDP socket.</li> </ul> <p>Location can also be set through the environment variable <code>SPECTATOR_OUTPUT_LOCATION</code>. If both are set, the environment variable takes precedence over the passed config. </p> <p>The environment variable <code>SPECTATOR_OUTPUT_LOCATION</code> can be set to <code>none</code> to disable metrics collection.</p>"},{"location":"spectator/lang/go/migrations/#meters","title":"Meters","text":"<p>The following new Meters have been added:</p> <ul> <li><code>meter.MaxGauge</code></li> <li><code>meter.Gauge</code> with TTL</li> </ul>"},{"location":"spectator/lang/go/migrations/#common-tags","title":"Common Tags","text":"<p>Common tags are now automatically added to all Meters. Their values are read from the environment variables.</p> Tag Environment Variable nf.container TITUS_CONTAINER_NAME nf.process NETFLIX_PROCESS_NAME <p>Tags from environment variables take precedence over tags passed on code when creating the <code>Config</code>.</p> <p>Note that common tags sourced by spectatord can't be overwritten.</p>"},{"location":"spectator/lang/go/migrations/#config","title":"Config","text":"<ul> <li><code>Config</code> is now created through a constructor which throws error if the passed in parameters are not valid.</li> <li><code>Config</code> members are now private.</li> </ul>"},{"location":"spectator/lang/go/migrations/#moved","title":"Moved","text":"<ul> <li>Runtime metrics collection has been moved   to spectator-go-runtime-metrics. Follow instructions in   the README to enable collection.</li> <li>Some types have been moved to different packages. For example, <code>spectator.Counter</code> is now in <code>meter.Counter</code>.</li> </ul>"},{"location":"spectator/lang/go/migrations/#removed","title":"Removed","text":"<ul> <li><code>spectator.HttpClient</code> has been removed. Use the standard <code>http.Client</code> instead.</li> <li><code>spectator.Meter</code>s no longer has a <code>Measure() []Measurement</code> function. Meters are now stateless and do not store   measurements.</li> <li><code>spectator.Clock</code> has been removed. Use the standard <code>time</code> package instead.</li> <li><code>spectator.Config</code> has been greatly simplified.</li> <li><code>spectator.Registry</code> no longer has a <code>Start()</code> function. The <code>Registry</code> is now effectively stateless and there is   nothing to start other than opening the output location.</li> <li><code>spectator.Registry</code> no longer has a <code>Stop()</code> function. Instead, use <code>Close()</code> to close the registry. Once the   registry is closed, it can't be started again.</li> <li><code>spectator.Config.IpcTimerRecord</code> has been removed. Use a <code>meter.Timer</code> instead to record Ipc metrics.</li> <li><code>spectator.MeterFactoryFun</code> has been removed. If you need to create a custom meter you can do so by wrapping one of   the meters returned by <code>spectator.Registry</code>.</li> <li><code>spectator.Registry</code> no longer reports <code>spectator.measurements</code> metrics. Instead, you can use spectatord metrics to   troubleshoot.</li> <li><code>spectator.Registry</code> no longer keep track of the Meters it creates. This means that you can't get a list of all Meters   from the Registry. If you need to keep track of Meters, you can do so in your application code.</li> <li><code>Percentile*</code> meters no longer support defining min/max values.</li> <li><code>spectator.Registry</code> no longer allows setting a different logger after creation. A custom logger can be set in the   <code>spectator.Config</code> before creating the Registry.</li> <li>File-based configuration is no longer supported.</li> </ul>"},{"location":"spectator/lang/go/migrations/#migration-steps","title":"Migration Steps","text":"<ol> <li>Make sure you're not relying on any of the removed functionality.</li> <li>Update imports to use <code>meters</code> package instead of <code>spectator</code> for Meters.</li> <li>If you want to collect runtime metrics    pull spectator-go-runtime-metrics and follow the    instructions in the README.</li> <li>If you use <code>PercentileDistributionSummary</code> or <code>PercentileTimer</code>, then  you need to update your code to use the    respective functions provided by the <code>Registry</code> to initialize these meters.</li> <li>Remove dependency on Spectator Go Internal configuration library. Such dependency is no longer required.</li> <li>There is no longer an option to start or stop the registry at runtime. If you need to configure a <code>Registry</code> that    doesn't emit metrics, for testing purposes, you can use the <code>spectator.Config.Location</code> option with <code>none</code> to    configure a no-op writer.</li> </ol>"},{"location":"spectator/lang/go/migrations/#writing-tests","title":"Writing Tests","text":"<p>To write tests against this library, instantiate a test instance of the <code>Registry</code> and configure it to use the MemoryWriter, which stores all updates in an <code>Array</code>. Maintain a handle to the <code>MemoryWriter</code>, then inspect the <code>Lines()</code> to verify your metrics updates. See the source code for more testing examples.</p> <pre><code>package app\n\nimport (\n    \"fmt\"\n    \"github.com/Netflix/spectator-go/v2/spectator/logger\"\n    \"github.com/Netflix/spectator-go/v2/spectator/writer\"\n    \"testing\"\n    \"time\"\n)\n\nfunc TestRegistryWithMemoryWriter_Counter(t *testing.T) {\n    mw := &amp;writer.MemoryWriter{}\n    r := NewTestRegistry(mw)\n\n    counter := r.Counter(\"test_counter\", nil)\n    counter.Increment()\n    expected := \"c:test_counter:1\"\n    if len(mw.Lines()) != 1 || mw.Lines()[0] != expected {\n        t.Errorf(\"Expected '%s', got '%s'\", expected, mw.Lines()[0])\n    }\n}\n\nfunc NewTestRegistry(mw *writer.MemoryWriter) Registry {\n    return &amp;spectatordRegistry{\n        config: &amp;Config{},\n        writer: mw,\n        logger: logger.NewDefaultLogger(),\n    }\n}\n</code></pre>"},{"location":"spectator/lang/go/usage/","title":"spectator-go Usage","text":"<p>Go thin-client metrics library for use with Atlas and SpectatorD.</p>"},{"location":"spectator/lang/go/usage/#supported-go-versions","title":"Supported Go Versions","text":"<p>This library currently targets the latest two stable versions of Go.</p> <p>There is one language feature used in the project which requires at least 1.21 - the log/slog structured logging library.</p>"},{"location":"spectator/lang/go/usage/#instrumenting-code","title":"Instrumenting Code","text":"<pre><code>package main\n\nimport (\n    \"github.com/Netflix/spectator-go/v2/spectator\"\n    \"github.com/Netflix/spectator-go/v2/spectator/meter\"\n    \"strconv\"\n    \"time\"\n)\n\ntype Server struct {\n    registry       spectator.Registry\n    requestCountId *meter.Id\n    requestLatency *meter.Timer\n    responseSizes  *meter.DistributionSummary\n}\n\ntype Request struct {\n    country string\n}\n\ntype Response struct {\n    status int\n    size   int64\n}\n\nfunc (s *Server) Handle(request *Request) (res *Response) {\n    start := time.Now()\n\n    // initialize response\n    res = &amp;Response{200, 64}\n\n    // Update the counter with dimensions based on the request.\n    tags := map[string]string{\n        \"country\": request.country,\n        \"status\":  strconv.Itoa(res.status),\n    }\n    requestCounterWithTags := s.requestCountId.WithTags(tags)\n    counter := s.registry.CounterWithId(requestCounterWithTags)\n    counter.Increment()\n\n    // ...\n    s.requestLatency.Record(time.Since(start))\n    s.responseSizes.Record(res.size)\n    return\n}\n\nfunc newServer(registry spectator.Registry) *Server {\n    return &amp;Server{\n        registry,\n        registry.NewId(\"server.requestCount\", nil),\n        registry.Timer(\"server.requestLatency\", nil),\n        registry.DistributionSummary(\"server.responseSizes\", nil),\n    }\n}\n\nfunc getNextRequest() *Request {\n    // ...\n    return &amp;Request{\"US\"}\n}\n\nfunc main() {\n    commonTags := map[string]string{\"nf.platform\": \"my_platform\", \"process_name\": \"my_process\"}\n    // if desired, replace the logger with a custom one, using the third parameter here:\n    config, _ := spectator.NewConfig(\"\", commonTags, nil)\n\n    registry, _ := spectator.NewRegistry(config)\n    defer registry.Close()\n\n    server := newServer(registry)\n\n    for i := 1; i &lt; 3; i++ {\n        // get a request\n        req := getNextRequest()\n        server.Handle(req)\n    }\n}\n</code></pre>"},{"location":"spectator/lang/go/usage/#logging","title":"Logging","text":"<p>Logging is implemented with the standard Golang slog package. The logger defines interfaces for Debugf, Infof, and Errorf. There are useful messages implemented at the Debug level which can help diagnose the metric publishing workflow. The logger can be overridden by providing one as the third parameter of the <code>Config</code> constructor.</p>"},{"location":"spectator/lang/go/usage/#runtime-metrics","title":"Runtime Metrics","text":"<p>Use spectator-go-runtime-metrics. Follow instructions in the README to enable collection.</p>"},{"location":"spectator/lang/go/usage/#design-considerations-reporting-intervals","title":"Design Considerations - Reporting Intervals","text":"<p>This client is stateless, and sends a UDP packet (or unixgram) to <code>spectatord</code> each time a meter is updated. If you are performing high-volume operations, on the order of tens-of-thousands or millions of operations per second, then you should pre-aggregate your metrics and report them at a cadence closer to the <code>spectatord</code> publish interval of 5 seconds. This will keep the CPU usage related to <code>spectator-go</code> and <code>spectatord</code> low (around 1% or less), as compared to up to 40% for high-volume scenarios.</p>"},{"location":"spectator/lang/java/servo-migration/","title":"Servo Migration","text":""},{"location":"spectator/lang/java/servo-migration/#servo-comparison","title":"Servo Comparison","text":"<p>Servo is an alternative client monitoring library that is also developed by Netflix. Originally, Spectator was an experiment for a simpler API that wrapped Servo. It was done as a separate project to avoid breaking backwards compatibility for Servo.</p> <p>From a user perspective, both will be supported for a long time, but most of our efforts for future improvement will go to Spectator. For new code, it is recommended to use the spectator API. If running at Netflix, the correct bindings will be in place for both Servo and Spectator.</p>"},{"location":"spectator/lang/java/servo-migration/#differences","title":"Differences","text":"<p>This section provides a quick summary of the differences between Spectator and Servo.</p>"},{"location":"spectator/lang/java/servo-migration/#simpler-api","title":"Simpler API","text":"<p>Servo gives the user a lot of control, but this makes it hard to use correctly. For example, to create a Counter, the user needs to understand the trade-offs and choose between:</p> <ul> <li>BasicCounter</li> <li>DynamicCounter</li> <li>ContextualCounter</li> <li>StepCounter</li> </ul> <p>Further, each of these can impact how data is reported to observers. The Spectator API focuses on the constructs a user needs to instrument the code. In Spectator, the user would always use the Registry to create a Counter. The implementation details are left up to the Registry.</p> <p>The registration is simpler as well to avoid common pitfalls when using Servo like overwriting a registered object.</p>"},{"location":"spectator/lang/java/servo-migration/#more-focused","title":"More Focused","text":"<p>The goal of Spectator is instrumenting code to send to a dimensional time-series system like Atlas. Servo has goals of staying compatible with a number of legacy libraries and naming formats, exposing data to JMX, etc. Examples of how this influences decisions:</p> <ul> <li>No support for non-numeric data. Servo supported this feature, so that it can expose data to JMX. Exposing the numeric data registered in Spectator to JMX can be done using a registry that supports it, but there is no goal to be a general interface for exposing arbitrary data in JMX.</li> <li>No support for custom time units when reporting timer data. Base units should always be used for reporting and conversions can be performed in the presentation layer, if needed. It also avoids a lot of the confusion around the timer unit for the data and issues like creating aggregates that are meaningless due to mixed units.</li> </ul> <p>It is better to have a simple way to send correct and easy-to-understand data to the backend than many options. If you want more knobs, then you can use Servo.</p>"},{"location":"spectator/lang/java/servo-migration/#di-friendly","title":"DI Friendly","text":"<p>When Servo was originally written, dependency injection (DI) was not heavily used at Netflix. Further, Servo needed to stay compatible with a number of use-cases that were heavily static.</p> <p>While Spectator does have a static registry that can be used, the recommended way is to create a registry and inject it either manually or via a framework into the classes that need it. This also makes it much easier to test in isolation.</p>"},{"location":"spectator/lang/java/servo-migration/#migration","title":"Migration","text":"<p>If you want to migrate from the Servo API to the Spectator API, then this section provides some guides on how Servo constructs can be ported over. The sub-sections are the class names of monitor types supported by Servo.</p> <p>For users at Netflix, we are not actively pushing teams to migrate or do any additional work. Servo is still supported and if it works for your use-case, then feel free to continue using it. </p>"},{"location":"spectator/lang/java/servo-migration/#registration","title":"Registration","text":"<p>First read through the Servo docs on registration. With Servo, say you have a class like the following:</p> <pre><code>public class Foo {\n\n  private AtomicInteger gauge;\n  private Counter counter;\n\n  public Foo(String id) {\n    gauge = new AtomicInteger();\n    counter = new BasicCounter(MonitorConfig.builder(\"counter\").build());\n    Monitors.registerObject(id, this);\n  }\n\n  @Monitor(name = \"gauge\", type = DataSourceType.GAUGE)\n  private int gauge() {\n    return gauge.get();\n  }\n\n  public void doSomething() {\n    ...\n  }\n}\n</code></pre> <p>The state of the class is in the member variables of an instance of <code>Foo</code>. If multiple instances of class <code>Foo</code> are created with the same value for <code>id</code>, then the last one will overwrite the others for the registration. So the values getting reported will only be from the last instance registered. Also the registry has a reference to the instance of <code>Foo</code>, so it will never go away.</p> <p>For Counters and Timers, one way to get around this is to use DynamicCounter and DynamicTimer, respectively. Those classes will automatically handle the registration and expire if there is no activity. They also get used for cases where the set of dimensions is not known up front.</p> <p>Gauges need to sample the state of something, so they need to have a reference to an object that contains the state. So the user would need to ensure that only a single copy was registered leading to patterns like:</p> <pre><code>class Foo {\n\n  private static class FooStats {\n\n    private AtomicInteger gauge;\n    private Counter counter;\n\n    public FooStats(String id) {\n      gauge = new AtomicInteger();\n      counter = new BasicCounter(MonitorConfig.builder(\"counter\").build());\n      Monitors.registerObject(id, this);\n    }\n\n    @Monitor(name = \"gauge\", type = DataSourceType.GAUGE)\n    private int gauge() {\n      return gauge.get();\n    }\n  }\n\n  private static ConcurrentHashMap&lt;String, FooStats&gt; STATS =\n    new ConcurrentHashMap&lt;&gt;();\n\n  private final FooStats stats;\n\n  public Foo(String id) {\n    stats = STATS.computeIfAbsent(id, (i) -&gt; new FooStats(i));\n  }\n\n  public void doSomething() {\n    ...\n    stats.update();\n  }\n}\n</code></pre> <p>This ensures that there is a single copy for a given id. In spectator this example would look like: </p> <pre><code>public class Foo {\n\n  private AtomicInteger gauge;\n  private Counter counter;\n\n  public Foo(Registry registry, String id) {\n    Id gaugeId = registry.createId(\"gauge\").withTag(\"id\", id);\n    gauge = registry.gauge(gaugeId, new AtomicInteger());\n    counter = registry.counter(\"counter\", \"id\", id);\n  }\n\n  public void doSomething() {\n    ...\n  }\n}\n</code></pre> <p>Everything using the same Registry will get the same Counter instance, if the same id is used. For the Gauge, the Registry will keep a weak reference and will sum the values if multiple instances are present. Since it is a weak reference, nothing will prevent an instance of <code>Foo</code> from getting garbage collected.</p>"},{"location":"spectator/lang/java/servo-migration/#annotations","title":"Annotations","text":"<p>Annotations are not supported, use the appropriate meter type:</p> DataSourceType Spectator Alternative COUNTER Counter Usage GAUGE Gauge Usage INFORMATIONAL Not supported"},{"location":"spectator/lang/java/servo-migration/#basiccounter","title":"BasicCounter","text":"<p>See the general overview of registration differences and summary of Counter usage.</p> <p>Servo:</p> <pre><code>public class Foo {\n  private final Counter c =\n    new BasicCounter(MonitorConfig.builder(\"name\").build());\n\n  public Foo(String id) {\n    Monitors.registerObject(id, this);\n  }\n\n  public void doSomething() {\n    c.increment();\n  }\n}\n</code></pre> <p>Spectator:</p> <pre><code>public class Foo {\n  private final Counter c;\n\n  @Inject\n  public Foo(Registry registry, String id) {\n    c = registry.counter(\"name\", \"id\", id);\n  }\n\n  public void doSomething() {\n    c.increment();\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/servo-migration/#basicgauge","title":"BasicGauge","text":"<p>See the general overview of registration differences and summary of Gauge usage.</p> <p>Servo:</p> <pre><code>public class Foo {\n  private final BasicGauge g = new BasicGauge(\n    MonitorConfig.builder(\"name\").build(),\n    this::getCurrentValue);\n\n  public Foo(String id) {\n    Monitors.registerObject(id, this);\n  }\n}\n</code></pre> <p>Spectator:</p> <pre><code>public class Foo {\n  @Inject\n  public Foo(Registry registry, String id) {\n    Id gaugeId = registry.createId(\"name\").withTag(\"id\", id);\n    registry.gauge(gaugeId, this, Foo::getCurrentValue);\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/servo-migration/#basictimer","title":"BasicTimer","text":"<p>See the general overview of registration differences and summary of Timer usage. In Spectator, the reported unit for Timers is always seconds and cannot be changed. Seconds is the base unit and other units should only be used as a presentation detail. Servo allows the unit to be customized and defaults to milliseconds.</p> <p>Servo:</p> <pre><code>public class Foo {\n  private final Timer t = new BasicTimer(\n    MonitorConfig.builder(\"name\").build(), TimeUnit.SECONDS);\n\n  public Foo(String id) {\n    Monitors.registerObject(id, this);\n  }\n\n  public void doSomething() {\n    Stopwatch s = t.start();\n    try {\n      ...\n    } finally {\n      s.stop();\n    }\n  }\n}\n</code></pre> <p>Spectator:</p> <pre><code>public class Foo {\n  private final Timer t;\n\n  @Inject\n  public Foo(Registry registry, String id) {\n    t = registry.timer(\"name\", \"id\", id);\n  }\n\n  public void doSomething() {\n    t.record(() -&gt; {\n      ...\n    });\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/servo-migration/#basicdistributionsummary","title":"BasicDistributionSummary","text":"<p>See the general overview of registration differences and summary of Distribution Summary usage.</p> <p>Servo:</p> <pre><code>public class Foo {\n  private final BasicDistributionSummary s = new BasicDistributionSummary(\n    MonitorConfig.builder(\"name\").build());\n\n  public Foo(String id) {\n    Monitors.registerObject(id, this);\n  }\n\n  public void doSomething() {\n    ...\n    s.record(getValue());\n  }\n}\n</code></pre> <p>Spectator:</p> <pre><code>public class Foo {\n  private final DistributionSummary s;\n\n  @Inject\n  public Foo(Registry registry, String id) {\n    s = registry.distributionSummary(\"name\", \"id\", id);\n  }\n\n  public void doSomething() {\n    ...\n    s.record(getValue());\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/servo-migration/#basicinformational","title":"BasicInformational","text":"<p>Not supported, see the overview of differences.</p>"},{"location":"spectator/lang/java/servo-migration/#basicstopwatch","title":"BasicStopwatch","text":"<p>There isn't an explicit stopwatch class in Spectator. Use a timing call directly. </p> <p>Servo:</p> <pre><code>  public void doSomething() {\n    Stopwatch s = timer.start();\n    try {\n      ...\n    } finally {\n      s.stop();\n    }\n  }\n</code></pre> <p>Spectator:</p> <pre><code>  public void doSomething() {\n    final long s = System.nanoTime();\n    try {\n      ...\n    } finally {\n      timer.record(System.nanoTime() - s, TimeUnit.NANOSECONDS);\n    }\n  }\n</code></pre>"},{"location":"spectator/lang/java/servo-migration/#buckettimer","title":"BucketTimer","text":"<p>See the general overview of registration differences.</p> <p>Servo:</p> <pre><code>public class Foo {\n  private final Timer t = new BucketTimer(\n    MonitorConfig.builder(\"name\").build(),\n    new BucketConfig.Builder()\n      .withTimeUnit(TimeUnit.MILLISECONDS)\n      .withBuckets(new long[] { 500, 2500, 5000, 10000 })\n      .build());\n\n  public Foo(String id) {\n    Monitors.registerObject(id, this);\n  }\n\n  public void doSomething() {\n    Stopwatch s = t.start();\n    try {\n      ...\n    } finally {\n      s.stop();\n    }\n  }\n}\n</code></pre> <p>Spectator:</p> <pre><code>public class Foo {\n  private final Timer t;\n\n  @Inject\n  public Foo(Registry registry, String id) {\n    Id timerId = registry.createId(\"name\", \"id\", id);\n    BucketFunction f = BucketFunctions.latency(10, TimeUnit.SECONDS);\n    t = BucketTimer.get(registry, timerId, f);\n  }\n\n  public void doSomething() {\n    t.record(() -&gt; {\n      ...\n    });\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/servo-migration/#contextualcounter","title":"ContextualCounter","text":"<p>Not supported. A fixed tag list for the context is too rigid and this class was never used much at Netflix. Future work being looked at in issue-180.</p>"},{"location":"spectator/lang/java/servo-migration/#contextualtimer","title":"ContextualTimer","text":"<p>Not supported. A fixed tag list for the context is too rigid and this class was never used much at Netflix. Future work being looked at in issue-180.</p>"},{"location":"spectator/lang/java/servo-migration/#doublegauge","title":"DoubleGauge","text":"<p>See the general overview of registration differences and summary of Gauge usage.</p> <p>Servo:</p> <pre><code>public class Foo {\n  private final DoubleGauge g = new DoubleGauge(\n    MonitorConfig.builder(\"name\").build());\n\n  public Foo(String id) {\n    Monitors.registerObject(id, this);\n  }\n}\n</code></pre> <p>Spectator:</p> <pre><code>import com.google.common.util.concurrent.AtomicDouble;\n\npublic class Foo {\n  private final AtomicDouble v;\n\n  @Inject\n  public Foo(Registry registry, String id) {\n    Id gaugeId = registry.createId(\"name\").withTag(\"id\", id);\n    v = registry.gauge(gaugeId, new AtomicDouble());\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/servo-migration/#durationtimer","title":"DurationTimer","text":"<p>See the general overview of registration differences, the summary of Timer usage, and Long Task Timer usage.</p> <p>Servo:</p> <pre><code>public class Foo {\n  private final DurationTimer t = new DurationTimer(\n    MonitorConfig.builder(\"name\").build());\n\n  public Foo(String id) {\n    Monitors.registerObject(id, this);\n  }\n}\n</code></pre> <p>Spectator:</p> <pre><code>public class Foo {\n  private final LongTaskTimer t;\n\n  @Inject\n  public Foo(Registry registry, String id) {\n    t = registry.longTaskTimer(\"name\", \"id\", id);\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/servo-migration/#dynamiccounter","title":"DynamicCounter","text":"<p>See the general overview of registration differences and summary of Counter usage.</p> <p>Servo:</p> <pre><code>public class Foo {\n\n  private final String id;\n\n  public Foo(String id) {\n    this.id = id;\n  }\n\n  public void doSomething(Context ctxt) {\n    DynamicCounter.increment(\"staticId\", \"id\", id);\n    DynamicCounter.increment(\"dynamicId\", \"id\", id, \"foo\", ctxt.getFoo());\n  }\n}\n</code></pre> <p>Spectator:</p> <pre><code>public class Foo {\n  private final Registry registry;\n  private final String id;\n  private final Counter staticCounter;\n  private final Id dynamicId;\n\n  @Inject\n  public Foo(Registry registry, String id) {\n    this.registry = registry;\n    this.id = id;\n    staticCounter = registry.counter(\"staticId\", \"id\", id);\n    dynamicId = registry.createId(\"dynamicId\", \"id\", id);\n  }\n\n  public void doSomething(Context ctxt) {\n    // Keeping the reference to the counter avoids additional allocations\n    // to create the id object and the lookup cost\n    staticCounter.increment();\n\n    // If the id is dynamic it must be looked up\n    registry.counter(\"dynamicId\", \"id\", id, \"foo\", ctxt.getFoo()).increment();\n\n    // This will update the same counter as the line above, but the base part\n    // of the id is precomputed to make it cheaper to construct the id.\n    registry.counter(dynamicId.withTag(\"foo\", ctxt.getFoo())).increment();\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/servo-migration/#dynamictimer","title":"DynamicTimer","text":"<p>See the general overview of registration differences and summary of Timer usage.</p> <p>Servo:</p> <pre><code>public class Foo {\n\n  private final String id;\n  private final MonitorConfig staticId;\n\n  public Foo(String id) {\n    this.id = id;\n    staticId = MonitorConfig.builder(\"staticId\").withTag(\"id\", id).build();\n  }\n\n  public void doSomething(Context ctxt) {\n    final long d = ctxt.getDurationMillis();\n    DynamicTimer.record(staticId, TimeUnit.SECONDS, d, TimeUnit.MILLISECONDS);\n\n    MonitorConfig dynamicId = MonitorConfig.builder(\"dynamicId\")\n      .withTag(\"id\", id)\n      .withTag(\"foo\", ctxt.getFoo())\n      .build();\n    DynamicTimer.record(dynamicId, TimeUnit.SECONDS, d, TimeUnit.MILLISECONDS);\n  }\n}\n</code></pre> <p>Spectator:</p> <pre><code>public class Foo {\n  private final Registry registry;\n  private final String id;\n  private final Timer staticTimer;\n  private final Id dynamicId;\n\n  @Inject\n  public Foo(Registry registry, String id) {\n    this.registry = registry;\n    this.id = id;\n    staticTimer = registry.timer(\"staticId\", \"id\", id);\n    dynamicId = registry.createId(\"dynamicId\", \"id\", id);\n  }\n\n  public void doSomething(Context ctxt) {\n    final long d = ctxt.getDurationMillis();\n\n    // Keeping the reference to the timer avoids additional allocations\n    // to create the id object and the lookup cost\n    staticTimer.record(d, TimeUnit.MILLISECONDS);\n\n    // If the id is dynamic it must be looked up\n    registry.timer(\"dynamicId\", \"id\", id, \"foo\", ctxt.getFoo())\n      .record(d, TimeUnit.MILLISECONDS);\n\n    // This will update the same timer as the line above, but the base part\n    // of the id is precomputed to make it cheaper to construct the id.\n    registry.timer(dynamicId.withTag(\"foo\", ctxt.getFoo()))\n      .record(d, TimeUnit.MILLISECONDS);\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/servo-migration/#longgauge","title":"LongGauge","text":"<p>See the general overview of registration differences and summary of Gauge usage.</p> <p>Servo:</p> <pre><code>public class Foo {\n  private final LongGauge g = new LongGauge(\n    MonitorConfig.builder(\"name\").build());\n\n  public Foo(String id) {\n    Monitors.registerObject(id, this);\n  }\n}\n</code></pre> <p>Spectator:</p> <pre><code>public class Foo {\n  private final AtomicLong v;\n\n  @Inject\n  public Foo(Registry registry, String id) {\n    Id gaugeId = registry.createId(\"name\").withTag(\"id\", id);\n    v = registry.gauge(gaugeId, new AtomicLong());\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/servo-migration/#monitorconfig","title":"MonitorConfig","text":"<p>See the documentation on naming.</p> <p>Servo:</p> <pre><code>MonitorConfig id = MonitorConfig.builder(\"name\")\n  .withTag(\"country\", \"US\")\n  .withTag(\"device\",  \"xbox\")\n  .build();\n</code></pre> <p>Spectator:</p> <pre><code>Id id = registry.createId(\"name\")\n  .withTag(\"country\", \"US\")\n  .withTag(\"device\",  \"xbox\");\n\n// or\n\nId id = registry.createId(\"name\", \"country\", \"US\", \"device\", \"xbox\");\n</code></pre>"},{"location":"spectator/lang/java/servo-migration/#monitoredcache","title":"MonitoredCache","text":"<p>Not supported because Spectator does not have a direct dependency on Guava. If there is enough demand, an extension can be created.</p>"},{"location":"spectator/lang/java/servo-migration/#numbergauge","title":"NumberGauge","text":"<p>See the general overview of registration differences and summary of gauge usage.</p> <p>Servo:</p> <pre><code>public class Foo {\n  private final NumberGauge g = new NumberGauge(\n    MonitorConfig.builder(\"name\").build(), new AtomicLong());\n\n  public Foo(String id) {\n    Monitors.registerObject(id, this);\n  }\n}\n</code></pre> <p>Spectator:</p> <pre><code>public class Foo {\n  private final AtomicLong v;\n\n  @Inject\n  public Foo(Registry registry, String id) {\n    Id gaugeId = registry.createId(\"name\").withTag(\"id\", id);\n    v = registry.gauge(gaugeId, new AtomicLong());\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/servo-migration/#statstimer","title":"StatsTimer","text":"<p>Not supported, see overview of differences.</p>"},{"location":"spectator/lang/java/servo-migration/#stepcounter","title":"StepCounter","text":"<p>See the general overview of registration differences and summary of Counter usage.</p> <p>Servo:</p> <pre><code>public class Foo {\n  private final Counter c =\n    new StepCounter(MonitorConfig.builder(\"name\").build());\n\n  public Foo(String id) {\n    Monitors.registerObject(id, this);\n  }\n\n  public void doSomething() {\n    c.increment();\n  }\n}\n</code></pre> <p>Spectator:</p> <pre><code>public class Foo {\n  private final Counter c;\n\n  @Inject\n  public Foo(Registry registry, String id) {\n    c = registry.counter(\"name\", \"id\", id);\n  }\n\n  public void doSomething() {\n    c.increment();\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/testing/","title":"Testing","text":"<p>Testing should be relatively straightforward if you are using injection for the Registry. Consider a sample class:</p> <pre><code>public class Foo {\n\n  private final Counter counter;\n\n  @Inject\n  public Foo(Registry registry) {\n    counter = registry.counter(\"foo\");\n  }\n\n  public void doSomething() {\n    counter.increment();\n  }\n}\n</code></pre> <p>Tests will typically want to use an isolated instance of the <code>DefaultRegistry</code>.</p>"},{"location":"spectator/lang/java/testing/#simple-test","title":"Simple Test","text":"<p>A basic standalone test class would look something like:</p> <pre><code>public class FooTest {\n\n  private Registry registry;\n  private Foo foo;\n\n  @Before\n  public void init() {\n    registry = new DefaultRegistry();\n    foo = new Foo(registry);\n  }\n\n  @Test\n  public void doSomething() {\n    foo.doSomething();\n    Assert.assertEquals(1, registry.counter(\"foo\").count());\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/testing/#spring-test","title":"Spring Test","text":"<p>If using Spring, then you can create a binding for the <code>DefaultRegistry</code>, for example:</p> <pre><code>public class FooTest {\n\n  private Registry registry;\n  private Foo foo;\n\n  @Configuration\n  public static class TestConfiguration {\n    @Bean\n    public Registry registry() {\n      return new DefaultRegistry();\n    }\n\n    @Bean\n    public Foo foo(Registry registry) {\n      return new Foo(registry);\n    }\n  }\n\n  private AnnotationConfigApplicationContext createContext() {\n    AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();\n    context.register(TestConfiguration.class);\n    context.refresh();\n    return context;\n  }\n\n  @Test\n  public void doSomething() {\n    try (AnnotationConfigApplicationContext context = createContext()) {\n      Foo foo = context.getBean(Foo.class);\n      foo.doSomething();\n\n      Registry registry = context.getBean(Registry.class);\n      Assert.assertEquals(1, registry.counter(\"foo\").count());\n    }\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/testing/#exceptions","title":"Exceptions","text":"<p>By default, for most user errors Spectator will log a warning rather than throw an exception. The rationale is that users do not often think about instrumentation and logging code causing an exception and interrupting the control flow of a program. However, for test cases it is recommended to be more aggressive and learn about problems as early as possible. This can be done by setting a system property:</p> <pre><code>spectator.api.propagateWarnings=true\n</code></pre> <p>Consider an example:</p> <pre><code>private static final Id RARE_EXCEPTION_ID = null;\n\npublic void doSomethingImportant() {\n  try {\n    ... do work ...\n  } catch (RareException e) {\n    // There is a bug in the program, an Id is not allowed to be null. In production we do\n    // not want it to throw and interrupt the control flow. Instrumentation should gracefully\n    // degrade.\n    registry.counter(RARE_EXCEPTION_ID).increment();\n\n    // These statements are important to provide context for operating the system\n    // and to ensure the app continues to function properly.\n    LOGGER.error(\"important context for user\", e);\n    properlyHandleException(e);\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/usage/","title":"Usage","text":""},{"location":"spectator/lang/java/usage/#project","title":"Project","text":"<ul> <li>Source</li> <li>Javadoc </li> <li>Product Lifecycle: GA</li> <li>Requirements: Java &gt;= 8</li> </ul>"},{"location":"spectator/lang/java/usage/#install-library","title":"Install Library","text":"<ol> <li> <p>Depend on the API library, which is available in Maven Central. The only transitive dependency is <code>slf4j</code>. For Gradle, the dependency is specified as follows:</p> <pre><code>dependencies {\n    compile \"com.netflix.spectator:spectator-api:0.101.0\"\n}\n</code></pre> </li> <li> <p>Pick a Registry to bind, when initializing the application.</p> </li> <li> <p>If running at Netflix, see the Netflix Integration section.</p> </li> </ol>"},{"location":"spectator/lang/java/usage/#instrumenting-code","title":"Instrumenting Code","text":"<p>Suppose we have a server and we want to keep track of:</p> <ul> <li>Number of requests received with dimensions for breaking down by status code, country, and   the exception type if the request fails in an unexpected way.</li> <li>Latency for handling requests.</li> <li>Summary of the response sizes.</li> <li>Current number of active connections on the server.</li> </ul> <p>Here is some sample code that does that:</p> <pre><code>// In the application initialization setup a registry\nRegistry registry = new DefaultRegistry();\nServer s = new Server(registry);\n\npublic class Server {\n  private final Registry registry;\n  private final Id requestCountId;\n  private final Timer requestLatency;\n  private final DistributionSummary responseSizes;\n\n  @Inject\n  public Server(Registry registry) {\n    this.registry = registry;\n\n    // Create a base id for the request count. The id will get refined with\n    // additional dimensions when we receive a request.\n    requestCountId = registry.createId(\"server.requestCount\");\n\n    // Create a timer for tracking the latency. The reference can be held onto\n    // to avoid additional lookup cost in critical paths.\n    requestLatency = registry.timer(\"server.requestLatency\");\n\n    // Create a distribution summary meter for tracking the response sizes.\n    responseSizes = registry.distributionSummary(\"server.responseSizes\");\n\n    // Gauge type that can be sampled. In this case it will invoke the\n    // specified method via reflection to get the value. The registry will\n    // keep a weak reference to the object passed in so that registration will\n    // not prevent garbage collection of the server object.\n    registry.methodValue(\"server.numConnections\", this, \"getNumConnections\");\n  }\n\n  public Response handle(Request req) {\n    final long s = System.nanoTime();\n    requestLatency.record(() -&gt; {\n      try {\n        Response res = doSomething(req);\n\n        // Update the counter id with dimensions based on the request. The\n        // counter will then be looked up in the registry which should be\n        // fairly cheap, such as lookup of id object in a ConcurrentHashMap.\n        // However, it is more expensive than having a local variable seti\n        // to the counter.\n        final Id cntId = requestCountId\n          .withTag(\"country\", req.country())\n          .withTag(\"status\", res.status());\n        registry.counter(cntId).increment();\n\n        responseSizes.record(res.body().size());\n\n        return res;\n      } catch (Exception e) {\n        final Id cntId = requestCountId\n          .withTag(\"country\", req.country())\n          .withTag(\"status\", \"exception\")\n          .withTag(\"error\", e.getClass().getSimpleName());\n        registry.counter(cntId).increment();\n        throw e;\n      }\n    });\n  }\n\n  public int getNumConnections() {\n    // however we determine the current number of connections on the server\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/usage/#netflix-integration","title":"Netflix Integration","text":"<p>When running at Netflix, use the <code>atlas-client</code> library to enable transferring the instrumented data to Atlas. See the appropriate section for the type of project you are working on:</p> <ul> <li>Libraries</li> <li>SBN Applications, specifically standalone apps using SBN.</li> </ul>"},{"location":"spectator/lang/java/usage/#libraries","title":"Libraries","text":"<p>For libraries, the only dependency that should be needed is:</p> <pre><code>com.netflix.spectator:spectator-api:0.101.0\n</code></pre> <p>The bindings to integrate internally should be included with the application. In your code, just inject a Registry, e.g.:</p> <pre><code>public class Foo {\n  @Inject\n  public Foo(Registry registry) {\n    ...\n  }\n  ...\n}\n</code></pre> <p>See the testing docs for more information about creating a binding to use with tests. Libraries should not install a particular registry. The bindings to use for the Registry should be determined by the application that is using the library. Think of it as being like slf4j where logging configuration is up to the end-user, not the library owner.</p> <p>You may want to avoid binding errors if the end-user has not provided a binding for the Spectator registry. For Spring, this can be done by using optional injections, for example:</p> <pre><code>// Sample library class\npublic class MyLib {\n  Registry registry;\n\n  @Inject\n  public MyLib(Optional&lt;Registry&gt; registryOpt) {\n    this.registry = registryOpt.orElseGet(NoopRegistry::new);\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/usage/#sbn-applications","title":"SBN Applications","text":"<p>Applications should include <code>spring-boot-netflix-starter-metrics</code> which will configure the registry bindings for internal use.</p>"},{"location":"spectator/lang/java/ext/jvm-buffer-pools/","title":"Buffer Pools","text":"<p>Buffer pools, such as direct byte buffers, can be monitored at a high level using the BufferPoolMXBean provided by the JDK. </p>"},{"location":"spectator/lang/java/ext/jvm-buffer-pools/#getting-started","title":"Getting Started","text":"<p>To get information about buffer pools in Spectator, just setup registration of standard MXBeans. Note, if you are building an app at Netflix, then this should happen automatically via the normal platform initialization.</p> <pre><code>import com.netflix.spectator.jvm.Jmx;\n\nJmx.registerStandardMXBeans(registry);\n</code></pre>"},{"location":"spectator/lang/java/ext/jvm-buffer-pools/#metrics","title":"Metrics","text":""},{"location":"spectator/lang/java/ext/jvm-buffer-pools/#jvmbuffercount","title":"jvm.buffer.count","text":"<p>Gauge showing the current number of distinct buffers.</p> <p>Unit: count </p> <p>Dimensions:</p> <ul> <li><code>id</code>: type of buffers. Value will be either <code>direct</code> for direct byte buffers or <code>mapped</code> for   memory mapped files.</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-buffer-pools/#jvmbuffermemoryused","title":"jvm.buffer.memoryUsed","text":"<p>Gauge showing the current number of bytes used by all buffers.</p> <p>Unit: bytes </p> <p>Dimensions:</p> <ul> <li><code>id</code>: type of buffers. Value will be either <code>direct</code> for direct byte buffers or <code>mapped</code> for   memory mapped files.</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-classloading/","title":"Class Loading","text":"<p>Uses the ClassLoadingMXBean provided by the JDK to monitor the number of classes loaded and unloaded.</p>"},{"location":"spectator/lang/java/ext/jvm-classloading/#getting-started","title":"Getting Started","text":"<p>To get information about classloading in Spectator, just setup registration of standard MXBeans. Note, if you are building an app at Netflix, then this should happen automatically via the normal platform initialization.</p> <pre><code>import com.netflix.spectator.jvm.Jmx;\n\nJmx.registerStandardMXBeans(registry);\n</code></pre>"},{"location":"spectator/lang/java/ext/jvm-classloading/#metrics","title":"Metrics","text":""},{"location":"spectator/lang/java/ext/jvm-classloading/#jvmclassloadingclassesloaded","title":"jvm.classloading.classesLoaded","text":"<p>Counter reporting the number of classes loaded.</p> <p>Unit: classes/second</p> <p>Dimensions:</p> <ul> <li>None.</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-classloading/#jvmclassloadingclassesunloaded","title":"jvm.classloading.classesUnloaded","text":"<p>Counter reporting the number of classes unloaded.</p> <p>Unit: classes/second</p> <p>Dimensions:</p> <ul> <li>None.</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-compilation/","title":"Compilation","text":"<p>Uses the CompilationMXBean provided by the JDK to monitor the time spent compiling code, for each compiler name.</p>"},{"location":"spectator/lang/java/ext/jvm-compilation/#getting-started","title":"Getting Started","text":"<p>To get information about compilation in Spectator, just setup registration of standard MXBeans. Note, if you are building an app at Netflix, then this should happen automatically via the normal platform initialization.</p> <pre><code>import com.netflix.spectator.jvm.Jmx;\n\nJmx.registerStandardMXBeans(registry);\n</code></pre>"},{"location":"spectator/lang/java/ext/jvm-compilation/#metrics","title":"Metrics","text":""},{"location":"spectator/lang/java/ext/jvm-compilation/#jvmcompilationcompilationtime","title":"jvm.compilation.compilationTime","text":"<p>Counter reporting the amount of elapsed time spent in compilation. If multiple threads are used for compilation, then this value represents the summation of the time each thread spent in compilation. </p> <p>Unit: seconds/second</p> <p>Dimensions:</p> <ul> <li><code>compiler</code>: name of the just-in-time (JIT) compiler</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/","title":"GC Causes","text":"<p>The various GC causes aren't well documented. The list provided here comes from the gcCause.cpp file in the jdk and we include some information on what these mean for the application.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#systemgc__","title":"System.gc__","text":"<p>Something called System.gc(). If you are seeing this once an hour it is likely related to the RMI GC interval. For more details see:</p> <ul> <li>Unexplained System.gc() calls due to Remote Method Invocation (RMI) or explict garbage collections</li> <li>sun.rmi.dgc.client.gcInterval</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#fullgcalot","title":"FullGCAlot","text":"<p>Most likely you'll never see this value. In debug builds of the jdk there is an option, <code>-XX:+FullGCALot</code>, that will trigger a full GC at a regular interval for testing purposes.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#scavengealot","title":"ScavengeAlot","text":"<p>Most likely you'll never see this value. In debug builds of the jdk there is an option, <code>-XX:+ScavengeALot</code>, that will trigger a minor GC at a regular interval for testing purposes.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#allocation_profiler","title":"Allocation_Profiler","text":"<p>Prior to java 8 you would see this if running with the <code>-Xaprof</code> setting. It would be triggered just before the jvm exits. The <code>-Xaprof</code> option was removed in java 8.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#jvmtienv_forcegarbagecollection","title":"JvmtiEnv_ForceGarbageCollection","text":"<p>Something called the JVM tool interface function ForceGarbageCollection. Look at the <code>-agentlib</code> param to java to see what agents are configured.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#gclocker_initiated_gc","title":"GCLocker_Initiated_GC","text":"<p>The GC locker prevents GC from occurring when JNI code is in a critical region. If GC is needed while a thread is in a critical region, then it will allow them to complete, i.e. call the corresponding release function. Other threads will not be permitted to enter a critical region. Once all threads are out of critical regions a GC event will be triggered. </p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#heap_inspection_initiated_gc","title":"Heap_Inspection_Initiated_GC","text":"<p>GC was initiated by an inspection operation on the heap. For example you can trigger this with jmap:</p> <p><code>$ jmap -histo:live &lt;pid&gt;</code></p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#heap_dump_initiated_gc","title":"Heap_Dump_Initiated_GC","text":"<p>GC was initiated before dumping the heap. For example you can trigger this with jmap:</p> <p><code>$ jmap -dump:live,format=b,file=heap.out &lt;pid&gt;</code></p> <p>Another common example would be clicking the Heap Dump button on the Monitor tab in VisualVM.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#whitebox_initiated_young_gc","title":"WhiteBox_Initiated_Young_GC","text":"<p>Most likely you'll never see this value. Used for testing hotspot, it indicates something called <code>sun.hotspot.WhiteBox.youngGC()</code>. </p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#no_gc","title":"No_GC","text":"<p>Used for CMS to indicate concurrent phases.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#allocation_failure","title":"Allocation_Failure","text":"<p>Usually this means that there is an allocation request that is bigger than the available space in young generation and will typically be associated with a minor GC. For G1 this will likely be a major GC and it is more common to see G1_Evacuation_Pause for routine minor collections.</p> <p>On linux the jvm will trigger a GC if the kernel indicates there isn't much memory left via mem_notify.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#tenured_generation_full","title":"Tenured_Generation_Full","text":"<p>Not used?</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#permanent_generation_full","title":"Permanent_Generation_Full","text":"<p>Triggered as a result of an allocation failure in PermGen. Pre java 8.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#metadata_gc_threshold","title":"Metadata_GC_Threshold","text":"<p>Triggered as a result of an allocation failure in Metaspace. Metaspace replaced PermGen was added in java 8.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#cms_generation_full","title":"CMS_Generation_Full","text":"<p>Not used?</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#cms_initial_mark","title":"CMS_Initial_Mark","text":"<p>Initial mark phase of CMS, for more details see Phases of CMS. Unfortunately it doesn't appear to be reported via the mbeans and we just get No_GC.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#cms_final_remark","title":"CMS_Final_Remark","text":"<p>Remark phase of CMS, for more details see Phases of CMS. Unfortunately it doesn't appear to be reported via the mbeans and we just get No_GC.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#cms_concurrent_mark","title":"CMS_Concurrent_Mark","text":"<p>Concurrent mark phase of CMS, for more details see Phases of CMS. Unfortunately it doesn't appear to be reported via the mbeans and we just get No_GC.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#old_generation_expanded_on_last_scavenge","title":"Old_Generation_Expanded_On_Last_Scavenge","text":"<p>Not used?</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#old_generation_too_full_to_scavenge","title":"Old_Generation_Too_Full_To_Scavenge","text":"<p>Not used?</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#ergonomics","title":"Ergonomics","text":"<p>This indicates you are using the adaptive size policy, <code>-XX:+UseAdaptiveSizePolicy</code> and is on by default for recent versions, with the parallel collector (<code>-XX:+UseParallelGC</code>). For more details see The Why of GC Ergonomics.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#g1_evacuation_pause","title":"G1_Evacuation_Pause","text":"<p>An evacuation pause is the most common young gen cause for G1 and indicates that it is copying live objects from one set of regions, young and sometimes young + old, to another set of regions. For more details see Understanding G1 GC Logs.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#g1_humongous_allocation","title":"G1_Humongous_Allocation","text":"<p>A humongous allocation is one where the size is greater than 50% of the G1 region size. Before a humongous allocation the jvm checks if it should do a routine evacuation pause without regard to the actual allocation size, but if triggered due to this check the cause will be listed as humongous allocation. This cause is also used for any collections used to free up enough space for the allocation. </p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#last_ditch_collection","title":"Last_ditch_collection","text":"<p>For perm gen (java 7 or earlier) and metaspace (java 8+) a last ditch collection will be triggered if an allocation fails and the memory pool cannot be expanded.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#illegal_value_-last_gc_cause-_illegal_value","title":"ILLEGAL_VALUE_-last_gc_cause-_ILLEGAL_VALUE","text":"<p>Included for completeness, but you should never see this value.</p>"},{"location":"spectator/lang/java/ext/jvm-gc-causes/#unknown_gccause","title":"unknown_GCCause","text":"<p>Included for completeness, but you should never see this value.</p>"},{"location":"spectator/lang/java/ext/jvm-gc/","title":"Garbage Collection","text":"<p>The GC module registers with the notification emitter of the GarbageCollectorMXBean to provide some basic GC logging and metrics.</p> <ul> <li>Getting started</li> <li>Logging</li> <li>Metrics</li> <li>Alerting</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-gc/#getting-started","title":"Getting Started","text":"<p>For using it internally at Netflix, see the Java Usage guide, otherwise keep reading this section.</p>"},{"location":"spectator/lang/java/ext/jvm-gc/#requirements","title":"Requirements","text":"<p>This library relies on the notification emitter added in 7u4, but there are known issues prior to 7u40. There is also a regression impacting Java 9 and higher, see #502 and JDK-8196325 for more information. For G1, it is recommended to be on the latest version available.</p>"},{"location":"spectator/lang/java/ext/jvm-gc/#dependencies","title":"Dependencies","text":"<pre><code>com.netflix.spectator:spectator-ext-gc:0.101.0\n</code></pre>"},{"location":"spectator/lang/java/ext/jvm-gc/#start-reporting","title":"Start Reporting","text":"<p>Then in the initialization for the application:</p> <pre><code>import com.netflix.spectator.gc.GcLogger;\n...\n// Keep a single instance of the logger\nGcLogger gc = new GcLogger();\ngc.start(null);\n</code></pre>"},{"location":"spectator/lang/java/ext/jvm-gc/#logging","title":"Logging","text":"<p>After GC events, an DEBUG level log message will get reported using slf4j. This makes it easy to see GC events in the context of other log messages for the application. The logger name is <code>com.netflix.spectator.gc.GcLogger</code> and the message will look like:</p> <pre><code>${GC_TYPE}: ${COLLECTOR_NAME}, id=${N}, at=${START_TIME}, duration=${T}ms,\ncause=[${CAUSE}], ${TOTAL_USAGE_BEFORE} =&gt; ${TOTAL_USAGE_AFTER} / ${MAX_SIZE}\n(${PERCENT_USAGE_BEFORE} =&gt; ${PERCENT_USAGE_AFTER})\n</code></pre> <p>The id can be used to verify events were not skipped or correlate with other sources like detailed GC logs. See GC causes for more details on the possible causes.</p> <p>Sample:</p> <pre><code>2014-08-31 02:02:24,724  DEBUG [com.netflix.spectator.gc.GcLogger] YOUNG: ParNew,\nid=5281, at=Sun Aug 31 02:02:24 UTC 2014, duration=2ms, cause=[Allocation Failure],\n0.4G =&gt; 0.3G / 1.8G (24.3% =&gt; 16.6%)\n</code></pre>"},{"location":"spectator/lang/java/ext/jvm-gc/#metrics","title":"Metrics","text":""},{"location":"spectator/lang/java/ext/jvm-gc/#jvmgcallocationrate","title":"jvm.gc.allocationRate","text":"<p>The allocation rate measures how fast the application is allocating memory. It is a counter that is incremented after a GC event by the amount <code>youngGen.sizeBeforeGC</code>.</p> <p>Technically, right now it is:</p> <pre><code>youngGen.sizeBeforeGC - youngGen.sizeAfterGC\n</code></pre> <p>However, <code>youngGen.sizeAfterGC</code> should be 0 and thus the size of young gen before the GC is the amount allocated since the previous GC event.</p> <p>Unit: bytes/second</p> <p>Dimensions:</p> <ul> <li>None.</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-gc/#jvmgcpromotionrate","title":"jvm.gc.promotionRate","text":"<p>The promotion rate measures how fast data is being moved from young generation into the old generation.</p> <p>It is a counter that is incremented after a GC event by the amount:</p> <pre><code>abs(oldGen.sizeAfterGC - oldGen.sizeBeforeGC)\n</code></pre> <p>Unit: bytes/second</p> <p>Dimensions:</p> <ul> <li>None.</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-gc/#jvmgclivedatasize","title":"jvm.gc.liveDataSize","text":"<p>The live data size is the size of the old generation after a major GC.</p> <p>The image below shows how the live data size view compares to a metric showing the current size of the memory pool:</p> <p></p> <p>Unit: bytes</p> <p>Dimensions:</p> <ul> <li>None.</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-gc/#jvmgcmaxdatasize","title":"jvm.gc.maxDataSize","text":"<p>Maximum size for the old generation. Primary use-case is for gaining perspective on the the live data size.</p> <p>Unit: bytes</p> <p>Dimensions:</p> <ul> <li>None.</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-gc/#jvmgcpause","title":"jvm.gc.pause","text":"<p>Pause time for a GC event. All of the values reported are stop the world pauses.</p> <p>Unit: seconds</p> <p>Dimensions:</p> <ul> <li><code>action</code>: action performed by the garbage collector (getGcAction). There is no guarantee, but the typical values seen are <code>end_of_major_GC</code> and <code>end_of_minor_GC</code>.</li> <li><code>cause</code>: cause that instigated GC (getGcCause). For an explanation of common causes see the GC causes page.</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-gc/#jvmgcconcurrentphasetime","title":"jvm.gc.concurrentPhaseTime","text":"<p>Time spent in concurrent phases of CMS pauses.</p> <p>Unit: seconds</p> <p>Dimensions:</p> <ul> <li><code>action</code>: action performed by the garbage collector (getGcAction). There is no guarantee, but the typical values seen are <code>end_of_major_GC</code> and <code>end_of_minor_GC</code>.</li> <li><code>cause</code>: cause that instigated GC (getGcCause). For an explanation of common causes see the GC causes page.</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-gc/#alerting","title":"Alerting","text":"<p>This section assumes the data is available in Atlas, but users of other systems should be able to take the idea and make it work. For all of these alerts it is recommended to check them on instance. At Netflix that can be done by selecting the option in alert ui:</p> <p></p>"},{"location":"spectator/lang/java/ext/jvm-gc/#max-pause-time","title":"Max Pause Time","text":"<p>Example to trigger an alert if the pause time exceeds 500 milliseconds:</p> <pre><code>name,jvm.gc.pause,:eq,\nstatistic,max,:eq,\n:and,\n:max,(,cause,),:by,\n0.5,:gt,\n$cause,:legend\n</code></pre>"},{"location":"spectator/lang/java/ext/jvm-gc/#heap-pressure","title":"Heap Pressure","text":"<p>Example to trigger an alert if the live data size is over 70% of the heap:</p> <pre><code>name,jvm.gc.liveDataSize,:eq,:max,\nname,jvm.gc.maxDataSize,:eq,:max,\n:div,100,:mul,\n70,:gt,\npercentUsed,:legend\n</code></pre>"},{"location":"spectator/lang/java/ext/jvm-memory-pools/","title":"Memory Pools","text":"<p>Uses the MemoryPoolMXBean provided by the JDK to monitor the sizes of java memory spaces such as perm gen, eden, old gen, etc. </p>"},{"location":"spectator/lang/java/ext/jvm-memory-pools/#getting-started","title":"Getting Started","text":"<p>To get information about memory pools in Spectator, just setup registration of standard MXBeans. Note, if you are building an app at Netflix, then this should happen automatically via the normal platform initialization.</p> <pre><code>import com.netflix.spectator.jvm.Jmx;\n\nJmx.registerStandardMXBeans(registry);\n</code></pre>"},{"location":"spectator/lang/java/ext/jvm-memory-pools/#metrics","title":"Metrics","text":""},{"location":"spectator/lang/java/ext/jvm-memory-pools/#jvmmemoryused","title":"jvm.memory.used","text":"<p>Gauge reporting the current amount of memory used. For the young and old gen pools this metric will typically have a sawtooth pattern. For alerting or detecting memory pressure the live data size is probably a better option.</p> <p>Unit: bytes</p> <p>Dimensions:</p> <ul> <li>See metric dimensions.</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-memory-pools/#jvmmemorycommitted","title":"jvm.memory.committed","text":"<p>Gauge reporting the current amount of memory committed. From the javadocs, committed is:</p> <p>The amount of memory (in bytes) that is guaranteed to be available for use by the Java virtual machine. The amount of committed memory may change over time (increase or decrease). The Java virtual machine may release memory to the system and committed could be less than init. committed will always be greater than or equal to used.</p> <p>Unit: bytes </p> <p>Dimensions:</p> <ul> <li>See metric dimensions.</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-memory-pools/#jvmmemorymax","title":"jvm.memory.max","text":"<p>Gauge reporting the max amount of memory that can be used. From the javadocs, max is:</p> <p>The maximum amount of memory (in bytes) that can be used for memory management. Its value may be undefined. The maximum amount of memory may change over time if defined. The amount of used and committed memory will always be less than or equal to max if max is defined. A memory allocation may fail if it attempts to increase the used memory such that <code>used &gt; committed</code> even if <code>used &lt;= max</code> would still be true (for example, when the system is low on virtual memory).</p> <p>Unit: bytes </p> <p>Dimensions:</p> <ul> <li>See metric dimensions.</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-memory-pools/#metric-dimensions","title":"Metric Dimensions","text":"<p>All memory metrics have the following dimensions:</p> <ul> <li><code>id</code>: name of the memory pool being reported. The names of the pools vary depending on the   garbage collector algorithm being used.</li> <li><code>memtype</code>: type of memory. It has two possible values: <code>HEAP</code> and <code>NON_HEAP</code>. For more   information see the javadocs for MemoryType.</li> </ul>"},{"location":"spectator/lang/java/ext/jvm-safepoint/","title":"Safepoint","text":"<p>Uses Hotspot mbean to access the spent in and getting to safepoints.</p>"},{"location":"spectator/lang/java/ext/jvm-safepoint/#getting-started","title":"Getting Started","text":"<p>To get information about compilation in Spectator, just setup registration of standard MXBeans. Note, if you are building an app at Netflix, then this should happen automatically via the normal platform initialization.</p> <pre><code>import com.netflix.spectator.jvm.Jmx;\n\nJmx.registerStandardMXBeans(registry);\n</code></pre>"},{"location":"spectator/lang/java/ext/jvm-safepoint/#metrics","title":"Metrics","text":""},{"location":"spectator/lang/java/ext/jvm-safepoint/#jvmhotspotsafepointtime","title":"jvm.hotspot.safepointTime","text":"<p>Timer reporting the amount of time the application has been stopped for safepoint operations.</p> <p>Unit: seconds</p>"},{"location":"spectator/lang/java/ext/jvm-safepoint/#jvmhotspotsafepointsynctime","title":"jvm.hotspot.safepointSyncTime","text":"<p>Timer reporting the amount of time spent getting to safepoints.</p> <p>Unit: seconds</p>"},{"location":"spectator/lang/java/ext/jvm-threads/","title":"Threads","text":"<p>Uses the ThreadMXBean provided by the JDK to monitor the number of active threads and threads started.</p>"},{"location":"spectator/lang/java/ext/jvm-threads/#getting-started","title":"Getting Started","text":"<p>To get information about threads in Spectator, just setup registration of standard MXBeans. Note, if you are building an app at Netflix, then this should happen automatically via the normal platform initialization.</p> <pre><code>import com.netflix.spectator.jvm.Jmx;\n\nJmx.registerStandardMXBeans(registry);\n</code></pre>"},{"location":"spectator/lang/java/ext/jvm-threads/#metrics","title":"Metrics","text":""},{"location":"spectator/lang/java/ext/jvm-threads/#jvmthreadthreadcount","title":"jvm.thread.threadCount","text":"<p>Gauge reporting the number of active threads.</p> <p>Unit: threads</p> <p>Dimensions:</p> <ul> <li><code>id</code>: thread category, either <code>daemon</code> or <code>non-daemon</code></li> </ul>"},{"location":"spectator/lang/java/ext/jvm-threads/#jvmthreadthreadsstarted","title":"jvm.thread.threadsStarted","text":"<p>Counter reporting the number of threads started.</p> <p>Unit: threads/second</p> <p>Dimensions:</p> <ul> <li>None.</li> </ul>"},{"location":"spectator/lang/java/ext/log4j1/","title":"Log4j1 Appender","text":"<p>Custom appender for log4j1 to track the number of log messages reported. </p> <p>Note</p> <p>Log4j 1.x has reached end of life and is no longer supported by Apache. This extension is provided for some users that have difficulty moving to a supported version of log4j.</p>"},{"location":"spectator/lang/java/ext/log4j1/#getting-started","title":"Getting Started","text":"<p>To use it simply add a dependency:</p> <pre><code>com.netflix.spectator:spectator-ext-log4j1:0.101.0\n</code></pre> <p>Then in your log4j configuration specify the <code>com.netflix.spectator.log4j.SpectatorAppender</code>. In a properties file it would look something like:</p> <pre><code>log4j.rootLogger=ALL, A1\nlog4j.appender.A1=com.netflix.spectator.log4j.SpectatorAppender\n</code></pre>"},{"location":"spectator/lang/java/ext/log4j1/#metrics","title":"Metrics","text":""},{"location":"spectator/lang/java/ext/log4j1/#log4jnummessages","title":"log4j.numMessages","text":"<p>Counters showing the number of messages that have been passed to the appender.</p> <p>Unit: messages/second</p> <p>Dimensions:</p> <ul> <li><code>loglevel</code>: standard log level of the events.</li> </ul>"},{"location":"spectator/lang/java/ext/log4j1/#log4jnumstacktraces","title":"log4j.numStackTraces","text":"<p>Counter for the number of messages with stack traces written to the logs.</p> <p>Unit: messages/second</p> <p>Dimensions:</p> <ul> <li><code>loglevel</code>: standard log level of the events.</li> <li><code>exception</code>: simple class name for the exception that was thrown.</li> <li><code>file</code>: file name for where the exception was thrown.</li> </ul>"},{"location":"spectator/lang/java/ext/log4j2/","title":"Log4j2 Appender","text":"<p>Custom appender for log4j2 to track the number of log messages reported. </p>"},{"location":"spectator/lang/java/ext/log4j2/#getting-started","title":"Getting Started","text":"<p>To use it simply add a dependency:</p> <pre><code>com.netflix.spectator:spectator-ext-log4j2:0.101.0\n</code></pre> <p>Then in your application initialization:</p> <pre><code>Registry registry = ...\nSpectatorAppender.addToRootLogger(\n    registry,             // Registry to use\n    \"spectator\",          // Name for the appender\n    false);               // Should stack traces be ignored?\n</code></pre> <p>This will add the appender to the root logger and register a listener so it will get re-added if the configuration changes. You can also use the appender by specifying it in the log4j2 configuration, but this will cause some of the loggers in Spectator to get created before log4j is properly initialized and result in some lost log messages. With that caveat in mind, if you need the additional flexibility of using the configuration then specify the <code>Spectator</code> appender:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Configuration monitorInterval=\"5\" status=\"warn\"&gt;\n  &lt;Appenders&gt;\n    &lt;Spectator name=\"root\"/&gt;\n  &lt;/Appenders&gt;\n  &lt;Loggers&gt;\n    &lt;Root level=\"debug\"&gt;\n      &lt;AppenderRef ref=\"root\"/&gt;\n    &lt;/Root&gt;\n  &lt;/Loggers&gt;\n&lt;/Configuration&gt;\n</code></pre>"},{"location":"spectator/lang/java/ext/log4j2/#metrics","title":"Metrics","text":""},{"location":"spectator/lang/java/ext/log4j2/#log4jnummessages","title":"log4j.numMessages","text":"<p>Counters showing the number of messages that have been passed to the appender.</p> <p>Unit: messages/second</p> <p>Dimensions:</p> <ul> <li><code>appender</code>: name of the spectator appender.</li> <li><code>loglevel</code>: standard log level of the events.</li> </ul>"},{"location":"spectator/lang/java/ext/log4j2/#log4jnumstacktraces","title":"log4j.numStackTraces","text":"<p>Counter for the number of messages with stack traces written to the logs. This will only be collected if the <code>ignoreExceptions</code> flag is set to false for the appender.</p> <p>Unit: messages/second</p> <p>Dimensions:</p> <ul> <li><code>appender</code>: name of the spectator appender.</li> <li><code>loglevel</code>: standard log level of the events.</li> <li><code>exception</code>: simple class name for the exception that was thrown.</li> <li><code>file</code>: file name for where the exception was thrown.</li> </ul>"},{"location":"spectator/lang/java/ext/placeholders/","title":"Placeholders","text":"<p>The placeholders extension allows for identifiers to be created with dimensions that will get filled in based on the context when an activity occurs. The primary use-cases are to support:</p> <ol> <li>Optional dimensions that can be conditionally enabled.</li> <li>Pulling dimensions from another context such as a thread local store. This can make    it is easier to share the across various parts of the code.</li> </ol>"},{"location":"spectator/lang/java/ext/placeholders/#dependencies","title":"Dependencies","text":"<p>To use the placeholders support add a dependency on:</p> <pre><code>com.netflix.spectator:spectator-ext-placeholders:0.101.0\n</code></pre>"},{"location":"spectator/lang/java/ext/placeholders/#usage","title":"Usage","text":"<p>Placeholder support is available for activity based types including counters, timers, and distribution summaries. To get started create a <code>PlaceholderFactory</code> from the registry:</p> <pre><code>PlaceholderFactory factory = PlaceholderFactory.from(registry);\n</code></pre> <p>Then use the factory to create an identifier using a <code>TagFactory</code> to dynamically fetch the value for a given dimension when some activity occurs. Suppose we want to use a dynamic configuration library such as Archaius to conditionally enable a dimension with high cardinality:</p> <pre><code>public class Server {\n\n  private final Context context;\n  private final Counter rps;\n\n  public Server(Context context, PropertyFactory props, Registry registry) {\n    this.context = context;\n\n    // Property that can be dynamically updated to indicate whether or not\n    // detailed dimensions should be added to metrics.\n    Property&lt;Boolean&gt; enabled = props\n      .getProperty(\"server.detailedMetricsEnabled\")\n      .asBoolean(false);\n\n    // Factory for creating instances of the counter using placeholders\n    PlaceholderFactory factory = PlaceholderFactory.from(registry);\n\n    // Create the underlying id with 4 possible dimensions:\n    // *  method and status - low cardinality and always added if available\n    //    in the context.\n    // *  geo and device - high cardinality and only available if the property\n    //    to enable detailed metrics is set to true.\n    PlaceholderId rpsId = factory.createId(\"server.requests\")\n      .withTagFactory(TagFactory.from(\"method\", context::getMethod))\n      .withTagFactory(TagFactory.from(\"status\", context::getStatus))\n      .withTagFactory(new DetailedDimension(\"geo\", enabled, context::getGeo))\n      .withTagFactory(new DetailedDimension(\"device\", enabled, context::getDevice));\n    rps = factory.counter(rpsId);\n  }\n\n  public Response handle(Request request) {\n    fillInContext(request);\n    Response response = process(request);\n    fillInContext(response);\n\n    // Update the counter, the placeholders will be resolved when the activity, in\n    // this case the increment is called.\n    rps.increment();\n    return response;\n  }\n\n  // Tag factory that can be controlled with an enabled property.\n  private static class DetailedDimension implements TagFactory {\n\n    private final String name;\n    private final Supplier&lt;String&gt; valueFunc;\n\n    DetailedDimension(String name, Property&lt;Boolean&gt; enabled, Supplier&lt;String&gt; valueFunc) {\n      this.name = name;\n      this.enabled = enabled;\n      this.valueFunc = valueFunc;\n    }\n\n    @Override public String name() {\n      return name;\n    }\n\n    @Override public Tag createTag() {\n      return enabled.get()\n          ? new BasicTag(name, valueFunc.get())\n          : null;\n    }\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/ext/thread-pools/","title":"Thread Pools","text":"<p>Java's ThreadPoolExecutor exposes several properties that are useful to monitor to assess the health, performance, and configuration of the pool.</p>"},{"location":"spectator/lang/java/ext/thread-pools/#getting-started","title":"Getting Started","text":"<p>To report thread pool metrics, one can attach a ThreadPoolMonitor in the following manner:</p> <pre><code>import com.netflix.spectator.api.patterns.ThreadPoolMonitor;\n\nThreadPoolMonitor.attach(registry, myThreadPoolExecutor, \"my-thread-pool\");\n</code></pre> <p>The thread pool's properties will be polled regularly in the background and will report metrics to the provided registry. The third parameter will be added to each metric as an <code>id</code> dimension, if provided. However, if the value is <code>null</code> or an empty string, then a default will be used as the <code>id</code>.</p>"},{"location":"spectator/lang/java/ext/thread-pools/#metrics","title":"Metrics","text":""},{"location":"spectator/lang/java/ext/thread-pools/#threadpooltaskcount","title":"threadpool.taskCount","text":"<p>Counter of the total number of tasks that have been scheduled.</p> <p>Unit: tasks/second</p> <p>Data Source: <code>ThreadPoolExecutor#getTaskCount()</code></p>"},{"location":"spectator/lang/java/ext/thread-pools/#threadpoolcompletedtaskcount","title":"threadpool.completedTaskCount","text":"<p>Counter of the total number of tasks that have completed.</p> <p>Unit: tasks/second</p> <p>Data Source: <code>ThreadPoolExecutor#getCompletedTaskCount()</code></p>"},{"location":"spectator/lang/java/ext/thread-pools/#threadpoolcurrentthreadsbusy","title":"threadpool.currentThreadsBusy","text":"<p>Gauge showing the current number of threads actively doing work.</p> <p>Unit: count</p> <p>Data Source: <code>ThreadPoolExecutor#getActiveCount()</code></p>"},{"location":"spectator/lang/java/ext/thread-pools/#threadpoolmaxthreads","title":"threadpool.maxThreads","text":"<p>Gauge showing the current maximum number of threads configured for the pool.</p> <p>Unit: count</p> <p>Data Source: <code>ThreadPoolExecutor#getMaximumPoolSize()</code></p>"},{"location":"spectator/lang/java/ext/thread-pools/#threadpoolpoolsize","title":"threadpool.poolSize","text":"<p>Gauge showing the current size of the pool.</p> <p>Unit: count</p> <p>Data Source: <code>ThreadPoolExecutor#getPoolSize()</code></p>"},{"location":"spectator/lang/java/ext/thread-pools/#threadpoolcorepoolsize","title":"threadpool.corePoolSize","text":"<p>Gauge showing the current maximum number of core threads configured for the pool.</p> <p>Unit: count</p> <p>Data Source: <code>ThreadPoolExecutor#getCorePoolSize()</code></p>"},{"location":"spectator/lang/java/ext/thread-pools/#threadpoolqueuesize","title":"threadpool.queueSize","text":"<p>Gauge showing the current number of threads queued for execution.</p> <p>Unit: count</p> <p>Data Source: <code>ThreadPoolExecutor#getQueue().size()</code></p>"},{"location":"spectator/lang/java/meters/counter/","title":"Java Counters","text":"<p>Counters are created using the Registry, which is be setup as part of application initialization. For example:</p> <pre><code>public class Queue {\n\n  private final Counter insertCounter;\n  private final Counter removeCounter;\n  private final QueueImpl impl;\n\n  @Inject\n  public Queue(Registry registry) {\n    insertCounter = registry.counter(\"queue.insert\");\n    removeCounter = registry.counter(\"queue.remove\");\n    impl = new QueueImpl();\n  }\n</code></pre> <p>Then call increment when an event occurs:</p> <pre><code>  public void insert(Object obj) {\n    insertCounter.increment();\n    impl.insert(obj);\n  }\n\n  public Object remove() {\n    if (impl.nonEmpty()) {\n      removeCounter.increment();\n      return impl.remove();\n    } else {\n      return null;\n    }\n  }\n</code></pre> <p>Optionally, an amount can be passed in when calling increment. This is useful when a collection of events happen together. </p> <pre><code>  public void insertAll(Collection&lt;Object&gt; objs) {\n    insertCounter.increment(objs.size());\n    impl.insertAll(objs);\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/meters/dist-summary/","title":"Java Distribution Summaries","text":"<p>Distribution Summaries are created using the Registry, which will be setup as part of application initialization. For example:</p> <pre><code>public class Server {\n\n  private final DistributionSummary requestSize;\n\n  @Inject\n  public Server(Registry registry) {\n    requestSize = registry.distributionSummary(\"server.requestSize\");\n  }\n</code></pre> <p>Then call record when an event occurs:</p> <p><pre><code>  public Response handle(Request request) {\n    requestSize.record(request.sizeInBytes());\n  }\n}\n</code></pre> Note: If the amount recorded is less than 0 the value will be dropped.</p>"},{"location":"spectator/lang/java/meters/gauge/","title":"Java Gauges","text":""},{"location":"spectator/lang/java/meters/gauge/#polled-gauges","title":"Polled Gauges","text":"<p>The most common use of Gauges is by registering a hook with Spectator, so that it will poll the values in the background. This is done by using the PolledMeter helper class.</p> <p>A Polled Gauge is registered by passing in an id, a reference to the object, and a function to get or compute a numeric value based on the object. Note that a Gauge should only be registered once, not on each update. Consider this example of a web server tracking the number of connections:</p> <pre><code>class HttpServer {\n  // Tracks the number of current connections to the server\n  private AtomicInteger numConnections;\n\n  public HttpServer(Registry registry) {\n    numConnections = PolledMeter.using(registry)\n      .withName(\"server.numConnections\")\n      .monitorValue(new AtomicInteger(0));\n  }\n\n  public void onConnectionCreated() {\n    numConnections.incrementAndGet();\n    ...\n  }\n\n  public void onConnectionClosed() {\n    numConnections.decrementAndGet();\n    ...\n  }\n\n  ...\n}\n</code></pre> <p>The Spectator Registry will keep a weak reference to the object. If the object is garbage collected, then it will automatically drop the registration. In the example above, the Registry will have a weak reference to <code>numConnections</code> and the server instance will have a strong reference to <code>numConnections</code>. If the server instance goes away, then the Gauge will as well. </p> <p>When multiple Gauges are registered with the same id, the reported value will be the sum of the matches. For example, if multiple instances of the <code>HttpServer</code> class were created on different ports, then the value <code>server.numConnections</code> would be the total number of connections across all server instances. If a different behavior is desired, then ensure your usage does not perform multiple registrations.</p> <p>There are several different ways to register a Gauge:</p>"},{"location":"spectator/lang/java/meters/gauge/#using-number","title":"Using Number","text":"<p>A Gauge can also be created based on an implementation of Number. Note the Number implementation should be thread-safe. For example:</p> <pre><code>AtomicInteger size = new AtomicInteger();\nPolledMeter.using(registry)\n  .withName(\"queue.size\")\n  .monitorValue(size);\n</code></pre> <p>The call will return the Number so the registration can be inline on the assignment:</p> <pre><code>AtomicInteger size = PolledMeter.using(registry)\n  .withName(\"queue.size\")\n  .monitorValue(new AtomicInteger());\n</code></pre> <p>Updates to the value are performed by updating the Number instance directly.</p>"},{"location":"spectator/lang/java/meters/gauge/#using-lambda","title":"Using Lambda","text":"<p>Specify a lambda that takes the object as parameter.</p> <pre><code>public class Queue {\n\n  @Inject\n  public Queue(Registry registry) {\n    PolledMeter.using(registry)\n      .withName(\"queue.size\")\n      .monitorValue(this, Queue::size);\n  }\n\n  ...\n}\n</code></pre> <p>Warning</p> <p>Be careful to avoid creating a reference to the object in the lambda. It will prevent garbage collection and can lead to a memory leak in the application. For example, by calling size without using the passed in object there will be a reference to <code>this</code>:</p> <pre><code>PolledMeter.using(registry)\n  .withName(\"queue.size\")\n  .monitorValue(this, obj -&gt; size());\n</code></pre>"},{"location":"spectator/lang/java/meters/gauge/#collection-sizes","title":"Collection Sizes","text":"<p>For classes that implement <code>Collection</code> or <code>Map</code>, there are helpers:</p> <pre><code>Queue queue = new LinkedBlockingQueue();\nPolledMeter.using(registry)\n  .withName(\"queue.size\")\n  .monitorSize(queue);\n\nMap&lt;String, String&gt; cache = new ConcurrentMap&lt;&gt;();\nPolledMeter.using(registry)\n  .withName(\"cache.size\")\n  .monitorSize(cache);\n</code></pre>"},{"location":"spectator/lang/java/meters/gauge/#monotonic-counters","title":"Monotonic Counters","text":"<p>A common technique used by some libraries is to expose a monotonically increasing counter that represents the number of events since the system was initialized. An example of that in the JDK is ThreadPoolExecutor.getCompletedTaskCount, which returns the number of completed tasks on the thread pool.</p> <p>For sources like this, the <code>monitorMonotonicCounter</code> method can be used:</p> <pre><code>// For an implementation of Number\nLongAdder tasks = new LongAdder();\nPolledMeter.using(registry)\n  .withName(\"pool.completedTasks\")\n  .monitorMonotonicCounter(tasks);\n\n// Or using a lambda\nThreadPoolExecutor executor = ...\nPolledMeter.using(registry)\n  .withName(\"pool.completedTasks\")\n  .monitorMonotonicCounter(executor, ThreadPoolExecutor::getCompletedTaskCount);\n</code></pre> <p>For thread pools specifically, there are better options for getting standard metrics. See the docs for the Thread Pools extension for more information.</p>"},{"location":"spectator/lang/java/meters/gauge/#active-gauges","title":"Active Gauges","text":"<p>Gauges can also be set directly by the user. In this mode, the user is responsible for regularly updating the value of the Gauge by calling <code>set</code>. Looking at the HttpServer example, with an active gauge, it would look like:</p> <pre><code>class HttpServer {\n  // Tracks the number of current connections to the server\n  private AtomicInteger numConnections;\n  private Gauge gauge;\n\n  public HttpServer(Registry registry) {\n    numConnections = new AtomicInteger();\n    gauge = registry.gauge(\"server.numConnections\");\n    gauge.set(numConnections.get());\n  }\n\n  public void onConnectionCreated() {\n    numConnections.incrementAndGet();\n    gauge.set(numConnections.get());\n    ...\n  }\n\n  public void onConnectionClosed() {\n    numConnections.decrementAndGet();\n    gauge.set(numConnections.get());\n    ...\n  }\n\n  ...\n}\n</code></pre>"},{"location":"spectator/lang/java/meters/percentile-timer/","title":"Java Percentile Timers","text":"<p>Note: Percentile timers generate a metric per bucket in the histogram. Create instances once per ID and reuse them as needed. Avoid adding tags with high cardinality as that increases the cardinality of the metric. If at all possible, use a Timer instead.</p> <p>To get started, create an instance using the Registry:</p> <pre><code>public class Server {\n\n  private final Registry registry;\n  private final PercentileTimer requestLatency;\n\n  @Inject\n  public Server(Registry registry) {\n    this.registry = registry;\n    requestLatency = PercentileTimer.builder(registry)\n        .withId(registry.createId(\"server.request.latency\", \"status\", \"200\"))\n        .build();\n</code></pre> <p>Then wrap the call you need to measure, preferably using a lambda:</p> <pre><code>  public Response handle(Request request) {\n    return requestLatency.recordRunnable(() -&gt; handleImpl(request));\n  }\n</code></pre> <p>The lambda variants will handle exceptions for you and ensure the record happens as part of a finally block using the monotonic time. It could also have been done more explicitly like:</p> <pre><code>  public Response handle(Request request) {\n    final long start = registry.clock().monotonicTime();\n    try {\n      return handleImpl(request);\n    } finally {\n      final long end = registry.clock().monotonicTime();\n      requestLatency.record(end - start, TimeUnit.NANOSECONDS);\n    }\n  }\n</code></pre> <p>This example uses the Clock from the Registry, which can be useful for testing, if you need to control the timing. In actual usage, it will typically get mapped to the system clock. It is recommended to use a monotonically increasing source for measuring the times, to avoid occasionally having bogus measurements due to time adjustments. For more information, see the Clock documentation.</p>"},{"location":"spectator/lang/java/meters/timer/","title":"Java Timers","text":""},{"location":"spectator/lang/java/meters/timer/#timer","title":"Timer","text":"<p>To get started, create an instance using the Registry:</p> <pre><code>public class Server {\n\n  private final Registry registry;\n  private final Timer requestLatency;\n\n  @Inject\n  public Server(Registry registry) {\n    this.registry = registry;\n    requestLatency = registry.timer(\"server.requestLatency\");\n  }\n</code></pre> <p>Then wrap the call you need to measure, preferably using a lambda:</p> <pre><code>  public Response handle(Request request) {\n    return requestLatency.recordRunnable(() -&gt; handleImpl(request));\n  }\n</code></pre> <p>The lambda variants will handle exceptions for you and ensure the record happens as part of a finally block using the monotonic time. It could also have been done more explicitly like:</p> <pre><code>  public Response handle(Request request) {\n    final long start = registry.clock().monotonicTime();\n    try {\n      return handleImpl(request);\n    } finally {\n      final long end = registry.clock().monotonicTime();\n      requestLatency.record(end - start, TimeUnit.NANOSECONDS);\n    }\n  }\n</code></pre> <p>This example uses the Clock from the Registry, which can be useful for testing, if you need to control the timing. In actual usage, it will typically get mapped to the system clock. It is recommended to use a monotonically increasing source for measuring the times, to avoid occasionally having bogus measurements due to time adjustments. For more information, see the Clock documentation.</p> <p>Note: If the amount recorded is less than 0 the value will be dropped.</p>"},{"location":"spectator/lang/java/meters/timer/#longtasktimer","title":"LongTaskTimer","text":"<p>To get started, create an instance using the Registry:</p> <pre><code>import com.netflix.spectator.api.patterns.LongTaskTimer;\n\npublic class MetadataService {\n\n  private final LongTaskTimer metadataRefresh;\n\n  @Inject\n  public MetadataService(Registry registry) {\n    metadataRefresh = LongTaskTimer.get(\n        registry, registry.createId(\"metadata.refreshDuration\"));\n    // setup background thread to call refresh()\n  }\n\n  private void refresh() {\n    final int id = metadataRefresh.start();\n    try {\n      refreshImpl();\n    } finally {\n      metadataRefresh.stop(id);\n    }\n  }\n</code></pre> <p>The id value returned by the <code>start</code> method is used to keep track of a particular task being measured by the LongTaskTimer. It must be stopped using the provided id. Note that unlike a regular Timer that does not do anything until the final duration is recorded, a LongTaskTimer will report as two Gauges:</p> <ul> <li><code>duration</code>: total duration spent within all currently running tasks.</li> <li><code>activeTasks</code>: number of currently running tasks.</li> </ul> <p>This means that you can see what is happening while the task is running, but you need to keep in mind:</p> <ul> <li>The meter id is fixed before the task begins. There is no way to change tags based on the run, e.g., update a different Timer, if an exception is thrown.</li> <li>Being a Gauge, it is inappropriate for short tasks. In particular, Gauges are sampled and if it is not sampled during the execution, or the sampling period is a significant subset of the expected duration, then the duration value will not be meaningful.</li> </ul>"},{"location":"spectator/lang/java/registry/metrics3/","title":"Metrics3 Registry","text":"<p>Registry that uses metrics3 as the underlying implementation. To use the metrics registry, add a dependency on the <code>spectator-reg-metrics3</code> library. For gradle:</p> <pre><code>com.netflix.spectator:spectator-reg-metrics3:0.101.0\n</code></pre> <p>Then when initializing the application, use the <code>MetricsRegistry</code>. For more information see the metrics3 example.</p>"},{"location":"spectator/lang/java/registry/overview/","title":"Registry","text":"<p>The Registry is the main class for managing a set of meters. A Meter is a class for collecting a set of measurements about your application.</p>"},{"location":"spectator/lang/java/registry/overview/#choose-implementation","title":"Choose Implementation","text":"<p>The core Spectator library, <code>spectator-api</code>, comes with the following Registry implementations:</p> Class         Dependency         Description      DefaultRegistry spectator-api                  Updates local counters, frequently used with unit tests.      NoopRegistry spectator-api                  Does nothing, tries to make operations as cheap as possible.                  This implementation is typically used to help understand the overhead being created         due to instrumentation. It can also be useful in testing to help ensure that no side         effects were introduced where the instrumentation is now needed in order for the         application for function properly.      MetricsRegistry spectator-reg-metrics3          Map to metrics3 library.                  This implementation is typically used for reporting to local files, JMX, or other         backends like Graphite. Note that it uses a hierarchical naming scheme rather         than the dimensional naming used by Spectator, so the names will get flattened         when mapped to this Registry.  <p>It is recommended for libraries to write code against the Registry interface and allow the implementation to get injected by the user of the library. The simplest way is to accept the Registry via the constructor, for example:</p> <pre><code>public class HttpServer {\n  public HttpServer(Registry registry) {\n    // use registry to collect measurements\n  }\n}\n</code></pre> <p>The user of the class can then provide the implementation:</p> <pre><code>Registry registry = new DefaultRegistry();\nHttpServer server = new HttpServer(registry);\n</code></pre> <p>More complete examples can be found on the testing page or in the spectator-examples repo.</p>"},{"location":"spectator/lang/java/registry/overview/#working-with-ids","title":"Working with Ids","text":"<p>Spectator is primarily intended for collecting data for dimensional time series backends like Atlas. The ids used for looking up a Meter in the Registry consist of a name and set of tags. Ids will be consumed many times by users after the data has been reported, so they should be chosen with some care and thought about how they will get used. See the conventions page for some general guidelines.</p> <p>Ids are created via the Registry, for example:</p> <pre><code>Id id = registry.createId(\"server.requestCount\");\n</code></pre> <p>The ids are immutable, so they can be freely passed around and used in a concurrent context. Tags can be added when an id is created:</p> <pre><code>Id id = registry.createId(\n    \"server.requestCount\",\n    \"status\", \"2xx\",\n    \"method\", \"GET\"\n);\n</code></pre> <p>Or by using <code>withTag</code> and <code>withTags</code> on an existing id:</p> <pre><code>public class HttpServer {\n  private final Id baseId;\n\n  public HttpServer(Registry registry) {\n    baseId = registry.createId(\"server.requestCount\");\n  }\n\n  private void handleRequestComplete(HttpRequest req, HttpResponse res) {\n    // Remember Id is immutable, withTags will return a copy with the\n    // the additional metadata\n    Id reqId = baseId.withTags(\n      \"status\", res.getStatus(),\n      \"method\", req.getMethod().name());\n    registry.counter(reqId).increment();\n  }\n\n  private void handleRequestError(HttpRequest req, Throwable t) {\n    // Can also be added individually using `withTag`. However, it is better\n    // for performance to batch modifications using `withTags`.\n    Id reqId = baseId\n      .withTag(\"error\",  t.getClass().getSimpleName())\n      .withTag(\"method\", req.getMethod().name());\n    registry.counter(reqId).increment();\n  }\n}\n</code></pre>"},{"location":"spectator/lang/java/registry/overview/#collecting-measurements","title":"Collecting Measurements","text":"<p>Once you have an id, the Registry can be used to get an instance of a Meter to record a measurement. Meters can roughly be categorized in two groups:</p>"},{"location":"spectator/lang/java/registry/overview/#active","title":"Active","text":"<p>Active Meters are ones that are called directly when some event occurs. There are three basic types supported:</p> <ul> <li>Counters measure how often something is occurring. This will be reported to backend systems as a rate-per-second. For example, the number of requests processed by a web server.</li> <li>Timers measure how long something took. For example, the latency of requests processed by a web server.</li> <li>Distribution Summaries measure the size of something. For example, the entity sizes for requests processed by a web server.</li> </ul>"},{"location":"spectator/lang/java/registry/overview/#passive","title":"Passive","text":"<p>Passive Meters are ones where the Registry has a reference to get the value when needed. For example, the number of current connections on a web server or the number threads that are currently in use. These will be Gauges.</p>"},{"location":"spectator/lang/java/registry/overview/#global-registry","title":"Global Registry","text":"<p>There are some use-cases where injecting the Registry is not possible or is too cumbersome. The main example from the core Spectator libraries is the log4j appender. The Global Registry is useful there because logging is often initialized before any other systems and Spectator itself uses logging via the slf4j api which is quite likely being bound to log4j when that the appender is being used. By using the Global Registry, the logging initialization can proceed before the Spectator initialization in the application. Though any measurements taken before a Registry instance has been added will be lost.</p> <p>The Global Registry is accessed using:</p> <pre><code>Registry registry = Spectator.globalRegistry();\n</code></pre> <p>By default, it will not record anything. For a specific registry instance you can choose to configure it to work with the Global Registry by calling <code>add</code>:</p> <pre><code>public void init() {\n  Registry registry = // Choose an appropriate implementation\n\n  // Add it to the global registry so it will receive\n  // any activity on the global registry\n  Spectator.globalRegistry().add(registry);\n}\n</code></pre> <p>Any measurements taken while no Registries are added to the global instance will be lost. If multiple Registries are added, all will receive updates made to the Global Registry.</p>"},{"location":"spectator/lang/nodejs/usage/","title":"Usage","text":""},{"location":"spectator/lang/nodejs/usage/#project","title":"Project","text":""},{"location":"spectator/lang/nodejs/usage/#spectator-js","title":"spectator-js","text":"<ul> <li>Source</li> <li>NPM</li> <li>Product Lifecycle: GA</li> <li>Module Name: <code>nflx-spectator</code></li> </ul> <p>This module can be used to instrument an application using counters, distribution summaries, gauges, long task timers, timers, and more complex meter types (like Bucket or Percentile Timers) using a dimensional data model.</p> <p>The generated metrics are periodically sent to an Atlas Aggregator.</p>"},{"location":"spectator/lang/nodejs/usage/#spectator-js-nodejsmetrics","title":"spectator-js-nodejsmetrics","text":"<ul> <li>Source</li> <li>NPM</li> <li>Product Lifecycle: GA</li> <li>Module Name: <code>nflx-spectator-nodejsmetrics</code></li> </ul> <p>Generate Node.js runtime metrics using the spectator-js Node module.</p>"},{"location":"spectator/lang/nodejs/usage/#install-libraries","title":"Install Libraries","text":"<p>Add the following dependencies to <code>package.json</code>:</p> <pre><code>{\n  \"dependencies\": {\n    \"nflx-spectator\": \"*\",\n    \"nflx-spectator-nodejsmetrics\": \"*\"\n  }\n}\n</code></pre>"},{"location":"spectator/lang/nodejs/usage/#instrumenting-code","title":"Instrumenting Code","text":"<pre><code>'use strict';\n\nconst spectator = require('nflx-spectator');\n\n// Netflix applications can use the nflx-spectator-config node module available\n// internally through artifactory to generate the config required by nflx-spectator\nfunction getConfig() {\n  return {\n    commonTags: {'nf.node': 'i-1234'},\n    uri: 'http://atlas.example.org/v1/publish',\n    timeout: 1000 // milliseconds \n  }\n}\n\nclass Response {\n  constructor(status, size) {\n    this.status = status;\n    this.size = size;\n  }\n}\n\nclass Server {\n  constructor(registry) {\n    this.registry = registry;\n    // create a base Id, to which we'll add some dynamic tags later\n    this.requestCountId = registry.createId('server.requestCount', {version: 'v1'});\n    this.requestLatency = registry.timer('server.requestLatency');\n    this.responseSize = registry.distributionSummary('server.responseSizes');\n  }\n\n  handle(request) {\n    const start = this.registry.hrtime();\n\n    // do some work based on request and obtain a response\n    const res = new Response(200, 64);\n\n    // update the counter id with dimensions based on the request. The\n    // counter will then be looked up in the registry which should be \n    // fairly cheap, such as a lookup of an id object in a map\n    // However, it is more expensive than having a local variable set\n    // to the counter\n    const counterId = this.requestCountId.withTags({country: request.country, \n        status: res.status});\n    this.registry.counter(counterId).increment();\n    this.requestLatency.record(this.registry.hrtime(start));\n    this.responseSize.record(res.size);\n    return res;\n  }\n}\n\nconst config = getConfig();\nconst registry = new spectator.Registry(config);\n\nclass Request {\n  constructor(country) {\n    this.country = country;\n  }\n}\n\n// somehow get a request from the user...\nfunction getNextRequest() {\n  return new Request('AR');\n}\n\nfunction handleTermination() {\n  registry.stop();\n}\n\nprocess.on('SIGINT', handleTermination);\nprocess.on('SIGTERM', handleTermination);\n\nregistry.start();\n\nconst server = new Server(registry);\n\nfor (let i = 0; i &lt; 3; ++i) {\n  const req = getNextRequest();\n  server.handle(req)\n}\n\nregistry.stop();\n</code></pre>"},{"location":"spectator/lang/nodejs/usage/#enable-runtime-metrics","title":"Enable Runtime Metrics","text":"<pre><code>'use strict';\n\nfunction getConfig() {\n}\n\nconst spectator = require('nflx-spectator');\nconst NodeMetrics = require('nflx-spectator-nodejsmetrics');\n\nconst config = {\n  commonTags: {'nf.node': 'i-1234'},\n  uri: 'http://atlas.example.org/v1/publish'\n};\nconst registry = new spectator.Registry(config);\nregistry.start();\n\nconst metrics = new NodeMetrics(registry);\nmetrics.start(); // start collecting nodejs metrics\n\n// ...\n\nmetrics.stop();\nregistry.stop();\n</code></pre>"},{"location":"spectator/lang/nodejs/usage/#netflix-integration","title":"Netflix Integration","text":"<p>Create a Netflix Spectator Config to be used by spectator-js.</p> <p>Only applications should depend on the <code>@netflix-internal/spectator-conf</code> package. Libraries should get the Registry passed by the application, and therefore should only need to depend on spectator-js.</p> <p>Add the following dependencies to <code>package.json</code>:</p> <pre><code>{\n  \"dependencies\": {\n    \"nflx-spectator\": \"*\",\n    \"nflx-spectator-nodejsmetrics\": \"*\",\n    \"@netflix-internal/spectator-conf\": \"*\"\n  }\n}\n</code></pre> <p>This configuration also brings in spectator-js-nodejsmetrics to provide Node.js runtime metrics.</p> <p>You can override the logger used by the Spectator registry by setting the logger property. The specified logger should provide <code>debug</code>, <code>info</code>, and <code>error</code> methods. By default, spectator-js logs to stdout.</p> <pre><code>const spectator = require('nflx-spectator');\nconst NodeMetrics = require('nflx-spectator-nodejsmetrics');\nconst getSpectatorConfig = require('@netflix-internal/spectator-conf');\nconst logger = require('pino')();\n\n//...\n\nconst registry = new spectator.Registry(getSpectatorConfig());\nregistry.logger = logger;\nregistry.start();\n\nconst metrics = new NodeMetrics(registry);\nmetrics.start();\n\nfunction handleTermination() {\n  metrics.stop();\n  registry.stop();\n}\n\nprocess.on('SIGINT', handleTermination);\nprocess.on('SIGTERM', handleTermination);\n\n//... your app\n\nhandleTermination();\n</code></pre>"},{"location":"spectator/lang/nodejs/meters/counter/","title":"Counter","text":"<p>TBD</p>"},{"location":"spectator/lang/nodejs/meters/dist-summary/","title":"Distribution Summary","text":"<p>TBD</p>"},{"location":"spectator/lang/nodejs/meters/gauge/","title":"Gauge","text":"<p>TBD</p>"},{"location":"spectator/lang/nodejs/meters/percentile-timer/","title":"Percentile Timer","text":"<p>TBD</p>"},{"location":"spectator/lang/nodejs/meters/timer/","title":"Timer","text":"<p>TBD</p>"},{"location":"spectator/lang/py/migrations/","title":"Migrations","text":""},{"location":"spectator/lang/py/migrations/#migrating-from-02-to-10","title":"Migrating from 0.2 to 1.0","text":"<p>Version 1.0 consists of a major rewrite that cleans up and simplifies the <code>spectator-py</code> thin client API. It is designed to send metrics through spectatord. As a result, some functionality has been moved to other modules, or removed. Most uses of the various meters through the <code>GlobalRegistry</code> will continue to work as expected, although migrating to the new <code>Registry</code> usage pattern is advised. A key addition is the ability to work directly with complex <code>MeterId</code> objects, which offers more ways to compose tags.</p>"},{"location":"spectator/lang/py/migrations/#new","title":"New","text":""},{"location":"spectator/lang/py/migrations/#config","title":"Config","text":"<ul> <li>Replace the <code>SidecarConfig</code> with <code>Config</code>, and simplify usage.</li> <li>The <code>location</code> configuration is clarified, with a default set to the <code>spectatord</code> UDP port, and a new option for picking the default Unix Domain Socket for <code>spectatord</code>.</li> <li>The <code>extra_common_tags</code> concept is clarified. Any extra common tags provided through the <code>Config</code> object are merged with two process-specific tags that may be present in environment variables.</li> <li>Any <code>MeterId</code> or <code>Meter</code> objects created through <code>Registry</code> methods will contain these extra tags.</li> </ul>"},{"location":"spectator/lang/py/migrations/#meters","title":"Meters","text":"<ul> <li>The <code>AgeGauge</code> meter added a <code>now()</code> method, which sets <code>0</code> as the value, so you do not need to remember this special value.</li> <li>Add <code>MonotonicCounterUint</code> with a <code>c_uint64</code> data type, to support <code>uint64</code> data types. These are not commonly encountered, as they usually only show up in networking metrics, such as bytes/sec in high-volume contexts. When you need it, you need it, else wise, it can be ignored.</li> <li>The <code>MonotonicCounter</code> with a <code>float</code> data type continues to exist, for the more common use case.</li> <li>Note that monotonic counters are convenience meter types provided by <code>spectatord</code>, because they help you avoid the work of tracking previous values and calculating deltas.</li> </ul>"},{"location":"spectator/lang/py/migrations/#registry","title":"Registry","text":"<ul> <li>Add a <code>new_id()</code> method and <code>*_with_id()</code> methods for all meter types, to support more complex tag operations related to <code>MeterId</code> objects. This follows the way they work in the other clients.</li> </ul>"},{"location":"spectator/lang/py/migrations/#moved","title":"Moved","text":""},{"location":"spectator/lang/py/migrations/#meters_1","title":"Meters","text":"<ul> <li>Separate classes for each <code>Meter</code> type. Relocated to a new module, <code>spectator.meter</code>.</li> </ul>"},{"location":"spectator/lang/py/migrations/#stopwatch","title":"StopWatch","text":"<ul> <li>The <code>StopWatch</code> context manager is no longer part of the <code>Timer</code> class; it is now a standalone class. It has been preserved, because it continues to fulfill the purpose of simplifying how <code>Timer</code> and <code>PercentileTimer</code> meters record their values after exiting a block of code, and there are a few uses of this class across the organization.</li> </ul> <p>Before:</p> <pre><code>import time\nfrom spectator import GlobalRegistry\n\nserver_latency = GlobalRegistry.pct_timer(\"serverLatency\")\n\nwith server_latency.stopwatch():\n    time.sleep(5)\n</code></pre> <p>After:</p> <pre><code>import time\nfrom spectator.registry import Registry\nfrom spectator.stopwatch import StopWatch\n\nregistry = Registry()\nserver_latency = registry.pct_timer(\"serverLatency\")\n\nwith StopWatch(server_latency):\n    time.sleep(5)\n</code></pre>"},{"location":"spectator/lang/py/migrations/#writers","title":"Writers","text":"<ul> <li>Separate classes for each <code>Writer</code> type. Relocated to a new module, <code>spectator.writer</code>.</li> </ul>"},{"location":"spectator/lang/py/migrations/#removed","title":"Removed","text":"<ul> <li>All remnants of the previous thick-client API.</li> </ul>"},{"location":"spectator/lang/py/migrations/#deprecated","title":"Deprecated","text":"<ul> <li>The <code>GlobalRegistry</code> is a hold-over from the thick-client version of this library, but it has been maintained to help minimize the amount of code change that application owners need to implement when adopting the thin-client version of the library. Replace with direct use of <code>Registry</code>.</li> <li>There are no plans to remove the <code>GlobalRegistry</code>, until we know that all uses have been removed.</li> </ul> <p>Before:</p> <pre><code>from spectator import GlobalRegistry\n\nGlobalRegistry.gauge(\"server.queueSize\", ttl_seconds=120).set(10)\n</code></pre> <p>After:</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.gauge(\"server.queueSize\", ttl_seconds=120).set(10)\n</code></pre>"},{"location":"spectator/lang/py/migrations/#migrating-from-01-to-02","title":"Migrating from 0.1 to 0.2","text":"<ul> <li>This library no longer publishes directly to the Atlas backends. It now publishes to the SpectatorD sidecar which is bundled with all standard AMIs and containers. If you must have the previous direct publishing behavior, because SpectatorD is not yet available on the platform where your code runs, then you can pin to version <code>0.1.18</code>.</li> <li>The internal Netflix configuration companion library is no longer required and this dependency may be dropped from your project.</li> <li>The API surface area remains unchanged to avoid breaking library consumers, and standard uses of <code>GlobalRegistry</code> helper methods for publishing metrics continue to work as expected. Several helper methods on meter classes are now no-ops, always returning values such as <code>0</code> or <code>nan</code>. If you want to write tests to validate metrics publication, take a look at the tests in this library for a few examples of how that can be done. The core idea is to capture the lines which will be written out to SpectatorD.</li> <li> <p>Replace uses of <code>PercentileDistributionSummary</code> with direct use of the Registry <code>pct_distribution_summary</code> method.</p> <pre><code># before\nfrom spectator import GlobalRegistry\nfrom spectator.histogram import PercentileDistributionSummary\n\nd = PercentileDistributionSummary(GlobalRegistry, \"server.requestSize\")\nd.record(10)\n</code></pre> <pre><code># after\nfrom spectator import GlobalRegistry\n\nGlobalRegistry.pct_distribution_summary(\"server.requestSize\").record(10)\n</code></pre> </li> <li> <p>Replace uses of <code>PercentileTimer</code> with direct use of the Registry <code>pct_timer</code> method.</p> <pre><code># before\nfrom spectator import GlobalRegistry\nfrom spectator.histogram import PercentileTimer\n\nt = PercentileTimer(GlobalRegistry, \"server.requestSize\")\nt.record(0.01)\n</code></pre> <pre><code># after\nfrom spectator import GlobalRegistry\n\nGlobalRegistry.pct_timer(\"server.requestSize\").record(0.1)\n</code></pre> </li> <li> <p>Implemented new meter types supported by SpectatorD: <code>age_gauge</code>, <code>max_gauge</code> and <code>monotonic_counter</code>. See the SpectatorD documentation or the class docstrings for more details.</p> </li> </ul>"},{"location":"spectator/lang/py/usage/","title":"spectator-py Usage","text":"<p>Python thin-client metrics library for use with Atlas and SpectatorD.</p>"},{"location":"spectator/lang/py/usage/#supported-python-versions","title":"Supported Python Versions","text":"<p>This library currently targets the Python &gt;= 3.8.</p>"},{"location":"spectator/lang/py/usage/#installing","title":"Installing","text":"<p>Install this library for your project as follows:</p> <pre><code>pip install netflix-spectator-py\n</code></pre>"},{"location":"spectator/lang/py/usage/#instrumenting-code","title":"Instrumenting Code","text":""},{"location":"spectator/lang/py/usage/#simple-example","title":"Simple Example","text":"<pre><code>import logging\n\nfrom flask import Flask, request, Response\nfrom flask.logging import default_handler\nfrom spectator.registry import Registry\n\nroot_logger = logging.getLogger()\nroot_logger.setLevel(logging.DEBUG)\nroot_logger.addHandler(default_handler)\n\nregistry = Registry()\n\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef root():\n    return Response(\"Usage: /api/v1/play?country=foo&amp;title=bar\")\n\n@app.route(\"/api/v1/play\", methods=[\"GET\", \"POST\"])\ndef play():\n    country = request.args.get(\"country\", default=\"none\")\n    title = request.args.get(\"title\", default=\"none\")\n    registry.counter(\"server.requestCount\", {\"version\": \"v1\"}).increment()\n    return Response(f\"requested play for country={country} title={title}\")\n</code></pre> <p>Save this snippet as <code>app.py</code>, then <code>flask --app app run</code>.</p>"},{"location":"spectator/lang/py/usage/#complex-example","title":"Complex Example","text":"<pre><code>import logging\n\nfrom flask import Flask, request, Response\nfrom flask.logging import default_handler\nfrom spectator.config import Config\nfrom spectator.registry import Registry\nfrom spectator.stopwatch import StopWatch\n\nroot_logger = logging.getLogger()\nroot_logger.setLevel(logging.DEBUG)\nroot_logger.addHandler(default_handler)\n\nconfig = Config(extra_common_tags={\"nf.platform\": \"my_platform\"})\nregistry = Registry(config)\n\nrequest_count_id = registry.new_id(\"server.requestCount\", {\"version\": \"v1\"})\nrequest_latency = registry.timer(\"server.requestLatency\")\nresponse_size = registry.distribution_summary(\"server.responseSize\")\n\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef root():\n    return Response(\"Usage: /api/v1/play?country=foo&amp;title=bar\")\n\n@app.route(\"/api/v1/play\", methods=[\"GET\", \"POST\"])\ndef play():\n    if request.method == \"GET\":\n        with StopWatch(request_latency):\n            status_code = 200\n            country = request.args.get(\"country\", default=\"none\")\n            title = request.args.get(\"title\", default=\"none\")\n\n            tags = {\"country\": country, \"title\": title, \"status\": str(status_code)}\n            request_count_with_tags = request_count_id.with_tags(tags)\n            counter = registry.counter_with_id(request_count_with_tags)\n            counter.increment()\n\n            message = f\"requested play for country={country} title={title}\"\n            response_size.record(len(message))\n            return Response(message, status=status_code)\n    else:\n        status_code = 405\n\n        tags = {\"status\": str(status_code)}\n        request_count_with_tags = request_count_id.with_tags(tags)\n        counter = registry.counter_with_id(request_count_with_tags)\n        counter.increment()\n\n        return Response(\"unsupported request method\", status=status_code)\n</code></pre> <p>Save this snippet as <code>app.py</code>, then <code>flask --app app run</code>.</p>"},{"location":"spectator/lang/py/usage/#importing","title":"Importing","text":""},{"location":"spectator/lang/py/usage/#standard-usage","title":"Standard Usage","text":"<p>Instantiate a <code>Registry</code> object, with either a default or custom <code>Config</code>, and use it to create and manage <code>MeterId</code> and <code>Meter</code> objects.</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.counter(\"server.requestCount\").increment()\n</code></pre>"},{"location":"spectator/lang/py/usage/#legacy-usage","title":"Legacy Usage","text":"<p>The <code>GlobalRegistry</code> concept is a hold-over from the thick-client version of this library, but it has been maintained to help minimize the amount of code change that application owners need to implement when adopting the thin client version of the library. It existed as a concept in the thick client because it was stateful, and required starting background threads. The thin client version is stateless. </p> <p>Importing the <code>GlobalRegistry</code> instantiates a <code>Registry</code> with a default <code>Config</code> that applies process-specific common tags based on environment variables and opens a UDP socket to the local SpectatorD agent. The remainder of the instance-specific common tags are provided by SpectatorD. Once imported, the <code>GlobalRegistry</code> can be used to create and manage Meters.</p> <pre><code>from spectator import GlobalRegistry\n\nGlobalRegistry.counter(\"server.requestCount\").increment()\n</code></pre>"},{"location":"spectator/lang/py/usage/#logging","title":"Logging","text":"<p>This package provides the following loggers:</p> <ul> <li><code>spectator.meter.meter_id</code>, which reports invalid tags at WARNING level.</li> <li><code>spectator.registry</code>, which reports Registry status messages at INFO level, and errors closing writers at ERROR level.</li> <li><code>spectator.writer</code>, which reports the protocol lines written at DEBUG level, and writing errors at ERROR level.</li> </ul> <p>When troubleshooting metrics collection and reporting, you should set the <code>spectator.meter.meter_id</code> logger to <code>DEBUG</code> level, before the first metric is recorded. For example:</p> <pre><code>import logging\n\n# record the human-readable time, name of the logger, logging level, thread id and message\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(thread)d - %(message)s'\n)\n\nlogging.getLogger('spectator.meter.meter_id').setLevel(logging.DEBUG)\n</code></pre>"},{"location":"spectator/lang/py/usage/#runtime-metrics","title":"Runtime Metrics","text":"<p>Use spectator-py-runtime-metrics. Follow instructions in the README to enable collection.</p>"},{"location":"spectator/lang/py/usage/#working-with-meterid-objects","title":"Working with MeterId Objects","text":"<p>Each metric stored in Atlas is uniquely identified by the combination of the name and the tags associated with it. In <code>spectator-py</code>, this data is represented with <code>MeterId</code> objects, created by the <code>Registry</code>. The <code>new_id()</code> method returns new <code>MeterId</code> objects, which have extra common tags applied, and which can be further customized by calling the <code>with_tag()</code> and <code>with_tags()</code> methods. Each <code>MeterId</code> will create and store a validated subset of the <code>spectatord</code> protocol line to be written for each <code>Meter</code>, when it is instantiated. <code>MeterId</code> objects are immutable, so they can be freely passed around and used concurrently. Manipulating the tags with the provided methods will create new <code>MeterId</code> objects, to assist with maintaining immutability.</p> <p>Note that all tag keys and values must be strings. For example, if you want to keep track of the number of successful requests, then you must cast integers to strings. The <code>MeterId</code> class will validate these values, dropping or changing any that are not valid, and reporting a warning log.</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.counter(\"server.numRequests\", {\"statusCode\": str(200)}).increment()\n\nnum_requests_id = registry.new_id(\"server.numRequests\", {\"statusCode\": str(200)})\nregistry.counter_with_id(num_requests_id).increment()\n</code></pre> <p>Atlas metrics will be consumed by users many times after the data has been reported, so they should be chosen thoughtfully, while considering how they will be used. See the naming conventions page for general guidelines on metrics naming and restrictions.</p>"},{"location":"spectator/lang/py/usage/#meter-types","title":"Meter Types","text":"<ul> <li>Age Gauge</li> <li>Counter</li> <li>Distribution Summary</li> <li>Gauge</li> <li>Max Gauge</li> <li>Monotonic Counter</li> <li>Monotonic Counter Uint</li> <li>Percentile Distribution Summary</li> <li>Percentile Timer</li> <li>Timer</li> </ul>"},{"location":"spectator/lang/py/usage/#asyncio-support","title":"asyncio Support","text":"<p>The <code>Registry</code> provides a <code>UdpWriter</code> by default. UDP is a non-blocking, unordered and connectionless protocol, which is ideal for communicating with a local SpectatorD process in a variety of circumstances. The <code>UdpWriter</code> should be used in asyncio applications.</p> <p>The <code>FileWriter</code> implementation, which can be used to communicate with the SpectatorD Unix domain socket, for slightly higher performance, does not offer asyncio support at this time.</p>"},{"location":"spectator/lang/py/usage/#ipv6-support","title":"IPv6 Support","text":"<p>By default, SpectatorD will listen on <code>IPv6 UDP *:1234</code>, without setting the <code>v6_only(true)</code> flag. On dual-stacked systems, this means that it will receive packets from both IPv4 and IPv6, and the IPv4 addresses will show up on the server as IPv4-mapped IPv6 addresses.</p> <p>By default, the <code>UdpWriter</code> will send UDP packets to <code>127.0.0.1:1234</code>, which will allow for communication with SpectatorD on dual-stacked systems.</p> <p>On IPv6-only systems, it may be necessary to change the default configuration using one of the following methods:</p> <ul> <li>Configure the following environment variable, which will override the default location <code>Config</code> in the <code>Registry</code>:</li> </ul> <pre><code>export SPECTATOR_OUTPUT_LOCATION=\"udp://[::1]:1234\"\n</code></pre> <ul> <li>Provide a custom <code>Config</code> for the <code>Registry</code>:</li> </ul> <pre><code>from spectator.config import Config\nfrom spectator.registry import Registry\n\nconfig = Config(location=\"udp://[::1]:1234\")\nregistry = Registry(config)\nregistry.counter(\"server.numRequests\").increment()\n</code></pre>"},{"location":"spectator/lang/py/usage/#output-location","title":"Output Location","text":"<p>If you need to override the default output location (UDP) of the <code>Registry</code>, then you can set a <code>Config</code> class location to one of the following supported values:</p> <ul> <li><code>none</code>   - Disable output.</li> <li><code>memory</code> - Write to memory.</li> <li><code>stderr</code> - Write to standard error for the process.</li> <li><code>stdout</code> - Write to standard out for the process.</li> <li><code>udp</code>    - Write to the default UDP port for <code>spectatord</code>.</li> <li><code>unix</code>   - Write to the default unix datagram socket for <code>spectatord</code>.</li> <li><code>file://$path_to_file</code> - Write to a custom file (e.g. <code>file:///tmp/foo/bar</code>).</li> <li><code>udp://$host:$port</code>    - Write to a custom UDP socket.</li> </ul> <p>The <code>SPECTATOR_OUTPUT_LOCATION</code> environment variable accepts the same values, and can be used to override the value provided to the <code>Config</code> class, which may be useful in CI/CD contexts. For example, if you want to disable metrics publishing from the <code>Registry</code>, then you can set:</p> <pre><code>export SPECTATOR_OUTPUT_LOCATION=none\n</code></pre>"},{"location":"spectator/lang/py/usage/#batch-usage","title":"Batch Usage","text":"<p>When using <code>spectator-py</code> to report metrics from a batch job, ensure that the batch job runs for at least five (5), if not ten (10) seconds in duration. This is necessary in order to allow sufficient time for <code>spectatord</code> to publish metrics to the Atlas backend; it publishes every five seconds. If your job does not run this long, or you find you are missing metrics that were reported at the end of your job run, then add a five-second sleep before exiting: <code>time.sleep(5)</code>. This will allow time for the metrics to be sent.</p>"},{"location":"spectator/lang/py/usage/#debug-metrics-delivery-to-spectatord","title":"Debug Metrics Delivery to <code>spectatord</code>","text":"<p>In order to see debug log messages from <code>spectatord</code>, create an <code>/etc/default/spectatord</code> file with the following contents:</p> <pre><code>SPECTATORD_OPTIONS=\"--verbose\"\n</code></pre> <p>This will report all metrics that are sent to the Atlas backend in the <code>spectatord</code> logs, which will provide an opportunity to correlate metrics publishing events from your client code.</p>"},{"location":"spectator/lang/py/usage/#design-considerations-reporting-intervals","title":"Design Considerations - Reporting Intervals","text":"<p>This client is stateless, and sends a UDP packet (or unixgram) to <code>spectatord</code> each time a meter is updated. If you are performing high-volume operations, on the order of tens-of-thousands or millions of operations per second, then you should pre-aggregate your metrics and report them at a cadence closer to the <code>spectatord</code> publish interval of 5 seconds. This will keep the CPU usage related to <code>spectator-py</code> and <code>spectatord</code> low (around 1% or less), as compared to up to 40% for high-volume scenarios.</p>"},{"location":"spectator/lang/py/usage/#writing-tests","title":"Writing Tests","text":"<p>To write tests against this library, instantiate an instance of the <code>Registry</code> and provide a <code>Config</code> that selects the MemoryWriter. This <code>Writer</code> stores all updates in a <code>List[str]</code>. Use the <code>writer()</code> method on the <code>Registry</code> to access the writer, then inspect the <code>last_line()</code> or <code>get()</code> all messages to verify your metrics updates.</p> <pre><code>import unittest\n\nfrom spectator.config import Config\nfrom spectator.registry import Registry\n\nclass MetricsTest(unittest.TestCase):\n\n    def test_counter(self):\n        r = Registry(Config(\"memory\"))\n\n        c = r.counter(\"server.numRequests\")\n        self.assertTrue(r.writer().is_empty())\n\n        c.increment()\n        self.assertEqual(\"c:server.numRequests:1\", r.writer().last_line())\n</code></pre>"},{"location":"spectator/lang/py/usage/#protocol-parser","title":"Protocol Parser","text":"<p>A SpectatorD line protocol parser is available, which ca be used for validating  the results captured by a <code>MemoryWriter</code>.</p> <pre><code>import unittest\n\nfrom spectator.meter.counter import Counter\nfrom spectator.protocol_parser import get_meter_class, parse_protocol_line\n\nclass ProtocolParserTest(unittest.TestCase):\n\n    def test_parse_counter_with_multiple_tags(self):\n        symbol, id, value = parse_protocol_line(\"c:counter,foo=bar,baz=quux:1\")\n        self.assertEqual(\"c\", symbol)\n        self.assertEqual(Counter, get_meter_class(symbol))\n        self.assertEqual(\"counter\", id.name())\n        self.assertEqual({\"foo\": \"bar\", \"baz\": \"quux\"}, id.tags())\n        self.assertEqual(\"1\", value)\n</code></pre>"},{"location":"spectator/lang/py/meters/age-gauge/","title":"Age Gauge","text":"<p>The value is the time in seconds since the epoch at which an event has successfully occurred, or <code>0</code> to use the current time in epoch seconds. After an Age Gauge has been set, it will continue reporting the number of seconds since the last time recorded, for as long as the SpectatorD process runs. The purpose of this metric type is to enable users to more easily implement the Time Since Last Success alerting pattern.</p> <p>To set a specific time as the last success:</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.age_gauge(\"time.sinceLastSuccess\").set(1611081000)\n\nlast_success = registry.new_id(\"time.sinceLastSuccess\")\nregistry.age_gauge_with_id(last_success).set(1611081000)\n</code></pre> <p>To set <code>now()</code> as the last success:</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.age_gauge(\"time.sinceLastSuccess\").now()\n\nlast_success = registry.new_id(\"time.sinceLastSuccess\")\nregistry.age_gauge_with_id(last_success).now()\n</code></pre> <p>By default, a maximum of <code>1000</code> Age Gauges are allowed per <code>spectatord</code> process, because there is no mechanism for cleaning them up. This value may be tuned with the <code>--age_gauge_limit</code> flag on the <code>spectatord</code> binary.</p> <p>Since Age Gauges are long-lived entities that reside in the memory of the SpectatorD process, if you need to delete and re-create them for any reason, then you can use the SpectatorD admin server to accomplish this task. You can delete all Age Gauges or a single Age Gauge.</p> <p>Example:</p> <pre><code>curl -X DELETE \\\nhttp://localhost:1234/metrics/A\n</code></pre> <pre><code>curl -X DELETE \\\nhttp://localhost:1234/metrics/A/fooIsTheName,some.tag=val1,some.otherTag=val2\n</code></pre>"},{"location":"spectator/lang/py/meters/counter/","title":"Counter","text":"<p>A Counter is used to measure the rate at which an event is occurring. Considering an API endpoint, a Counter could be used to measure the rate at which it is being accessed.</p> <p>Counters are reported to the backend as a rate-per-second. In Atlas, the <code>:per-step</code> operator can be used to convert them back into a value-per-step on a graph.</p> <p>Call <code>increment()</code> when an event occurs:</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.counter(\"server.numRequests\").increment()\n\nnum_requests = registry.new_id(\"server.numRequests\")\nregistry.counter_with_id(num_requests).increment()\n</code></pre> <p>You can also pass a value to <code>increment()</code>. This is useful when a collection of events happens together:</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.counter(\"queue.itemsAdded\").increment(10)\n\nnum_requests = registry.new_id(\"server.numRequests\")\nregistry.counter_with_id(num_requests).increment(10)\n</code></pre>"},{"location":"spectator/lang/py/meters/dist-summary/","title":"Distribution Summary","text":"<p>A Distribution Summary is used to track the distribution of events. It is similar to a Timer, but more general, in that the size does not have to be a period of time. For example, a Distribution Summary could be used to measure the payload sizes of requests hitting a server.</p> <p>Always use base units when recording data, to ensure that the tick labels presented on Atlas graphs are readable. If you are measuring payload size, then use bytes, not kilobytes (or some other unit). This means that a <code>4K</code> tick label will represent 4 kilobytes, rather than 4 kilo-kilobytes.</p> <p>Call <code>record()</code> with a value:</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.distribution_summary(\"server.requestSize\").record(10)\n\nrequest_size = registry.new_id(\"server.requestSize\")\nregistry.distribution_summary_with_id(request_size).record(10)\n</code></pre>"},{"location":"spectator/lang/py/meters/gauge/","title":"Gauges","text":"<p>A gauge is a value that is sampled at some point in time. Typical examples for gauges would be the size of a queue or number of threads in a running state. Since gauges are not updated inline when a state change occurs, there is no information about what might have occurred between samples.</p> <p>Consider monitoring the behavior of a queue of tasks. If the data is being collected once a minute, then a gauge for the size will show the size when it was sampled. The size may have been much higher or lower at some point during interval, but that is not known.</p> <p>Call <code>set()</code> with a value:</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.gauge(\"server.queueSize\").set(10)\n\nqueue_size = registry.new_id(\"server.queueSize\")\nregistry.gauge_with_id(queue_size).set(10)\n</code></pre> <p>Gauges will report the last set value for 15 minutes. This done so that updates to the values do not need to be collected on a tight 1-minute schedule to ensure that Atlas shows unbroken lines in graphs. A custom TTL may be configured for gauges. SpectatorD enforces a minimum TTL of 5 seconds.</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.gauge(\"server.queueSize\", ttl_seconds=120).set(10)\n\nqueue_size = registry.new_id(\"server.queueSize\")\nregistry.gauge_with_id(queue_size, ttl_seconds=120).set(10)\n</code></pre>"},{"location":"spectator/lang/py/meters/max-gauge/","title":"Max Gauge","text":"<p>The value is a number that is sampled at a point in time, but it is reported as a maximum Gauge value to the backend. This ensures that only the maximum value observed during a reporting interval is sent to the backend, thus over-riding the last-write-wins semantics of standard Gauges. Unlike standard Gauges, Max Gauges do not continue to report to the backend, and there is no TTL.</p> <p>Call <code>set()</code> with a value:</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.max_gauge(\"server.queueSize\").set(10)\n\nqueue_size = registry.new_id(\"server.queueSize\")\nregistry.max_gauge_with_id(queue_size).set(10)\n</code></pre>"},{"location":"spectator/lang/py/meters/monotonic-counter-uint/","title":"Monotonic Counter Uint","text":"<p>A Monotonic Counter (uint64) is used to measure the rate at which an event is occurring, when the source data is a monotonically increasing number. A minimum of two samples must be sent, in order to calculate a delta value and report it to the backend as a rate-per-second. A variety of networking metrics may be reported monotonically, and this metric type provides a convenient means of recording these values, at the expense of a slower time-to-first metric.</p> <p>Call <code>set()</code> when an event occurs:</p> <pre><code>from ctypes import c_uint64\nfrom spectator.registry import Registry\n\nregistry = Registry()\nregistry.monotonic_counter_uint(\"iface.bytes\").set(c_uint64(1))\n\niface_bytes = registry.new_id(\"iface.bytes\")\nregistry.monotonic_counter_uint_with_id(iface_bytes).set(c_uint64(1))\n</code></pre>"},{"location":"spectator/lang/py/meters/monotonic-counter/","title":"Monotonic Counter","text":"<p>A Monotonic Counter (float) is used to measure the rate at which an event is occurring, when the source data is a monotonically increasing number. A minimum of two samples must be sent, in order to calculate a delta value and report it to the backend as a rate-per-second. A variety of networking metrics may be reported monotonically, and this metric type provides a convenient means of recording these values, at the expense of a slower time-to-first metric.</p> <p>Call <code>set()</code> when an event occurs:</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.monotonic_counter(\"iface.bytes\").set(10)\n\niface_bytes = registry.new_id(\"iface.bytes\")\nregistry.monotonic_counter_with_id(iface_bytes).set(10)\n</code></pre>"},{"location":"spectator/lang/py/meters/percentile-dist-summary/","title":"Percentile Distribution Summary","text":"<p>The value tracks the distribution of events, with percentile estimates. It is similar to a <code>PercentileTimer</code>, but more general, because the size does not have to be a period of time.</p> <p>For example, it can be used to measure the payload sizes of requests hitting a server or the number of records returned from a query.</p> <p>In order to maintain the data distribution, they have a higher storage cost, with a worst-case of up to 300X that of a standard Distribution Summary. Be diligent about any additional dimensions added to Percentile Distribution Summaries and ensure that they have a small bounded cardinality.</p> <p>Call <code>record()</code> with a value:</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.pct_distribution_summary(\"server.requestSize\").record(10)\n\nrequest_size = registry.new_id(\"server.requestSize\")\nregistry.pct_distribution_summary_with_id(request_size).record(10)\n</code></pre>"},{"location":"spectator/lang/py/meters/percentile-timer/","title":"Percentile Timer","text":"<p>The value is the number of seconds that have elapsed for an event, with percentile estimates.</p> <p>This metric type will track the data distribution by maintaining a set of Counters. The distribution can then be used on the server side to estimate percentiles, while still allowing for arbitrary slicing and dicing based on dimensions.</p> <p>In order to maintain the data distribution, they have a higher storage cost, with a worst-case of up to 300X that of a standard Timer. Be diligent about any additional dimensions added to Percentile Timers and ensure that they have a small bounded cardinality.</p> <p>Call <code>record()</code> with a value:</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.pct_timer(\"server.requestLatency\").record(0.01)\n\nrequest_latency = registry.new_id(\"server.requestLatency\")\nregistry.pct_timer_with_id(request_latency).record(0.01)\n</code></pre> <p>A <code>StopWatch</code> class is available, which may be used as a Context Manager to automatically record the number of seconds that have elapsed while executing a block of code:</p> <pre><code>import time\nfrom spectator.registry import Registry\nfrom spectator.stopwatch import StopWatch\n\nregistry = Registry()\nthread_sleep = registry.pct_timer(\"thread.sleep\")\n\nwith StopWatch(thread_sleep):\n    time.sleep(5)\n</code></pre>"},{"location":"spectator/lang/py/meters/timer/","title":"Timer","text":"<p>A Timer is used to measure how long (in seconds) some event is taking.</p> <p>Call <code>record()</code> with a value:</p> <pre><code>from spectator.registry import Registry\n\nregistry = Registry()\nregistry.timer(\"server.requestLatency\").record(0.01)\n\nrequest_latency = registry.new_id(\"server.requestLatency\")\nregistry.timer_with_id(request_latency).record(0.01)\n</code></pre> <p>A <code>StopWatch</code> class is available, which may be used as a Context Manager to automatically record the number of seconds that have elapsed while executing a block of code:</p> <pre><code>import time\nfrom spectator.registry import Registry\nfrom spectator.stopwatch import StopWatch\n\nregistry = Registry()\nthread_sleep = registry.timer(\"thread.sleep\")\n\nwith StopWatch(thread_sleep):\n    time.sleep(5)\n</code></pre>"},{"location":"spectator/lang/rb/deprecated/","title":"spectator-rb Usage","text":"<p>This client library is deprecated, does not support spectatord, and it is no longer maintained.</p> <p>You should move to a Paved Path language as soon as possible.</p>"},{"location":"spectator/patterns/cardinality-limiter/","title":"Cardinality Limiter","text":"<p>Helper functions to help manage the cardinality of tag values. This should be used anywhere you cannot guarantee that the tag values being used are strictly bounded. There is support for two different modes: (1) selecting the first N values that are seen, or (2) selecting the most frequent N values that are seen.</p> <p>Example usage:</p> <pre><code>class WebServer {\n\n  // Limiter instance, should be shared for all uses of that tag value\n  private final Function&amp;lt;String, String&amp;gt; pathLimiter =\n    CardinalityLimiters.mostFrequent(10);\n\n  private final Registry registry;\n  private final Id baseId;\n\n  public WebServer(Registry registry) {\n    this.registry = registry;\n    this.baseId = registry.createId(\"server.requestCount\");\n  }\n\n  public Response handleRequest(Request req) {\n    Response res = doSomething(req);\n\n    // Update metrics, use limiter to restrict the set of values for the\n    // path and avoid an explosion\n    String pathValue = pathLimiter.apply(req.getPath());\n    Id id = baseId\n      .withTag(\"path\", pathValue)\n      .withTag(\"status\", res.getStatus());\n    registry.counter(id).increment();\n  }\n}\n</code></pre>"},{"location":"spectator/patterns/gauge-poller/","title":"Gauge Poller","text":"<p>Helper for polling gauges in a background thread. A shared executor is used with a single thread. If registered gauge methods are cheap as they should be, then this should be plenty of capacity to process everything regularly. If not, then this will help limit the damage to a single core and avoid causing problems for the application.</p>"},{"location":"spectator/patterns/interval-counter/","title":"Interval Counter","text":"<p>A counter that also keeps track of the time since last update.</p>"},{"location":"spectator/patterns/long-task-timer/","title":"Long Task Timer","text":"<p>Timer intended to track a small number of long running tasks. Example would be something like a batch hadoop job. Though \"long running\" is a bit subjective the assumption is that anything over a minute is long running.</p> <p>A regular Timer just records the duration and has no information until the task is complete.</p> <p>As an example, consider a chart showing request latency to a typical web server. The expectation is many short requests, so the timer will be getting updated many times per second.</p> <p></p> <p>Now consider a background process to refresh metadata from a data store. For example, Edda caches AWS resources such as instances, volumes, auto-scaling groups etc. Normally, all data can be refreshed in a few minutes. If the AWS services are having problems, it can take much longer. A long duration timer can be used to track the overall time for refreshing the metadata.</p> <p>The charts below show max latency for the refresh using a regular timer and a long task timer. Regular timer, note that the y-axis is using a logarithmic scale:</p> <p></p> <p>Long Task Timer:</p> <p></p>"},{"location":"spectator/patterns/percentile-timer/","title":"Percentile Timers","text":"<p>A Timer that buckets the counts, to allow for estimating percentiles. This Timer type will track the data distribution for the timer by maintaining a set of Counters. The distribution can then be used on the server side to estimate percentiles, while still allowing for arbitrary slicing and dicing based on dimensions.</p> <p>Warning</p> <p>Please be selective about what you measure as there is significant overhead on both the client and storage side. Usually only one or two key performance indicators (KPIs) per application. Limit the tag cardinality as much as possible. For example, only include an endpoint tag, not a user agent or response code. Use one of the other meter types whenever possible.</p> <p>In order to maintain the data distribution, they have a higher storage cost, with a worst-case of up to 300X that of a standard Timer. Be diligent about any additional dimensions added to Percentile Timers and ensure that they have a small bounded cardinality. In addition, it is highly recommended to set a range, whenever possible, to restrict the worst case overhead.</p> <p>When using the builder, the range will default from 10 ms to 1 minute. Based on data at Netflix, this is the most common range for request latencies and restricting to this window reduces the worst case multiple from 276X to 58X.</p>"},{"location":"spectator/patterns/percentile-timer/#range-recommendations","title":"Range Recommendations","text":"<p>The range should be the SLA boundary or failure point for the activity. Explicitly setting the range allows us to optimize for the important range of values and reduce the overhead associated with tracking the data distribution.</p> <p>For example, suppose you are making a client call and timeout after 10 seconds. Setting the range to 10 seconds will restrict the possible set of buckets used to those approaching the boundary. So we can still detect if it is nearing failure, but percentiles that are further away from the range may be inflated compared to the actual value.</p>"},{"location":"spectator/patterns/percentile-timer/#bucket-distribution","title":"Bucket Distribution","text":"<p>The set of buckets is generated by using powers of 4 and incrementing by one-third of the previous power of 4 in between as long as the value is less than the next power of 4 minus the delta.</p> <pre><code>Base: 1, 2, 3\n\n4 (4^1), delta = 1\n    5, 6, 7, ..., 14,\n\n16 (4^2), delta = 5\n   21, 26, 31, ..., 56,\n\n64 (4^3), delta = 21\n...\n</code></pre>"},{"location":"spectator/patterns/polled-meter/","title":"Polled Meter","text":"<p>Helper for configuring a meter that will receive a value by regularly polling the source in the background.</p> <p>Example usage:</p> <pre><code>Registry registry = ...\nAtomicLong connections = PolledMeter.using(registry)\n  .withName(\"server.currentConnections\")\n  .monitorValue(new AtomicLong());\n\n// When a connection is added\nconnections.incrementAndGet();\n\n// When a connection is removed\nconnections.decrementAndGet();\n</code></pre> <p>Polling frequency will depend on the underlying Registry implementation, but users should assume it will be frequently checked and that the provided function is cheap. Users should keep in mind that polling will not capture all activity, just sample it at some frequency. For example, if monitoring a queue, then a meter will only tell you the last sampled size when the value is reported. If more details are needed, then use an alternative type and ensure that all changes are reported when they occur.</p> <p>For example, consider tracking the number of currently established connections to a server. Using a polled meter will show the last sampled number when reported. An alternative would be to report the number of connections to a Distribution Summary every time a connection is added or removed. The distribution summary would provide more accurate tracking such as max and average number of connections across an interval of time. The polled meter would not provide that level of detail.</p> <p>If multiple values are monitored with the same id, then the values will be aggregated and the sum will be reported. For example, registering multiple meters for active threads in a thread pool with the same id would produce a value that is the overall number of active threads. For other behaviors, manage it on the user side and avoid multiple registrations.</p>"},{"location":"spectator/specs/ipc/","title":"IPC","text":"<p>This is a description of the Common IPC Metrics that can be published by various IPC libraries, with the goal of allowing consolidated monitoring and analysis across differing IPC implementations.</p>"},{"location":"spectator/specs/ipc/#dimensions-common-to-all-metrics","title":"Dimensions Common to All Metrics","text":"<p>Not all dimensions are applicable for all of the metrics, and later in the sections  for each specific metric, the applicable dimensions are specified.</p> <p>Also note that not all dimensions have been implemented or are applicable for all implementations.</p> <ul> <li><code>ipc.protocol</code>: A short name of the network protocol in use, eg. <code>grpc</code>, <code>http_1</code>,   <code>http_2</code>, <code>udp</code>, etc ...</li> <li><code>ipc.vip</code>: The Eureka VIP address used to find the the server.</li> <li><code>ipc.result</code>: Was this considered by the implementation to be successful. Allowed Values =   [<code>success</code>, <code>failure</code>].</li> <li><code>ipc.status</code>: One of a predefined list of status values indicating the general result, eg.   success, bad_request, timeout, etc\u2026 See the ipc.status values section below.</li> <li><code>ipc.status.detail</code>: For cases where the ipc.status needs to be further subdivided, this tag   can hold an additional more specific detail, likely ipc-implementation specific. eg status of   connection_error and detail of no_servers / connect_timeout / ssl_handshake_failure.</li> <li><code>ipc.failure.injected</code>: Indicates that an artificial failure was injected into the request   processing for testing purposes. The outcome of that failure will be reflected in the other   error tags. Allowed Values = [true]</li> <li><code>ipc.endpoint</code>: The name of the endpoint/function/feature the message was sent to within   the server (eg. the URL path prefix for a java servlet, or the grpc endpoint name).</li> <li><code>ipc.attempt</code>: Which attempt at sending this message is this. Allowed Values =   [<code>initial</code>, <code>second</code>, <code>third_up</code>] (<code>initial</code> is the first attempt, <code>second</code> is 2nd attempt   but first retry, <code>third_up</code> means third or higher attempt).</li> <li><code>ipc.attempt.final</code>: Indicates if this request was the final attempt of potentially multiple   retry attempts. Allowed Values = [<code>true</code>, <code>false</code>].</li> <li><code>ipc.server.app</code>: The <code>nf.app</code> of the server the message is being sent to.</li> <li><code>ipc.server.cluster</code>: The <code>nf.cluster</code> of the server the message is being sent to.</li> <li><code>ipc.server.asg</code>: The <code>nf.asg</code> of the server the message is being sent to.</li> <li><code>ipc.client.app</code>: The <code>nf.app</code> of the server the message is being sent from.</li> <li><code>ipc.client.cluster</code>: The <code>nf.cluster</code> of the server the message is being sent from.</li> <li><code>ipc.client.asg</code>: The <code>nf.asg</code> of the server the message is being sent from.</li> <li><code>owner</code>: The library/impl publishing the metrics, eg. evcache, zuul, grpc, nodequark,   platform_1_ipc, geoclient, etc ...</li> <li><code>id</code>: Conceptual name of service. Equivalent of RestClient name in NIWS.</li> </ul>"},{"location":"spectator/specs/ipc/#allowed-values-for-ipcstatus-dimension","title":"Allowed Values for <code>ipc.status</code> Dimension","text":"<ul> <li><code>success</code>: The request was successfully processed and responded to, as far as the client or   server know.</li> <li><code>bad_request</code>: There was a problem with the clients' request causing it not to be fulfilled.</li> <li><code>unexpected_error</code>: The client or server encountered an unexpected error processing the request.</li> <li><code>connection_error</code>: There was an error with the underlying network connection either during   establishment or while in use.</li> <li><code>unavailable</code>: There were no servers available to process the request.</li> <li><code>throttled</code>: The request was rejected due to the client or server considering the server to   be above capacity.</li> <li><code>timeout</code>: The request could not or would not be complete within the configured threshold   (either on client or server).</li> <li><code>cancelled</code>: The client cancelled the request before it was completed.</li> <li><code>access_denied</code>: The request was denied access for authentication or authorization reasons.</li> </ul>"},{"location":"spectator/specs/ipc/#server-metrics","title":"Server Metrics","text":""},{"location":"spectator/specs/ipc/#ipcservercall","title":"ipc.server.call","text":"<p>This is a percentile timer that is recorded for each inbound message to a server.</p> <p>Unit: seconds</p> <p>Dimensions:</p> <ul> <li><code>ipc.protocol</code></li> <li><code>ipc.result</code></li> <li><code>ipc.vip</code></li> <li><code>ipc.endpoint</code></li> <li><code>ipc.status</code></li> <li><code>ipc.status.detail</code></li> <li><code>ipc.failure.injected</code></li> <li><code>ipc.attempt</code></li> <li><code>ipc.client.app</code></li> <li><code>ipc.client.cluster</code></li> <li><code>ipc.client.asg</code></li> <li><code>owner</code></li> <li><code>id</code></li> </ul>"},{"location":"spectator/specs/ipc/#ipcservercallsizeinbound","title":"ipc.server.call.size.inbound","text":"<p>This is a distribution summary of the size in bytes of inbound messages received by a server.</p> <p>Unit: bytes</p> <p>Dimensions:</p> <ul> <li><code>ipc.protocol</code></li> <li><code>ipc.vip</code></li> <li><code>ipc.endpoint</code></li> <li><code>ipc.result</code></li> <li><code>ipc.status</code></li> <li><code>ipc.status.detail</code></li> <li><code>ipc.client.app</code></li> <li><code>ipc.client.cluster</code></li> <li><code>ipc.client.asg</code></li> <li><code>owner</code></li> <li><code>id</code></li> </ul>"},{"location":"spectator/specs/ipc/#ipcservercallsizeoutbound","title":"ipc.server.call.size.outbound","text":"<p>This is a distribution summary of the size in bytes of outbound messages sent from a server.</p> <p>Unit: bytes</p> <p>Dimensions:</p> <ul> <li><code>ipc.protocol</code></li> <li><code>ipc.vip</code></li> <li><code>ipc.endpoint</code></li> <li><code>ipc.result</code></li> <li><code>ipc.status</code></li> <li><code>ipc.status.detail</code></li> <li><code>ipc.client.app</code></li> <li><code>ipc.client.cluster</code></li> <li><code>ipc.client.asg</code></li> <li><code>owner</code></li> <li><code>id</code></li> </ul>"},{"location":"spectator/specs/ipc/#ipcserverinflight","title":"ipc.server.inflight","text":"<p>This is a distribution summary that shows the number of inbound IPC messages currently being processed in a server.</p> <p>Note</p> <p>Distribution summaries are not suitable for use-cases trying to perform hierarchical accumulation across dimensions. Each measurement is recorded with a certain set of dimensions, as illustrated below with the inflight metric. Therefore, when using the :dist-max operator to query over a set of filters, the response will represent the maximum inflight count for a given set of tag values within the group, not the accumulated value of measurements across the entire group.</p> <p>Unit: inflight message count</p> <p>Dimensions:</p> <ul> <li><code>ipc.protocol</code></li> <li><code>ipc.endpoint</code></li> <li><code>ipc.client.app</code></li> <li><code>ipc.client.cluster</code></li> <li><code>ipc.client.asg</code></li> <li><code>owner</code></li> <li><code>id</code></li> </ul>"},{"location":"spectator/specs/ipc/#client-metrics","title":"Client Metrics","text":""},{"location":"spectator/specs/ipc/#ipcclientcall","title":"ipc.client.call","text":"<p>This is a percentile timer that is recorded for each outbound message from a client.</p> <p>Unit: seconds</p> <p>Dimensions:</p> <ul> <li><code>ipc.protocol</code></li> <li><code>ipc.result</code></li> <li><code>ipc.vip</code></li> <li><code>ipc.endpoint</code></li> <li><code>ipc.status</code></li> <li><code>ipc.status.detail</code></li> <li><code>ipc.failure.injected</code></li> <li><code>ipc.attempt</code></li> <li><code>ipc.attempt.final</code></li> <li><code>ipc.server.app</code></li> <li><code>ipc.server.cluster</code></li> <li><code>ipc.server.asg</code></li> <li><code>owner</code></li> <li><code>id</code></li> </ul>"},{"location":"spectator/specs/ipc/#ipcclientcallsizeinbound","title":"ipc.client.call.size.inbound","text":"<p>This is a distribution summary of the size in bytes of inbound messages received by a client.</p> <p>Unit: bytes</p> <p>Dimensions:</p> <ul> <li><code>ipc.protocol</code></li> <li><code>ipc.vip</code></li> <li><code>ipc.endpoint</code></li> <li><code>ipc.result</code></li> <li><code>ipc.status</code></li> <li><code>ipc.status.detail</code></li> <li><code>ipc.server.app</code></li> <li><code>ipc.server.cluster</code></li> <li><code>ipc.server.asg</code></li> <li><code>owner</code></li> <li><code>id</code></li> </ul>"},{"location":"spectator/specs/ipc/#ipcclientcallsizeoutbound","title":"ipc.client.call.size.outbound","text":"<p>This is a distribution summary of the size in bytes of outbound messages sent from a client.</p> <p>Unit: bytes</p> <p>Dimensions:</p> <ul> <li><code>ipc.protocol</code></li> <li><code>ipc.vip</code></li> <li><code>ipc.endpoint</code></li> <li><code>ipc.result</code></li> <li><code>ipc.status</code></li> <li><code>ipc.status.detail</code></li> <li><code>ipc.server.app</code></li> <li><code>ipc.server.cluster</code></li> <li><code>ipc.server.asg</code></li> <li><code>owner</code></li> <li><code>id</code></li> </ul>"},{"location":"spectator/specs/ipc/#ipcclientinflight","title":"ipc.client.inflight","text":"<p>This is a distribution summary that shows the number of currently outstanding outbound IPC messages from a client.</p> <p>Note</p> <p>Distribution summaries are not suitable for use-cases trying to perform hierarchical accumulation across dimensions. Each measurement is recorded with a certain set of dimensions, as illustrated below with the inflight metric. Therefore, when using the :dist-max operator to query over a set of filters, the response will represent the  maximum inflight count for a given set of tag values within the group, not the accumulated value of measurements  across the entire group.</p> <p>Unit: inflight message count</p> <p>Dimensions:</p> <ul> <li><code>ipc.protocol</code></li> <li><code>ipc.vip</code></li> <li><code>ipc.endpoint</code></li> <li><code>ipc.server.app</code></li> <li><code>ipc.server.cluster</code></li> <li><code>ipc.server.asg</code></li> <li><code>owner</code></li> <li><code>id</code></li> </ul>"}]}